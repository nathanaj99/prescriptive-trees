{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILP Formulation from Nathan Kallus' Paper (Problem 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specifications\n",
    "#### Since we chose to modify the formulation to a certain extent, these variables simply allow us to revert back to the original model\n",
    "- delta_include: If true, then constraint 4c from original formulation holds. If false, only the added constraint that gamma[p] need to add to 1 holds\n",
    "- different_Cp = If true, then we have different sets of branching choices for every non-leaf node (like original formulation). If false, then we have a static set C for all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- This class is an alternative to solving the right/left ancestor problem --\n",
    "\"\"\"\n",
    "INPUT: d = depth of tree (which includes root node), so d = 2 would make a tree with {1, 2, 3}\n",
    "RELEVANT FUNCTIONS:\n",
    "- get_right_left: For all leaf nodes, returns its right and left ancestors in a dictionary \n",
    "                  of {(p, q): 1 or -1 if q is right or left ancestor respectively}\n",
    "\"\"\"\n",
    "class Tree:\n",
    "    def __init__(self, d):\n",
    "        self.depth = d\n",
    "        self.nodes = list(range(1, 2**(d-1)))\n",
    "        self.leaves = list(range(2**(d-1), 2**d))\n",
    "        self.ancestor_rl = {}\n",
    "    \n",
    "    def get_left_children(self, n):\n",
    "        if n in self.nodes:\n",
    "            return int(2*n)\n",
    "        else:\n",
    "            raise Exception ('Invalid node n')\n",
    "    \n",
    "    def get_right_children(self, n):\n",
    "        if n in self.nodes:\n",
    "            return int(2*n+1)\n",
    "        else:\n",
    "            raise Exception ('Invalid node n')\n",
    "    \n",
    "    def get_parent(self, n):\n",
    "        if (n in self.nodes) | (n in self.leaves):\n",
    "            return int(math.floor(n/2))\n",
    "        else:\n",
    "            raise Exception ('Invalide node n')\n",
    "    \n",
    "    def get_ancestors(self, direction, n):\n",
    "        current = n\n",
    "        ancestors = []\n",
    "        while current != 1:\n",
    "            current_buffer = self.get_parent(current)\n",
    "            if direction == 'r':\n",
    "                if self.get_right_children(current_buffer) == current:\n",
    "                    ancestors.append(current_buffer)\n",
    "            else:\n",
    "                if self.get_left_children(current_buffer) == current:\n",
    "                    ancestors.append(current_buffer)\n",
    "            current = current_buffer\n",
    "        return ancestors\n",
    "    \n",
    "    def get_right_left(self):\n",
    "        for i in self.leaves:\n",
    "            right = self.get_ancestors('r', i)\n",
    "            for j in right:\n",
    "                self.ancestor_rl[(i, j)] = 1\n",
    "            left = self.get_ancestors('l', i)\n",
    "            for j in left:\n",
    "                self.ancestor_rl[(i, j)] = -1\n",
    "        return self.ancestor_rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    train_X = df.iloc[:, :20]\n",
    "    real = df.iloc[:, 20:22]\n",
    "    train_t = df.iloc[:, 22]\n",
    "    train_y = df.iloc[:, 24]\n",
    "    return train_X, train_t, train_y, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoint_tree(node, i, test_X, test_real, test_t):\n",
    "    if node in L: #if datapoint has reached leaf node, calculate error\n",
    "        index = treatments[node]\n",
    "        ideal_outcome = max(test_real.iloc[i, :])\n",
    "        difference = ideal_outcome - test_real.iloc[i, index]\n",
    "        if difference == 0:\n",
    "            count_optimal = 1\n",
    "        else:\n",
    "            count_optimal = 0\n",
    "        \n",
    "        if index == test_t[i]:\n",
    "            same_treatment = 1\n",
    "        else:\n",
    "            same_treatment = 0\n",
    "        return difference, count_optimal, same_treatment\n",
    "    if test_X.iloc[i, branching[node]] <= 0: # go left (node 2)\n",
    "        return datapoint_tree(tree.get_left_children(node), i, test_X, test_real, test_t)\n",
    "    else:\n",
    "        return datapoint_tree(tree.get_right_children(node), i, test_X, test_real, test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_X, test_real, test_t):\n",
    "    difference = 0\n",
    "    count_optimal = 0\n",
    "    count_same = 0\n",
    "    for i in range(len(test_X)):\n",
    "        diff, optimal, treat = datapoint_tree(1, i, test_X, test_real, test_t)\n",
    "        difference += diff\n",
    "        count_optimal += optimal\n",
    "        count_same += treat\n",
    "    return difference, float(count_optimal)/len(test_X), float(count_same)/len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring variables determined a-priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Specfiying Input to Model\n",
    "- m treatments indexed by t {1,..., m}\n",
    "- n datapoints indexed by i {(X1, T1, Y1), ..., (Xn, Tn, Yn)} \n",
    "- d: depth of decision tree\n",
    "- n_min: minimum number of datapoints of each treatment in node p\n",
    "- num_features\n",
    "- num_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tree(depth, bert):\n",
    "    delta_include = False\n",
    "    different_Cp = False\n",
    "    bertsimas = bert\n",
    "\n",
    "    m = {0, 1}\n",
    "    n = len(train_X)\n",
    "    d = int(depth)\n",
    "    n_min = 0\n",
    "    num_features = 2\n",
    "    num_cuts = 2\n",
    "\n",
    "    \"\"\"# ---- CONSTRUCTING COMPLETE BINARY TREE ----\n",
    "    # - P = number of nodes in the tree\n",
    "    # - L_c = set of non-leaf nodes\n",
    "    # - L = set of leaf ndoes\"\"\"\n",
    "\n",
    "    P = 2**d\n",
    "    L_c = set(range(1, 2**(d-1)))\n",
    "    L = set(range(2**(d-1), P))\n",
    "\n",
    "    # - ancestors: dictionary {leaf nodes: {set of ancestors}}\n",
    "    ancestors = {}\n",
    "    for p in L:\n",
    "        ancestors[p] = [math.floor(p/(2**j)) for j in range(1, d)]\n",
    "\n",
    "        # Alternative way of retrieving right/left ancestors\n",
    "    tree = Tree(d)\n",
    "    right_left = tree.get_right_left()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    - C[p]: finite set of cuts on node p--determined apriori {(l, theta)}\n",
    "        Representation: dictionary {non-leaf node: list of (l, theta)}\n",
    "        Require a list instead of set so it's ordered (indexed easily)\n",
    "\n",
    "\n",
    "    From Kallus' paper, he wants us to:\n",
    "    1. For each l in [d], sort data along x_l\n",
    "    2a. For each non-leaf node, pick #features from [d] randomly\n",
    "    2b. Set J = {1, (n-1/#cuts), ..., n-1} in decreasing order of cuts\n",
    "    2c. Set Cp = {(l, midpoint between the two buckets in J) for all dimensions chosen and for all j in J}\n",
    "\n",
    "    Make version of ALG3 to take all features\"\"\"\n",
    "\n",
    "\n",
    "    if different_Cp:\n",
    "        pass\n",
    "    else:\n",
    "        # -- BINARY COVARIATES --> Create a finite set of cuts for C for all features --\n",
    "        C = []\n",
    "        for i in range(len(train_X.columns)):\n",
    "            C.append((i, 0))\n",
    "\n",
    "\n",
    "    \"\"\" --- OTHER DATA --- \n",
    "    BIG M Constraints:\n",
    "    - Ybar\n",
    "    - Ymax\n",
    "    - M\n",
    "\n",
    "    BINARY ENCODING FOR CUTS\n",
    "    - k_p: dictionary {non-leaf node p: k_p value}\n",
    "    - Z_p: dictionary {non-leaf node p: k_p x |C_p| 2d matrix}\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Big M Constraints ----\n",
    "    # Ybar is merged into data, but it could not be. ybar is a numpy array\n",
    "    minimum = min(train_y)\n",
    "\n",
    "    ybar = train_y - minimum\n",
    "    #data['ybar'] = ybar\n",
    "\n",
    "    # Ymax\n",
    "    ymax = max(ybar)\n",
    "\n",
    "    # M\n",
    "    # Find all sums for treatments 1, ..., m\n",
    "    #treatment_counts = treatment.value_counts().to_list()\n",
    "    unique, counts = np.unique(train_t, return_counts=True)\n",
    "    #frequencies = numpy.asarray((unique, counts)).T\n",
    "    M = np.array(counts)\n",
    "    M -= len(L) * n_min\n",
    "    M = max(M)\n",
    "    \n",
    "    model = gp.Model(\"Kallus\")\n",
    "    model.params.TimeLimit = 3600\n",
    "\n",
    "    # -- VARIABLE DECLARATION --\n",
    "\n",
    "    # -- Variables to determine: gamma and lambda --\n",
    "    # 1. gamma_p = choice of cut at node p ([0, 1]^C_p) (only applies to non-leaf node)\n",
    "    #       - represent with a matrix gamma (|L_c| x |C_p|)\n",
    "\n",
    "    gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "    # This assumes gamma is binary\n",
    "    #gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "\n",
    "    # 2. lambda_pt = choice of treatment t at node p (only applies to leaf nodes L)\n",
    "    #       - represent with a matrix lamb (|L| x m)\n",
    "    lamb = model.addVars(L, m, vtype=GRB.BINARY, name='lamb')\n",
    "\n",
    "\n",
    "    # -- Other Variables in Formulation --\n",
    "    # 1. w_ip = membership of datapoint i in node p (only applies to leaf nodes L)\n",
    "    #       - represent with a matrix w (n x |L|)\n",
    "\n",
    "    w = model.addVars(n, L, lb=0, ub=1, name='w')\n",
    "    # This assumes w is binary, when in reality it is continuous from 0-1\n",
    "    #w = model.addVars(n, L, vtype=GRB.BINARY, name='w') # Original paper has this be a continuous variable\n",
    "\n",
    "    # 2. mu_p = mean outcome of prescribed treatment in node p\n",
    "    #       - represent with a matrix mu (|L|)\n",
    "    mu = model.addVars(L, lb=0, name='mu') # define in constraint\n",
    "\n",
    "    # 3. nu_ip = \"effect\" of treatment in node p by multiplying mu and w\n",
    "    #       - represent with a matrix nu (n x |L|)\n",
    "    nu = model.addVars(n, L, lb=0, name='nu')\n",
    "\n",
    "    # 4. delta_p = forces only 1 choice of cut at node p\n",
    "    #       - represent with a dictionary {non-leaf node p: 1d matrix of size k_p}\n",
    "    #delta = model.addVars(L, k, vtype=GRB.BINARY, name='delta')\n",
    "\n",
    "    # 5. Chi_i(gamma) = 1 if choice of cut induces datapoint i to go left on the cut gamma, 0 otherwise\n",
    "    chi = model.addVars(L_c, n, vtype=GRB.BINARY, name='chi')\n",
    "\n",
    "    if bertsimas:\n",
    "        # 6. f_i\n",
    "        f = model.addVars(n, lb=0, name='f')\n",
    "\n",
    "        # 7. Beta_lt\n",
    "        beta = model.addVars(L, m, lb=0, name='beta')\n",
    "\n",
    "    theta = 0.5\n",
    "    \n",
    "        # --- OBJECTIVE FUNCTION ---\n",
    "    if bertsimas:\n",
    "        model.setObjective(theta * gp.quicksum(nu[i, p] for i in range(n) for p in L) \n",
    "                       - (1-theta) * gp.quicksum((train_y[i] - f[i]) * (train_y[i] - f[i]) for i in range(n)), GRB.MAXIMIZE)\n",
    "    else:\n",
    "        model.setObjective(gp.quicksum(nu[i, p] for i in range(n) for p in L), GRB.MAXIMIZE)\n",
    "\n",
    "\n",
    "    # --- CONSTRAINTS ---\n",
    "    # Constraint 4c (4b is done by definition of variables)\n",
    "    if delta_include:\n",
    "        for p in L_c:\n",
    "            # need to do matrix multiplication somehow, but this might work?\n",
    "            for j in range(k):\n",
    "                model.addConstr(delta[p, j] == gp.quicksum(gamma[p, i] * z[j, i] for i in range(len(C))))\n",
    "\n",
    "    # Additional constraint that gamma[p] adds up to 1\n",
    "    # CHECKED\n",
    "    for p in L_c:\n",
    "        model.addConstr(gp.quicksum(gamma[p, i] for i in range(len(C))) == 1)\n",
    "\n",
    "    # Add constraint Chi\n",
    "    for i in range(n):\n",
    "        for p in L_c:\n",
    "            model.addConstr(chi[p, i] == gp.quicksum(gamma[p, j] for j in range(len(C)) if C[j][1] >= train_X.iloc[i, C[j][0]]))\n",
    "\n",
    "\n",
    "    # Constraint 4d&e (Membership restriction from its ancestors) CHECKED\n",
    "    for p in L:\n",
    "        A_p = ancestors[p] #index ancestors of p\n",
    "        for q in A_p:\n",
    "            R_pq = right_left[(p, q)]\n",
    "            for i in range(n):\n",
    "                model.addConstr(w[i, p] <= (1+R_pq)/2 - R_pq * chi[q, i])\n",
    "\n",
    "\n",
    "    #4e CHECKED\n",
    "    for p in L:\n",
    "        A_p = ancestors[p] #index ancestors of p\n",
    "        for i in range(n):\n",
    "            model.addConstr(w[i, p] >= 1 + gp.quicksum(-chi[q, i] for q in A_p if right_left[(p, q)] == 1)\n",
    "                        + gp.quicksum(-1+chi[q, i] for q in A_p if right_left[(p, q)] == -1))\n",
    "\n",
    "\n",
    "    # Constraint 4f\n",
    "    # CHECKED\n",
    "    for t in m:\n",
    "        for p in L:\n",
    "            model.addConstr(gp.quicksum(w[i, p] for i in range(n) if train_t[i] == t) >= n_min) #assuming the input comes in vector (Xi, Ti, Yi)\n",
    "            # only add the datapoints that have been given treatment t\n",
    "\n",
    "    # Constraints 4g&h (Linearization of nu)\n",
    "    # CHECKED\n",
    "    for p in L:\n",
    "        for i in range(n):\n",
    "            model.addConstr(nu[i, p] <= ymax * w[i, p])\n",
    "            model.addConstr(nu[i, p] <= mu[p])\n",
    "            model.addConstr(nu[i, p] >= mu[p] - ymax * (1-w[i, p]))\n",
    "\n",
    "    # Constraint 4i (Choice of treatment applied to p)\n",
    "    # CHECKED\n",
    "    for p in L:\n",
    "        model.addConstr(gp.quicksum(lamb[p, t] for t in m) == 1)\n",
    "\n",
    "    # Constraint 4j&k (Consistency between lambda and mu)\n",
    "    # CHECKED. There are some inconsistencies where some w don't appear, but this is because ybar is 0 (i.e. the minimum)\n",
    "    for p in L:\n",
    "        for t in m:\n",
    "            model.addConstr(gp.quicksum(nu[i, p] - w[i, p] * ybar[i] for i in range(n) if train_t[i] == t) <= M*(1-lamb[p, t]))\n",
    "            model.addConstr(gp.quicksum(nu[i, p] - w[i, p] * ybar[i] for i in range(n) if train_t[i] == t) >= M*(lamb[p, t]-1))\n",
    "    #model.addConstr(lamb[2, 0] == 1)\n",
    "    if bertsimas:\n",
    "        for i in range(n):\n",
    "            for p in L:\n",
    "                for t in m:\n",
    "                    if train_t[i] == t:\n",
    "                        model.addConstr(f[i] - beta[p, t] <= M * (1-w[i, p]))\n",
    "                        model.addConstr(f[i] - beta[p, t] >= M * (w[i, p]-1))\n",
    "\n",
    "    model.optimize()\n",
    "    model.printAttr('X')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset  Depth  P(Correct Treatment)  Test Error  Test % Optimal  \\\n",
      "0        1      2                   0.5   53.227602           76.83   \n",
      "1        1      3                   0.5  123.833930           66.00   \n",
      "2        1      3                   0.5  123.833930           66.00   \n",
      "3        2      2                   0.5   24.915258           84.31   \n",
      "4        2      3                   0.5   24.915258           84.31   \n",
      "5        3      2                   0.5  166.280038           58.61   \n",
      "6        3      3                   0.5   57.544135           77.50   \n",
      "\n",
      "   Test % Same Treatment  Train Error  Train % Optimal  \\\n",
      "0                  49.33     1.833834             83.0   \n",
      "1                  49.34     2.356756             85.2   \n",
      "2                  49.34     2.356756             85.2   \n",
      "3                  50.46     1.220292             87.8   \n",
      "4                  50.46     1.220292             87.8   \n",
      "5                  49.19     5.115352             75.0   \n",
      "6                  49.48     2.759458             81.4   \n",
      "\n",
      "   Train % Same Treatment                                               Tree  \n",
      "0                    51.4      branching = {1: 2}, treatments = {2: 1, 3: 0}  \n",
      "1                    51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "2                    51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "3                    49.6      branching = {1: 3}, treatments = {2: 1, 3: 0}  \n",
      "4                    49.6  branching = {1: 3, 2: 13, 3: 15}, treatments =...  \n",
      "5                    48.6     branching = {1: 12}, treatments = {2: 0, 3: 0}  \n",
      "6                    46.6  branching = {1: 5, 2: 14, 3: 12}, treatments =...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"kallus = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                               'Train % Same Treatment', 'Tree'])\n",
    "bertsimas = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                                  'Train % Same Treatment', 'Tree'])\"\"\"\n",
    "\n",
    "\n",
    "bertsimas = pd.read_csv('bertsimas_athey_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed value of parameter TimeLimit to 3600.0\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Gurobi Optimizer version 9.0.3 build v9.0.3rc0 (mac64)\n",
      "Optimize a model with 5515 rows, 2526 columns and 21004 nonzeros\n",
      "Model fingerprint: 0xb7b8bcd1\n",
      "Variable types: 2002 continuous, 524 integer (524 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-03, 3e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+02]\n",
      "Presolve removed 4282 rows and 2031 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 1233 rows, 495 columns, 5135 nonzeros\n",
      "Variable types: 378 continuous, 117 integer (117 binary)\n",
      "\n",
      "Root relaxation: objective 4.951259e+02, 662 iterations, 0.01 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0  495.12588    0   63          -  495.12588      -     -    0s\n",
      "H    0     0                     214.3258956  495.12588   131%     -    0s\n",
      "H    0     0                     215.6808463  495.12588   130%     -    0s\n",
      "H    0     0                     253.1677824  495.12588  95.6%     -    0s\n",
      "     0     0  456.38015    0   67  253.16778  456.38015  80.3%     -    0s\n",
      "     0     0  456.38015    0   44  253.16778  456.38015  80.3%     -    0s\n",
      "     0     0  437.61694    0   85  253.16778  437.61694  72.9%     -    0s\n",
      "     0     0  362.29766    0   92  253.16778  362.29766  43.1%     -    0s\n",
      "     0     0  360.80040    0   92  253.16778  360.80040  42.5%     -    0s\n",
      "H    0     0                     254.4167659  360.80040  41.8%     -    0s\n",
      "     0     0  303.77082    0   96  254.41677  303.77082  19.4%     -    0s\n",
      "     0     0  295.34149    0   97  254.41677  295.34149  16.1%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 4\n",
      "  MIR: 10\n",
      "  RLT: 38\n",
      "  BQP: 13\n",
      "\n",
      "Explored 1 nodes (1923 simplex iterations) in 0.69 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 254.417 253.168 215.681 214.326 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.544167659020e+02, best bound 2.544167659020e+02, gap 0.0000%\n",
      "\n",
      "    Variable            X \n",
      "-------------------------\n",
      "  gamma[1,5]            1 \n",
      "   lamb[2,1]            1 \n",
      "   lamb[3,0]            1 \n",
      "      w[0,2]            1 \n",
      "      w[1,3]            1 \n",
      "      w[2,3]            1 \n",
      "      w[3,3]            1 \n",
      "      w[4,3]            1 \n",
      "      w[5,3]            1 \n",
      "      w[6,3]            1 \n",
      "      w[7,2]            1 \n",
      "      w[8,2]            1 \n",
      "      w[9,3]            1 \n",
      "     w[10,3]            1 \n",
      "     w[11,2]            1 \n",
      "     w[12,2]            1 \n",
      "     w[13,3]            1 \n",
      "     w[14,2]            1 \n",
      "     w[15,3]            1 \n",
      "     w[16,3]            1 \n",
      "     w[17,3]            1 \n",
      "     w[18,3]            1 \n",
      "     w[19,3]            1 \n",
      "     w[20,3]            1 \n",
      "     w[21,2]            1 \n",
      "     w[22,2]            1 \n",
      "     w[23,2]            1 \n",
      "     w[24,2]            1 \n",
      "     w[25,3]            1 \n",
      "     w[26,3]            1 \n",
      "     w[27,2]            1 \n",
      "     w[28,3]            1 \n",
      "     w[29,3]            1 \n",
      "     w[30,2]            1 \n",
      "     w[31,3]            1 \n",
      "     w[32,3]            1 \n",
      "     w[33,3]            1 \n",
      "     w[34,3]            1 \n",
      "     w[35,2]            1 \n",
      "     w[36,2]            1 \n",
      "     w[37,2]            1 \n",
      "     w[38,2]            1 \n",
      "     w[39,2]            1 \n",
      "     w[40,3]            1 \n",
      "     w[41,3]            1 \n",
      "     w[42,3]            1 \n",
      "     w[43,3]            1 \n",
      "     w[44,3]            1 \n",
      "     w[45,3]            1 \n",
      "     w[46,3]            1 \n",
      "     w[47,3]            1 \n",
      "     w[48,3]            1 \n",
      "     w[49,3]            1 \n",
      "     w[50,2]            1 \n",
      "     w[51,3]            1 \n",
      "     w[52,2]            1 \n",
      "     w[53,3]            1 \n",
      "     w[54,2]            1 \n",
      "     w[55,2]            1 \n",
      "     w[56,3]            1 \n",
      "     w[57,3]            1 \n",
      "     w[58,3]            1 \n",
      "     w[59,3]            1 \n",
      "     w[60,2]            1 \n",
      "     w[61,3]            1 \n",
      "     w[62,2]            1 \n",
      "     w[63,3]            1 \n",
      "     w[64,3]            1 \n",
      "     w[65,3]            1 \n",
      "     w[66,3]            1 \n",
      "     w[67,3]            1 \n",
      "     w[68,2]            1 \n",
      "     w[69,3]            1 \n",
      "     w[70,3]            1 \n",
      "     w[71,2]            1 \n",
      "     w[72,2]            1 \n",
      "     w[73,3]            1 \n",
      "     w[74,3]            1 \n",
      "     w[75,2]            1 \n",
      "     w[76,3]            1 \n",
      "     w[77,2]            1 \n",
      "     w[78,3]            1 \n",
      "     w[79,3]            1 \n",
      "     w[80,3]            1 \n",
      "     w[81,3]            1 \n",
      "     w[82,3]            1 \n",
      "     w[83,2]            1 \n",
      "     w[84,3]            1 \n",
      "     w[85,3]            1 \n",
      "     w[86,2]            1 \n",
      "     w[87,2]            1 \n",
      "     w[88,3]            1 \n",
      "     w[89,2]            1 \n",
      "     w[90,2]            1 \n",
      "     w[91,2]            1 \n",
      "     w[92,3]            1 \n",
      "     w[93,3]            1 \n",
      "     w[94,2]            1 \n",
      "     w[95,2]            1 \n",
      "     w[96,2]            1 \n",
      "     w[97,3]            1 \n",
      "     w[98,2]            1 \n",
      "     w[99,3]            1 \n",
      "    w[100,3]            1 \n",
      "    w[101,3]            1 \n",
      "    w[102,2]            1 \n",
      "    w[103,2]            1 \n",
      "    w[104,3]            1 \n",
      "    w[105,3]            1 \n",
      "    w[106,2]            1 \n",
      "    w[107,3]            1 \n",
      "    w[108,2]            1 \n",
      "    w[109,3]            1 \n",
      "    w[110,2]            1 \n",
      "    w[111,3]            1 \n",
      "    w[112,3]            1 \n",
      "    w[113,2]            1 \n",
      "    w[114,2]            1 \n",
      "    w[115,3]            1 \n",
      "    w[116,3]            1 \n",
      "    w[117,3]            1 \n",
      "    w[118,3]            1 \n",
      "    w[119,2]            1 \n",
      "    w[120,3]            1 \n",
      "    w[121,2]            1 \n",
      "    w[122,3]            1 \n",
      "    w[123,3]            1 \n",
      "    w[124,3]            1 \n",
      "    w[125,3]            1 \n",
      "    w[126,2]            1 \n",
      "    w[127,2]            1 \n",
      "    w[128,3]            1 \n",
      "    w[129,2]            1 \n",
      "    w[130,2]            1 \n",
      "    w[131,2]            1 \n",
      "    w[132,3]            1 \n",
      "    w[133,2]            1 \n",
      "    w[134,3]            1 \n",
      "    w[135,3]            1 \n",
      "    w[136,2]            1 \n",
      "    w[137,3]            1 \n",
      "    w[138,3]            1 \n",
      "    w[139,2]            1 \n",
      "    w[140,3]            1 \n",
      "    w[141,3]            1 \n",
      "    w[142,2]            1 \n",
      "    w[143,2]            1 \n",
      "    w[144,3]            1 \n",
      "    w[145,2]            1 \n",
      "    w[146,2]            1 \n",
      "    w[147,2]            1 \n",
      "    w[148,3]            1 \n",
      "    w[149,3]            1 \n",
      "    w[150,2]            1 \n",
      "    w[151,3]            1 \n",
      "    w[152,3]            1 \n",
      "    w[153,3]            1 \n",
      "    w[154,3]            1 \n",
      "    w[155,3]            1 \n",
      "    w[156,3]            1 \n",
      "    w[157,2]            1 \n",
      "    w[158,2]            1 \n",
      "    w[159,2]            1 \n",
      "    w[160,2]            1 \n",
      "    w[161,2]            1 \n",
      "    w[162,3]            1 \n",
      "    w[163,3]            1 \n",
      "    w[164,3]            1 \n",
      "    w[165,3]            1 \n",
      "    w[166,2]            1 \n",
      "    w[167,3]            1 \n",
      "    w[168,2]            1 \n",
      "    w[169,3]            1 \n",
      "    w[170,2]            1 \n",
      "    w[171,3]            1 \n",
      "    w[172,3]            1 \n",
      "    w[173,2]            1 \n",
      "    w[174,3]            1 \n",
      "    w[175,3]            1 \n",
      "    w[176,2]            1 \n",
      "    w[177,3]            1 \n",
      "    w[178,3]            1 \n",
      "    w[179,3]            1 \n",
      "    w[180,2]            1 \n",
      "    w[181,3]            1 \n",
      "    w[182,3]            1 \n",
      "    w[183,2]            1 \n",
      "    w[184,3]            1 \n",
      "    w[185,3]            1 \n",
      "    w[186,2]            1 \n",
      "    w[187,3]            1 \n",
      "    w[188,3]            1 \n",
      "    w[189,3]            1 \n",
      "    w[190,2]            1 \n",
      "    w[191,2]            1 \n",
      "    w[192,2]            1 \n",
      "    w[193,3]            1 \n",
      "    w[194,3]            1 \n",
      "    w[195,3]            1 \n",
      "    w[196,3]            1 \n",
      "    w[197,2]            1 \n",
      "    w[198,2]            1 \n",
      "    w[199,3]            1 \n",
      "    w[200,3]            1 \n",
      "    w[201,3]            1 \n",
      "    w[202,3]            1 \n",
      "    w[203,3]            1 \n",
      "    w[204,2]            1 \n",
      "    w[205,2]            1 \n",
      "    w[206,3]            1 \n",
      "    w[207,3]            1 \n",
      "    w[208,2]            1 \n",
      "    w[209,3]            1 \n",
      "    w[210,2]            1 \n",
      "    w[211,3]            1 \n",
      "    w[212,2]            1 \n",
      "    w[213,2]            1 \n",
      "    w[214,2]            1 \n",
      "    w[215,2]            1 \n",
      "    w[216,3]            1 \n",
      "    w[217,3]            1 \n",
      "    w[218,2]            1 \n",
      "    w[219,3]            1 \n",
      "    w[220,2]            1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    w[221,3]            1 \n",
      "    w[222,2]            1 \n",
      "    w[223,3]            1 \n",
      "    w[224,2]            1 \n",
      "    w[225,3]            1 \n",
      "    w[226,2]            1 \n",
      "    w[227,3]            1 \n",
      "    w[228,2]            1 \n",
      "    w[229,3]            1 \n",
      "    w[230,2]            1 \n",
      "    w[231,3]            1 \n",
      "    w[232,2]            1 \n",
      "    w[233,3]            1 \n",
      "    w[234,3]            1 \n",
      "    w[235,3]            1 \n",
      "    w[236,3]            1 \n",
      "    w[237,3]            1 \n",
      "    w[238,3]            1 \n",
      "    w[239,2]            1 \n",
      "    w[240,2]            1 \n",
      "    w[241,2]            1 \n",
      "    w[242,3]            1 \n",
      "    w[243,2]            1 \n",
      "    w[244,3]            1 \n",
      "    w[245,2]            1 \n",
      "    w[246,3]            1 \n",
      "    w[247,3]            1 \n",
      "    w[248,3]            1 \n",
      "    w[249,3]            1 \n",
      "    w[250,3]            1 \n",
      "    w[251,3]            1 \n",
      "    w[252,3]            1 \n",
      "    w[253,2]            1 \n",
      "    w[254,2]            1 \n",
      "    w[255,3]            1 \n",
      "    w[256,2]            1 \n",
      "    w[257,3]            1 \n",
      "    w[258,3]            1 \n",
      "    w[259,3]            1 \n",
      "    w[260,3]            1 \n",
      "    w[261,3]            1 \n",
      "    w[262,2]            1 \n",
      "    w[263,2]            1 \n",
      "    w[264,3]            1 \n",
      "    w[265,2]            1 \n",
      "    w[266,3]            1 \n",
      "    w[267,3]            1 \n",
      "    w[268,3]            1 \n",
      "    w[269,3]            1 \n",
      "    w[270,3]            1 \n",
      "    w[271,3]            1 \n",
      "    w[272,2]            1 \n",
      "    w[273,2]            1 \n",
      "    w[274,3]            1 \n",
      "    w[275,2]            1 \n",
      "    w[276,3]            1 \n",
      "    w[277,2]            1 \n",
      "    w[278,3]            1 \n",
      "    w[279,3]            1 \n",
      "    w[280,3]            1 \n",
      "    w[281,3]            1 \n",
      "    w[282,2]            1 \n",
      "    w[283,3]            1 \n",
      "    w[284,2]            1 \n",
      "    w[285,3]            1 \n",
      "    w[286,2]            1 \n",
      "    w[287,2]            1 \n",
      "    w[288,3]            1 \n",
      "    w[289,3]            1 \n",
      "    w[290,3]            1 \n",
      "    w[291,2]            1 \n",
      "    w[292,3]            1 \n",
      "    w[293,2]            1 \n",
      "    w[294,2]            1 \n",
      "    w[295,3]            1 \n",
      "    w[296,2]            1 \n",
      "    w[297,2]            1 \n",
      "    w[298,3]            1 \n",
      "    w[299,2]            1 \n",
      "    w[300,3]            1 \n",
      "    w[301,2]            1 \n",
      "    w[302,2]            1 \n",
      "    w[303,3]            1 \n",
      "    w[304,2]            1 \n",
      "    w[305,2]            1 \n",
      "    w[306,3]            1 \n",
      "    w[307,2]            1 \n",
      "    w[308,2]            1 \n",
      "    w[309,2]            1 \n",
      "    w[310,2]            1 \n",
      "    w[311,2]            1 \n",
      "    w[312,2]            1 \n",
      "    w[313,2]            1 \n",
      "    w[314,2]            1 \n",
      "    w[315,2]            1 \n",
      "    w[316,2]            1 \n",
      "    w[317,3]            1 \n",
      "    w[318,3]            1 \n",
      "    w[319,2]            1 \n",
      "    w[320,3]            1 \n",
      "    w[321,2]            1 \n",
      "    w[322,2]            1 \n",
      "    w[323,3]            1 \n",
      "    w[324,3]            1 \n",
      "    w[325,2]            1 \n",
      "    w[326,2]            1 \n",
      "    w[327,2]            1 \n",
      "    w[328,3]            1 \n",
      "    w[329,2]            1 \n",
      "    w[330,2]            1 \n",
      "    w[331,3]            1 \n",
      "    w[332,2]            1 \n",
      "    w[333,3]            1 \n",
      "    w[334,2]            1 \n",
      "    w[335,2]            1 \n",
      "    w[336,3]            1 \n",
      "    w[337,2]            1 \n",
      "    w[338,2]            1 \n",
      "    w[339,2]            1 \n",
      "    w[340,3]            1 \n",
      "    w[341,2]            1 \n",
      "    w[342,2]            1 \n",
      "    w[343,3]            1 \n",
      "    w[344,2]            1 \n",
      "    w[345,3]            1 \n",
      "    w[346,3]            1 \n",
      "    w[347,3]            1 \n",
      "    w[348,2]            1 \n",
      "    w[349,3]            1 \n",
      "    w[350,3]            1 \n",
      "    w[351,2]            1 \n",
      "    w[352,2]            1 \n",
      "    w[353,3]            1 \n",
      "    w[354,2]            1 \n",
      "    w[355,3]            1 \n",
      "    w[356,3]            1 \n",
      "    w[357,3]            1 \n",
      "    w[358,2]            1 \n",
      "    w[359,2]            1 \n",
      "    w[360,3]            1 \n",
      "    w[361,2]            1 \n",
      "    w[362,2]            1 \n",
      "    w[363,3]            1 \n",
      "    w[364,3]            1 \n",
      "    w[365,3]            1 \n",
      "    w[366,3]            1 \n",
      "    w[367,2]            1 \n",
      "    w[368,2]            1 \n",
      "    w[369,3]            1 \n",
      "    w[370,3]            1 \n",
      "    w[371,3]            1 \n",
      "    w[372,3]            1 \n",
      "    w[373,3]            1 \n",
      "    w[374,2]            1 \n",
      "    w[375,2]            1 \n",
      "    w[376,3]            1 \n",
      "    w[377,3]            1 \n",
      "    w[378,3]            1 \n",
      "    w[379,2]            1 \n",
      "    w[380,2]            1 \n",
      "    w[381,3]            1 \n",
      "    w[382,2]            1 \n",
      "    w[383,3]            1 \n",
      "    w[384,3]            1 \n",
      "    w[385,3]            1 \n",
      "    w[386,3]            1 \n",
      "    w[387,2]            1 \n",
      "    w[388,3]            1 \n",
      "    w[389,2]            1 \n",
      "    w[390,3]            1 \n",
      "    w[391,3]            1 \n",
      "    w[392,3]            1 \n",
      "    w[393,3]            1 \n",
      "    w[394,3]            1 \n",
      "    w[395,3]            1 \n",
      "    w[396,3]            1 \n",
      "    w[397,3]            1 \n",
      "    w[398,3]            1 \n",
      "    w[399,3]            1 \n",
      "    w[400,3]            1 \n",
      "    w[401,2]            1 \n",
      "    w[402,3]            1 \n",
      "    w[403,2]            1 \n",
      "    w[404,2]            1 \n",
      "    w[405,2]            1 \n",
      "    w[406,2]            1 \n",
      "    w[407,3]            1 \n",
      "    w[408,3]            1 \n",
      "    w[409,3]            1 \n",
      "    w[410,3]            1 \n",
      "    w[411,3]            1 \n",
      "    w[412,2]            1 \n",
      "    w[413,2]            1 \n",
      "    w[414,2]            1 \n",
      "    w[415,3]            1 \n",
      "    w[416,3]            1 \n",
      "    w[417,3]            1 \n",
      "    w[418,3]            1 \n",
      "    w[419,3]            1 \n",
      "    w[420,3]            1 \n",
      "    w[421,2]            1 \n",
      "    w[422,2]            1 \n",
      "    w[423,3]            1 \n",
      "    w[424,2]            1 \n",
      "    w[425,3]            1 \n",
      "    w[426,2]            1 \n",
      "    w[427,3]            1 \n",
      "    w[428,3]            1 \n",
      "    w[429,2]            1 \n",
      "    w[430,3]            1 \n",
      "    w[431,3]            1 \n",
      "    w[432,2]            1 \n",
      "    w[433,3]            1 \n",
      "    w[434,3]            1 \n",
      "    w[435,2]            1 \n",
      "    w[436,3]            1 \n",
      "    w[437,3]            1 \n",
      "    w[438,2]            1 \n",
      "    w[439,3]            1 \n",
      "    w[440,3]            1 \n",
      "    w[441,3]            1 \n",
      "    w[442,3]            1 \n",
      "    w[443,3]            1 \n",
      "    w[444,2]            1 \n",
      "    w[445,3]            1 \n",
      "    w[446,2]            1 \n",
      "    w[447,2]            1 \n",
      "    w[448,3]            1 \n",
      "    w[449,3]            1 \n",
      "    w[450,3]            1 \n",
      "    w[451,2]            1 \n",
      "    w[452,3]            1 \n",
      "    w[453,3]            1 \n",
      "    w[454,3]            1 \n",
      "    w[455,3]            1 \n",
      "    w[456,2]            1 \n",
      "    w[457,2]            1 \n",
      "    w[458,3]            1 \n",
      "    w[459,2]            1 \n",
      "    w[460,3]            1 \n",
      "    w[461,2]            1 \n",
      "    w[462,3]            1 \n",
      "    w[463,3]            1 \n",
      "    w[464,3]            1 \n",
      "    w[465,3]            1 \n",
      "    w[466,3]            1 \n",
      "    w[467,2]            1 \n",
      "    w[468,3]            1 \n",
      "    w[469,3]            1 \n",
      "    w[470,2]            1 \n",
      "    w[471,2]            1 \n",
      "    w[472,2]            1 \n",
      "    w[473,3]            1 \n",
      "    w[474,3]            1 \n",
      "    w[475,2]            1 \n",
      "    w[476,2]            1 \n",
      "    w[477,2]            1 \n",
      "    w[478,3]            1 \n",
      "    w[479,2]            1 \n",
      "    w[480,3]            1 \n",
      "    w[481,3]            1 \n",
      "    w[482,3]            1 \n",
      "    w[483,3]            1 \n",
      "    w[484,2]            1 \n",
      "    w[485,3]            1 \n",
      "    w[486,3]            1 \n",
      "    w[487,2]            1 \n",
      "    w[488,3]            1 \n",
      "    w[489,3]            1 \n",
      "    w[490,3]            1 \n",
      "    w[491,3]            1 \n",
      "    w[492,3]            1 \n",
      "    w[493,3]            1 \n",
      "    w[494,2]            1 \n",
      "    w[495,2]            1 \n",
      "    w[496,3]            1 \n",
      "    w[497,3]            1 \n",
      "    w[498,3]            1 \n",
      "    w[499,3]            1 \n",
      "       mu[2]     0.551399 \n",
      "       mu[3]     0.479498 \n",
      "     nu[0,2]     0.551399 \n",
      "     nu[1,3]     0.479498 \n",
      "     nu[2,3]     0.479498 \n",
      "     nu[3,3]     0.479498 \n",
      "     nu[4,3]     0.479498 \n",
      "     nu[5,3]     0.479498 \n",
      "     nu[6,3]     0.479498 \n",
      "     nu[7,2]     0.551399 \n",
      "     nu[8,2]     0.551399 \n",
      "     nu[9,3]     0.479498 \n",
      "    nu[10,3]     0.479498 \n",
      "    nu[11,2]     0.551399 \n",
      "    nu[12,2]     0.551399 \n",
      "    nu[13,3]     0.479498 \n",
      "    nu[14,2]     0.551399 \n",
      "    nu[15,3]     0.479498 \n",
      "    nu[16,3]     0.479498 \n",
      "    nu[17,3]     0.479498 \n",
      "    nu[18,3]     0.479498 \n",
      "    nu[19,3]     0.479498 \n",
      "    nu[20,3]     0.479498 \n",
      "    nu[21,2]     0.551399 \n",
      "    nu[22,2]     0.551399 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nu[23,2]     0.551399 \n",
      "    nu[24,2]     0.551399 \n",
      "    nu[25,3]     0.479498 \n",
      "    nu[26,3]     0.479498 \n",
      "    nu[27,2]     0.551399 \n",
      "    nu[28,3]     0.479498 \n",
      "    nu[29,3]     0.479498 \n",
      "    nu[30,2]     0.551399 \n",
      "    nu[31,3]     0.479498 \n",
      "    nu[32,3]     0.479498 \n",
      "    nu[33,3]     0.479498 \n",
      "    nu[34,3]     0.479498 \n",
      "    nu[35,2]     0.551399 \n",
      "    nu[36,2]     0.551399 \n",
      "    nu[37,2]     0.551399 \n",
      "    nu[38,2]     0.551399 \n",
      "    nu[39,2]     0.551399 \n",
      "    nu[40,3]     0.479498 \n",
      "    nu[41,3]     0.479498 \n",
      "    nu[42,3]     0.479498 \n",
      "    nu[43,3]     0.479498 \n",
      "    nu[44,3]     0.479498 \n",
      "    nu[45,3]     0.479498 \n",
      "    nu[46,3]     0.479498 \n",
      "    nu[47,3]     0.479498 \n",
      "    nu[48,3]     0.479498 \n",
      "    nu[49,3]     0.479498 \n",
      "    nu[50,2]     0.551399 \n",
      "    nu[51,3]     0.479498 \n",
      "    nu[52,2]     0.551399 \n",
      "    nu[53,3]     0.479498 \n",
      "    nu[54,2]     0.551399 \n",
      "    nu[55,2]     0.551399 \n",
      "    nu[56,3]     0.479498 \n",
      "    nu[57,3]     0.479498 \n",
      "    nu[58,3]     0.479498 \n",
      "    nu[59,3]     0.479498 \n",
      "    nu[60,2]     0.551399 \n",
      "    nu[61,3]     0.479498 \n",
      "    nu[62,2]     0.551399 \n",
      "    nu[63,3]     0.479498 \n",
      "    nu[64,3]     0.479498 \n",
      "    nu[65,3]     0.479498 \n",
      "    nu[66,3]     0.479498 \n",
      "    nu[67,3]     0.479498 \n",
      "    nu[68,2]     0.551399 \n",
      "    nu[69,3]     0.479498 \n",
      "    nu[70,3]     0.479498 \n",
      "    nu[71,2]     0.551399 \n",
      "    nu[72,2]     0.551399 \n",
      "    nu[73,3]     0.479498 \n",
      "    nu[74,3]     0.479498 \n",
      "    nu[75,2]     0.551399 \n",
      "    nu[76,3]     0.479498 \n",
      "    nu[77,2]     0.551399 \n",
      "    nu[78,3]     0.479498 \n",
      "    nu[79,3]     0.479498 \n",
      "    nu[80,3]     0.479498 \n",
      "    nu[81,3]     0.479498 \n",
      "    nu[82,3]     0.479498 \n",
      "    nu[83,2]     0.551399 \n",
      "    nu[84,3]     0.479498 \n",
      "    nu[85,3]     0.479498 \n",
      "    nu[86,2]     0.551399 \n",
      "    nu[87,2]     0.551399 \n",
      "    nu[88,3]     0.479498 \n",
      "    nu[89,2]     0.551399 \n",
      "    nu[90,2]     0.551399 \n",
      "    nu[91,2]     0.551399 \n",
      "    nu[92,3]     0.479498 \n",
      "    nu[93,3]     0.479498 \n",
      "    nu[94,2]     0.551399 \n",
      "    nu[95,2]     0.551399 \n",
      "    nu[96,2]     0.551399 \n",
      "    nu[97,3]     0.479498 \n",
      "    nu[98,2]     0.551399 \n",
      "    nu[99,3]     0.479498 \n",
      "   nu[100,3]     0.479498 \n",
      "   nu[101,3]     0.479498 \n",
      "   nu[102,2]     0.551399 \n",
      "   nu[103,2]     0.551399 \n",
      "   nu[104,3]     0.479498 \n",
      "   nu[105,3]     0.479498 \n",
      "   nu[106,2]     0.551399 \n",
      "   nu[107,3]     0.479498 \n",
      "   nu[108,2]     0.551399 \n",
      "   nu[109,3]     0.479498 \n",
      "   nu[110,2]     0.551399 \n",
      "   nu[111,3]     0.479498 \n",
      "   nu[112,3]     0.479498 \n",
      "   nu[113,2]     0.551399 \n",
      "   nu[114,2]     0.551399 \n",
      "   nu[115,3]     0.479498 \n",
      "   nu[116,3]     0.479498 \n",
      "   nu[117,3]     0.479498 \n",
      "   nu[118,3]     0.479498 \n",
      "   nu[119,2]     0.551399 \n",
      "   nu[120,3]     0.479498 \n",
      "   nu[121,2]     0.551399 \n",
      "   nu[122,3]     0.479498 \n",
      "   nu[123,3]     0.479498 \n",
      "   nu[124,3]     0.479498 \n",
      "   nu[125,3]     0.479498 \n",
      "   nu[126,2]     0.551399 \n",
      "   nu[127,2]     0.551399 \n",
      "   nu[128,3]     0.479498 \n",
      "   nu[129,2]     0.551399 \n",
      "   nu[130,2]     0.551399 \n",
      "   nu[131,2]     0.551399 \n",
      "   nu[132,3]     0.479498 \n",
      "   nu[133,2]     0.551399 \n",
      "   nu[134,3]     0.479498 \n",
      "   nu[135,3]     0.479498 \n",
      "   nu[136,2]     0.551399 \n",
      "   nu[137,3]     0.479498 \n",
      "   nu[138,3]     0.479498 \n",
      "   nu[139,2]     0.551399 \n",
      "   nu[140,3]     0.479498 \n",
      "   nu[141,3]     0.479498 \n",
      "   nu[142,2]     0.551399 \n",
      "   nu[143,2]     0.551399 \n",
      "   nu[144,3]     0.479498 \n",
      "   nu[145,2]     0.551399 \n",
      "   nu[146,2]     0.551399 \n",
      "   nu[147,2]     0.551399 \n",
      "   nu[148,3]     0.479498 \n",
      "   nu[149,3]     0.479498 \n",
      "   nu[150,2]     0.551399 \n",
      "   nu[151,3]     0.479498 \n",
      "   nu[152,3]     0.479498 \n",
      "   nu[153,3]     0.479498 \n",
      "   nu[154,3]     0.479498 \n",
      "   nu[155,3]     0.479498 \n",
      "   nu[156,3]     0.479498 \n",
      "   nu[157,2]     0.551399 \n",
      "   nu[158,2]     0.551399 \n",
      "   nu[159,2]     0.551399 \n",
      "   nu[160,2]     0.551399 \n",
      "   nu[161,2]     0.551399 \n",
      "   nu[162,3]     0.479498 \n",
      "   nu[163,3]     0.479498 \n",
      "   nu[164,3]     0.479498 \n",
      "   nu[165,3]     0.479498 \n",
      "   nu[166,2]     0.551399 \n",
      "   nu[167,3]     0.479498 \n",
      "   nu[168,2]     0.551399 \n",
      "   nu[169,3]     0.479498 \n",
      "   nu[170,2]     0.551399 \n",
      "   nu[171,3]     0.479498 \n",
      "   nu[172,3]     0.479498 \n",
      "   nu[173,2]     0.551399 \n",
      "   nu[174,3]     0.479498 \n",
      "   nu[175,3]     0.479498 \n",
      "   nu[176,2]     0.551399 \n",
      "   nu[177,3]     0.479498 \n",
      "   nu[178,3]     0.479498 \n",
      "   nu[179,3]     0.479498 \n",
      "   nu[180,2]     0.551399 \n",
      "   nu[181,3]     0.479498 \n",
      "   nu[182,3]     0.479498 \n",
      "   nu[183,2]     0.551399 \n",
      "   nu[184,3]     0.479498 \n",
      "   nu[185,3]     0.479498 \n",
      "   nu[186,2]     0.551399 \n",
      "   nu[187,3]     0.479498 \n",
      "   nu[188,3]     0.479498 \n",
      "   nu[189,3]     0.479498 \n",
      "   nu[190,2]     0.551399 \n",
      "   nu[191,2]     0.551399 \n",
      "   nu[192,2]     0.551399 \n",
      "   nu[193,3]     0.479498 \n",
      "   nu[194,3]     0.479498 \n",
      "   nu[195,3]     0.479498 \n",
      "   nu[196,3]     0.479498 \n",
      "   nu[197,2]     0.551399 \n",
      "   nu[198,2]     0.551399 \n",
      "   nu[199,3]     0.479498 \n",
      "   nu[200,3]     0.479498 \n",
      "   nu[201,3]     0.479498 \n",
      "   nu[202,3]     0.479498 \n",
      "   nu[203,3]     0.479498 \n",
      "   nu[204,2]     0.551399 \n",
      "   nu[205,2]     0.551399 \n",
      "   nu[206,3]     0.479498 \n",
      "   nu[207,3]     0.479498 \n",
      "   nu[208,2]     0.551399 \n",
      "   nu[209,3]     0.479498 \n",
      "   nu[210,2]     0.551399 \n",
      "   nu[211,3]     0.479498 \n",
      "   nu[212,2]     0.551399 \n",
      "   nu[213,2]     0.551399 \n",
      "   nu[214,2]     0.551399 \n",
      "   nu[215,2]     0.551399 \n",
      "   nu[216,3]     0.479498 \n",
      "   nu[217,3]     0.479498 \n",
      "   nu[218,2]     0.551399 \n",
      "   nu[219,3]     0.479498 \n",
      "   nu[220,2]     0.551399 \n",
      "   nu[221,3]     0.479498 \n",
      "   nu[222,2]     0.551399 \n",
      "   nu[223,3]     0.479498 \n",
      "   nu[224,2]     0.551399 \n",
      "   nu[225,3]     0.479498 \n",
      "   nu[226,2]     0.551399 \n",
      "   nu[227,3]     0.479498 \n",
      "   nu[228,2]     0.551399 \n",
      "   nu[229,3]     0.479498 \n",
      "   nu[230,2]     0.551399 \n",
      "   nu[231,3]     0.479498 \n",
      "   nu[232,2]     0.551399 \n",
      "   nu[233,3]     0.479498 \n",
      "   nu[234,3]     0.479498 \n",
      "   nu[235,3]     0.479498 \n",
      "   nu[236,3]     0.479498 \n",
      "   nu[237,3]     0.479498 \n",
      "   nu[238,3]     0.479498 \n",
      "   nu[239,2]     0.551399 \n",
      "   nu[240,2]     0.551399 \n",
      "   nu[241,2]     0.551399 \n",
      "   nu[242,3]     0.479498 \n",
      "   nu[243,2]     0.551399 \n",
      "   nu[244,3]     0.479498 \n",
      "   nu[245,2]     0.551399 \n",
      "   nu[246,3]     0.479498 \n",
      "   nu[247,3]     0.479498 \n",
      "   nu[248,3]     0.479498 \n",
      "   nu[249,3]     0.479498 \n",
      "   nu[250,3]     0.479498 \n",
      "   nu[251,3]     0.479498 \n",
      "   nu[252,3]     0.479498 \n",
      "   nu[253,2]     0.551399 \n",
      "   nu[254,2]     0.551399 \n",
      "   nu[255,3]     0.479498 \n",
      "   nu[256,2]     0.551399 \n",
      "   nu[257,3]     0.479498 \n",
      "   nu[258,3]     0.479498 \n",
      "   nu[259,3]     0.479498 \n",
      "   nu[260,3]     0.479498 \n",
      "   nu[261,3]     0.479498 \n",
      "   nu[262,2]     0.551399 \n",
      "   nu[263,2]     0.551399 \n",
      "   nu[264,3]     0.479498 \n",
      "   nu[265,2]     0.551399 \n",
      "   nu[266,3]     0.479498 \n",
      "   nu[267,3]     0.479498 \n",
      "   nu[268,3]     0.479498 \n",
      "   nu[269,3]     0.479498 \n",
      "   nu[270,3]     0.479498 \n",
      "   nu[271,3]     0.479498 \n",
      "   nu[272,2]     0.551399 \n",
      "   nu[273,2]     0.551399 \n",
      "   nu[274,3]     0.479498 \n",
      "   nu[275,2]     0.551399 \n",
      "   nu[276,3]     0.479498 \n",
      "   nu[277,2]     0.551399 \n",
      "   nu[278,3]     0.479498 \n",
      "   nu[279,3]     0.479498 \n",
      "   nu[280,3]     0.479498 \n",
      "   nu[281,3]     0.479498 \n",
      "   nu[282,2]     0.551399 \n",
      "   nu[283,3]     0.479498 \n",
      "   nu[284,2]     0.551399 \n",
      "   nu[285,3]     0.479498 \n",
      "   nu[286,2]     0.551399 \n",
      "   nu[287,2]     0.551399 \n",
      "   nu[288,3]     0.479498 \n",
      "   nu[289,3]     0.479498 \n",
      "   nu[290,3]     0.479498 \n",
      "   nu[291,2]     0.551399 \n",
      "   nu[292,3]     0.479498 \n",
      "   nu[293,2]     0.551399 \n",
      "   nu[294,2]     0.551399 \n",
      "   nu[295,3]     0.479498 \n",
      "   nu[296,2]     0.551399 \n",
      "   nu[297,2]     0.551399 \n",
      "   nu[298,3]     0.479498 \n",
      "   nu[299,2]     0.551399 \n",
      "   nu[300,3]     0.479498 \n",
      "   nu[301,2]     0.551399 \n",
      "   nu[302,2]     0.551399 \n",
      "   nu[303,3]     0.479498 \n",
      "   nu[304,2]     0.551399 \n",
      "   nu[305,2]     0.551399 \n",
      "   nu[306,3]     0.479498 \n",
      "   nu[307,2]     0.551399 \n",
      "   nu[308,2]     0.551399 \n",
      "   nu[309,2]     0.551399 \n",
      "   nu[310,2]     0.551399 \n",
      "   nu[311,2]     0.551399 \n",
      "   nu[312,2]     0.551399 \n",
      "   nu[313,2]     0.551399 \n",
      "   nu[314,2]     0.551399 \n",
      "   nu[315,2]     0.551399 \n",
      "   nu[316,2]     0.551399 \n",
      "   nu[317,3]     0.479498 \n",
      "   nu[318,3]     0.479498 \n",
      "   nu[319,2]     0.551399 \n",
      "   nu[320,3]     0.479498 \n",
      "   nu[321,2]     0.551399 \n",
      "   nu[322,2]     0.551399 \n",
      "   nu[323,3]     0.479498 \n",
      "   nu[324,3]     0.479498 \n",
      "   nu[325,2]     0.551399 \n",
      "   nu[326,2]     0.551399 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nu[327,2]     0.551399 \n",
      "   nu[328,3]     0.479498 \n",
      "   nu[329,2]     0.551399 \n",
      "   nu[330,2]     0.551399 \n",
      "   nu[331,3]     0.479498 \n",
      "   nu[332,2]     0.551399 \n",
      "   nu[333,3]     0.479498 \n",
      "   nu[334,2]     0.551399 \n",
      "   nu[335,2]     0.551399 \n",
      "   nu[336,3]     0.479498 \n",
      "   nu[337,2]     0.551399 \n",
      "   nu[338,2]     0.551399 \n",
      "   nu[339,2]     0.551399 \n",
      "   nu[340,3]     0.479498 \n",
      "   nu[341,2]     0.551399 \n",
      "   nu[342,2]     0.551399 \n",
      "   nu[343,3]     0.479498 \n",
      "   nu[344,2]     0.551399 \n",
      "   nu[345,3]     0.479498 \n",
      "   nu[346,3]     0.479498 \n",
      "   nu[347,3]     0.479498 \n",
      "   nu[348,2]     0.551399 \n",
      "   nu[349,3]     0.479498 \n",
      "   nu[350,3]     0.479498 \n",
      "   nu[351,2]     0.551399 \n",
      "   nu[352,2]     0.551399 \n",
      "   nu[353,3]     0.479498 \n",
      "   nu[354,2]     0.551399 \n",
      "   nu[355,3]     0.479498 \n",
      "   nu[356,3]     0.479498 \n",
      "   nu[357,3]     0.479498 \n",
      "   nu[358,2]     0.551399 \n",
      "   nu[359,2]     0.551399 \n",
      "   nu[360,3]     0.479498 \n",
      "   nu[361,2]     0.551399 \n",
      "   nu[362,2]     0.551399 \n",
      "   nu[363,3]     0.479498 \n",
      "   nu[364,3]     0.479498 \n",
      "   nu[365,3]     0.479498 \n",
      "   nu[366,3]     0.479498 \n",
      "   nu[367,2]     0.551399 \n",
      "   nu[368,2]     0.551399 \n",
      "   nu[369,3]     0.479498 \n",
      "   nu[370,3]     0.479498 \n",
      "   nu[371,3]     0.479498 \n",
      "   nu[372,3]     0.479498 \n",
      "   nu[373,3]     0.479498 \n",
      "   nu[374,2]     0.551399 \n",
      "   nu[375,2]     0.551399 \n",
      "   nu[376,3]     0.479498 \n",
      "   nu[377,3]     0.479498 \n",
      "   nu[378,3]     0.479498 \n",
      "   nu[379,2]     0.551399 \n",
      "   nu[380,2]     0.551399 \n",
      "   nu[381,3]     0.479498 \n",
      "   nu[382,2]     0.551399 \n",
      "   nu[383,3]     0.479498 \n",
      "   nu[384,3]     0.479498 \n",
      "   nu[385,3]     0.479498 \n",
      "   nu[386,3]     0.479498 \n",
      "   nu[387,2]     0.551399 \n",
      "   nu[388,3]     0.479498 \n",
      "   nu[389,2]     0.551399 \n",
      "   nu[390,3]     0.479498 \n",
      "   nu[391,3]     0.479498 \n",
      "   nu[392,3]     0.479498 \n",
      "   nu[393,3]     0.479498 \n",
      "   nu[394,3]     0.479498 \n",
      "   nu[395,3]     0.479498 \n",
      "   nu[396,3]     0.479498 \n",
      "   nu[397,3]     0.479498 \n",
      "   nu[398,3]     0.479498 \n",
      "   nu[399,3]     0.479498 \n",
      "   nu[400,3]     0.479498 \n",
      "   nu[401,2]     0.551399 \n",
      "   nu[402,3]     0.479498 \n",
      "   nu[403,2]     0.551399 \n",
      "   nu[404,2]     0.551399 \n",
      "   nu[405,2]     0.551399 \n",
      "   nu[406,2]     0.551399 \n",
      "   nu[407,3]     0.479498 \n",
      "   nu[408,3]     0.479498 \n",
      "   nu[409,3]     0.479498 \n",
      "   nu[410,3]     0.479498 \n",
      "   nu[411,3]     0.479498 \n",
      "   nu[412,2]     0.551399 \n",
      "   nu[413,2]     0.551399 \n",
      "   nu[414,2]     0.551399 \n",
      "   nu[415,3]     0.479498 \n",
      "   nu[416,3]     0.479498 \n",
      "   nu[417,3]     0.479498 \n",
      "   nu[418,3]     0.479498 \n",
      "   nu[419,3]     0.479498 \n",
      "   nu[420,3]     0.479498 \n",
      "   nu[421,2]     0.551399 \n",
      "   nu[422,2]     0.551399 \n",
      "   nu[423,3]     0.479498 \n",
      "   nu[424,2]     0.551399 \n",
      "   nu[425,3]     0.479498 \n",
      "   nu[426,2]     0.551399 \n",
      "   nu[427,3]     0.479498 \n",
      "   nu[428,3]     0.479498 \n",
      "   nu[429,2]     0.551399 \n",
      "   nu[430,3]     0.479498 \n",
      "   nu[431,3]     0.479498 \n",
      "   nu[432,2]     0.551399 \n",
      "   nu[433,3]     0.479498 \n",
      "   nu[434,3]     0.479498 \n",
      "   nu[435,2]     0.551399 \n",
      "   nu[436,3]     0.479498 \n",
      "   nu[437,3]     0.479498 \n",
      "   nu[438,2]     0.551399 \n",
      "   nu[439,3]     0.479498 \n",
      "   nu[440,3]     0.479498 \n",
      "   nu[441,3]     0.479498 \n",
      "   nu[442,3]     0.479498 \n",
      "   nu[443,3]     0.479498 \n",
      "   nu[444,2]     0.551399 \n",
      "   nu[445,3]     0.479498 \n",
      "   nu[446,2]     0.551399 \n",
      "   nu[447,2]     0.551399 \n",
      "   nu[448,3]     0.479498 \n",
      "   nu[449,3]     0.479498 \n",
      "   nu[450,3]     0.479498 \n",
      "   nu[451,2]     0.551399 \n",
      "   nu[452,3]     0.479498 \n",
      "   nu[453,3]     0.479498 \n",
      "   nu[454,3]     0.479498 \n",
      "   nu[455,3]     0.479498 \n",
      "   nu[456,2]     0.551399 \n",
      "   nu[457,2]     0.551399 \n",
      "   nu[458,3]     0.479498 \n",
      "   nu[459,2]     0.551399 \n",
      "   nu[460,3]     0.479498 \n",
      "   nu[461,2]     0.551399 \n",
      "   nu[462,3]     0.479498 \n",
      "   nu[463,3]     0.479498 \n",
      "   nu[464,3]     0.479498 \n",
      "   nu[465,3]     0.479498 \n",
      "   nu[466,3]     0.479498 \n",
      "   nu[467,2]     0.551399 \n",
      "   nu[468,3]     0.479498 \n",
      "   nu[469,3]     0.479498 \n",
      "   nu[470,2]     0.551399 \n",
      "   nu[471,2]     0.551399 \n",
      "   nu[472,2]     0.551399 \n",
      "   nu[473,3]     0.479498 \n",
      "   nu[474,3]     0.479498 \n",
      "   nu[475,2]     0.551399 \n",
      "   nu[476,2]     0.551399 \n",
      "   nu[477,2]     0.551399 \n",
      "   nu[478,3]     0.479498 \n",
      "   nu[479,2]     0.551399 \n",
      "   nu[480,3]     0.479498 \n",
      "   nu[481,3]     0.479498 \n",
      "   nu[482,3]     0.479498 \n",
      "   nu[483,3]     0.479498 \n",
      "   nu[484,2]     0.551399 \n",
      "   nu[485,3]     0.479498 \n",
      "   nu[486,3]     0.479498 \n",
      "   nu[487,2]     0.551399 \n",
      "   nu[488,3]     0.479498 \n",
      "   nu[489,3]     0.479498 \n",
      "   nu[490,3]     0.479498 \n",
      "   nu[491,3]     0.479498 \n",
      "   nu[492,3]     0.479498 \n",
      "   nu[493,3]     0.479498 \n",
      "   nu[494,2]     0.551399 \n",
      "   nu[495,2]     0.551399 \n",
      "   nu[496,3]     0.479498 \n",
      "   nu[497,3]     0.479498 \n",
      "   nu[498,3]     0.479498 \n",
      "   nu[499,3]     0.479498 \n",
      "    chi[1,0]            1 \n",
      "    chi[1,7]            1 \n",
      "    chi[1,8]            1 \n",
      "   chi[1,11]            1 \n",
      "   chi[1,12]            1 \n",
      "   chi[1,14]            1 \n",
      "   chi[1,21]            1 \n",
      "   chi[1,22]            1 \n",
      "   chi[1,23]            1 \n",
      "   chi[1,24]            1 \n",
      "   chi[1,27]            1 \n",
      "   chi[1,30]            1 \n",
      "   chi[1,35]            1 \n",
      "   chi[1,36]            1 \n",
      "   chi[1,37]            1 \n",
      "   chi[1,38]            1 \n",
      "   chi[1,39]            1 \n",
      "   chi[1,50]            1 \n",
      "   chi[1,52]            1 \n",
      "   chi[1,54]            1 \n",
      "   chi[1,55]            1 \n",
      "   chi[1,60]            1 \n",
      "   chi[1,62]            1 \n",
      "   chi[1,68]            1 \n",
      "   chi[1,71]            1 \n",
      "   chi[1,72]            1 \n",
      "   chi[1,75]            1 \n",
      "   chi[1,77]            1 \n",
      "   chi[1,83]            1 \n",
      "   chi[1,86]            1 \n",
      "   chi[1,87]            1 \n",
      "   chi[1,89]            1 \n",
      "   chi[1,90]            1 \n",
      "   chi[1,91]            1 \n",
      "   chi[1,94]            1 \n",
      "   chi[1,95]            1 \n",
      "   chi[1,96]            1 \n",
      "   chi[1,98]            1 \n",
      "  chi[1,102]            1 \n",
      "  chi[1,103]            1 \n",
      "  chi[1,106]            1 \n",
      "  chi[1,108]            1 \n",
      "  chi[1,110]            1 \n",
      "  chi[1,113]            1 \n",
      "  chi[1,114]            1 \n",
      "  chi[1,119]            1 \n",
      "  chi[1,121]            1 \n",
      "  chi[1,126]            1 \n",
      "  chi[1,127]            1 \n",
      "  chi[1,129]            1 \n",
      "  chi[1,130]            1 \n",
      "  chi[1,131]            1 \n",
      "  chi[1,133]            1 \n",
      "  chi[1,136]            1 \n",
      "  chi[1,139]            1 \n",
      "  chi[1,142]            1 \n",
      "  chi[1,143]            1 \n",
      "  chi[1,145]            1 \n",
      "  chi[1,146]            1 \n",
      "  chi[1,147]            1 \n",
      "  chi[1,150]            1 \n",
      "  chi[1,157]            1 \n",
      "  chi[1,158]            1 \n",
      "  chi[1,159]            1 \n",
      "  chi[1,160]            1 \n",
      "  chi[1,161]            1 \n",
      "  chi[1,166]            1 \n",
      "  chi[1,168]            1 \n",
      "  chi[1,170]            1 \n",
      "  chi[1,173]            1 \n",
      "  chi[1,176]            1 \n",
      "  chi[1,180]            1 \n",
      "  chi[1,183]            1 \n",
      "  chi[1,186]            1 \n",
      "  chi[1,190]            1 \n",
      "  chi[1,191]            1 \n",
      "  chi[1,192]            1 \n",
      "  chi[1,197]            1 \n",
      "  chi[1,198]            1 \n",
      "  chi[1,204]            1 \n",
      "  chi[1,205]            1 \n",
      "  chi[1,208]            1 \n",
      "  chi[1,210]            1 \n",
      "  chi[1,212]            1 \n",
      "  chi[1,213]            1 \n",
      "  chi[1,214]            1 \n",
      "  chi[1,215]            1 \n",
      "  chi[1,218]            1 \n",
      "  chi[1,220]            1 \n",
      "  chi[1,222]            1 \n",
      "  chi[1,224]            1 \n",
      "  chi[1,226]            1 \n",
      "  chi[1,228]            1 \n",
      "  chi[1,230]            1 \n",
      "  chi[1,232]            1 \n",
      "  chi[1,239]            1 \n",
      "  chi[1,240]            1 \n",
      "  chi[1,241]            1 \n",
      "  chi[1,243]            1 \n",
      "  chi[1,245]            1 \n",
      "  chi[1,253]            1 \n",
      "  chi[1,254]            1 \n",
      "  chi[1,256]            1 \n",
      "  chi[1,262]            1 \n",
      "  chi[1,263]            1 \n",
      "  chi[1,265]            1 \n",
      "  chi[1,272]            1 \n",
      "  chi[1,273]            1 \n",
      "  chi[1,275]            1 \n",
      "  chi[1,277]            1 \n",
      "  chi[1,282]            1 \n",
      "  chi[1,284]            1 \n",
      "  chi[1,286]            1 \n",
      "  chi[1,287]            1 \n",
      "  chi[1,291]            1 \n",
      "  chi[1,293]            1 \n",
      "  chi[1,294]            1 \n",
      "  chi[1,296]            1 \n",
      "  chi[1,297]            1 \n",
      "  chi[1,299]            1 \n",
      "  chi[1,301]            1 \n",
      "  chi[1,302]            1 \n",
      "  chi[1,304]            1 \n",
      "  chi[1,305]            1 \n",
      "  chi[1,307]            1 \n",
      "  chi[1,308]            1 \n",
      "  chi[1,309]            1 \n",
      "  chi[1,310]            1 \n",
      "  chi[1,311]            1 \n",
      "  chi[1,312]            1 \n",
      "  chi[1,313]            1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chi[1,314]            1 \n",
      "  chi[1,315]            1 \n",
      "  chi[1,316]            1 \n",
      "  chi[1,319]            1 \n",
      "  chi[1,321]            1 \n",
      "  chi[1,322]            1 \n",
      "  chi[1,325]            1 \n",
      "  chi[1,326]            1 \n",
      "  chi[1,327]            1 \n",
      "  chi[1,329]            1 \n",
      "  chi[1,330]            1 \n",
      "  chi[1,332]            1 \n",
      "  chi[1,334]            1 \n",
      "  chi[1,335]            1 \n",
      "  chi[1,337]            1 \n",
      "  chi[1,338]            1 \n",
      "  chi[1,339]            1 \n",
      "  chi[1,341]            1 \n",
      "  chi[1,342]            1 \n",
      "  chi[1,344]            1 \n",
      "  chi[1,348]            1 \n",
      "  chi[1,351]            1 \n",
      "  chi[1,352]            1 \n",
      "  chi[1,354]            1 \n",
      "  chi[1,358]            1 \n",
      "  chi[1,359]            1 \n",
      "  chi[1,361]            1 \n",
      "  chi[1,362]            1 \n",
      "  chi[1,367]            1 \n",
      "  chi[1,368]            1 \n",
      "  chi[1,374]            1 \n",
      "  chi[1,375]            1 \n",
      "  chi[1,379]            1 \n",
      "  chi[1,380]            1 \n",
      "  chi[1,382]            1 \n",
      "  chi[1,387]            1 \n",
      "  chi[1,389]            1 \n",
      "  chi[1,401]            1 \n",
      "  chi[1,403]            1 \n",
      "  chi[1,404]            1 \n",
      "  chi[1,405]            1 \n",
      "  chi[1,406]            1 \n",
      "  chi[1,412]            1 \n",
      "  chi[1,413]            1 \n",
      "  chi[1,414]            1 \n",
      "  chi[1,421]            1 \n",
      "  chi[1,422]            1 \n",
      "  chi[1,424]            1 \n",
      "  chi[1,426]            1 \n",
      "  chi[1,429]            1 \n",
      "  chi[1,432]            1 \n",
      "  chi[1,435]            1 \n",
      "  chi[1,438]            1 \n",
      "  chi[1,444]            1 \n",
      "  chi[1,446]            1 \n",
      "  chi[1,447]            1 \n",
      "  chi[1,451]            1 \n",
      "  chi[1,456]            1 \n",
      "  chi[1,457]            1 \n",
      "  chi[1,459]            1 \n",
      "  chi[1,461]            1 \n",
      "  chi[1,467]            1 \n",
      "  chi[1,470]            1 \n",
      "  chi[1,471]            1 \n",
      "  chi[1,472]            1 \n",
      "  chi[1,475]            1 \n",
      "  chi[1,476]            1 \n",
      "  chi[1,477]            1 \n",
      "  chi[1,479]            1 \n",
      "  chi[1,484]            1 \n",
      "  chi[1,487]            1 \n",
      "  chi[1,494]            1 \n",
      "  chi[1,495]            1 \n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "prob = 0.5\n",
    "dataset = 3\n",
    "bert = False\n",
    "\n",
    "train_filepath = 'data/data_train_enc_' + str(prob) + '_' + str(dataset) + '.csv'\n",
    "test_filepath = 'data/data_test_enc_' + str(prob) + '_' + str(dataset) + '.csv'\n",
    "train_X, train_t, train_y, train_real = open_file(train_filepath)\n",
    "run_tree(d, bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if d == 2:\n",
    "    branching = {1: 16}\n",
    "    treatments = {2: 1, 3: 1}\n",
    "elif d == 3:\n",
    "    branching = {1: 10, 2: 16, 3: 0}\n",
    "    treatments = {4: 1, 5: 1, 6: 1, 7: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267.9863312540136 0.4446 0.5066\n",
      "21.252969854711775 0.354 0.5\n"
     ]
    }
   ],
   "source": [
    "tree = Tree(d)\n",
    "L = set(range(2**(d-1), 2**d))\n",
    "test_X, test_t, test_y, test_real = open_file(test_filepath)\n",
    "error, pct, acc = get_metrics(test_X, test_real, test_t)\n",
    "error1, pct1, acc1 = get_metrics(train_X, train_real, train_t)\n",
    "print(error, pct, acc)\n",
    "print(error1, pct1, acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 0.9, 267.9863312540136, 44.46, 50.660000000000004, 21.252969854711775, 35.4, 50.0, 'branching = {1: 10, 2: 16, 3: 0}, treatments = {4: 1, 5: 1, 6: 1, 7: 1}']\n"
     ]
    }
   ],
   "source": [
    "tree_stats = 'branching = ' + str(branching) + ', treatments = ' + str(treatments)\n",
    "row = [dataset, d, prob, error, pct*100, acc*100, error1, pct1*100, acc1*100, tree_stats]\n",
    "print(row)\n",
    "if bert:\n",
    "    bertsimas.loc[len(bertsimas)] = row\n",
    "else:\n",
    "    kallus.loc[len(kallus)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset  Depth  P(Correct Treatment)  Test Error  Test % Optimal  \\\n",
      "0         1      2                   0.5   53.227602           76.83   \n",
      "1         1      3                   0.5  123.833930           66.00   \n",
      "2         1      3                   0.5  123.833930           66.00   \n",
      "3         2      2                   0.5   24.915258           84.31   \n",
      "4         2      3                   0.5   24.915258           84.31   \n",
      "5         3      2                   0.5  166.280038           58.61   \n",
      "6         3      3                   0.5   57.544135           77.50   \n",
      "7         4      2                   0.5  432.810829           24.05   \n",
      "8         4      3                   0.5  231.607156           44.69   \n",
      "9         5      2                   0.5  189.645268           55.55   \n",
      "10        5      3                   0.5   36.072978           82.59   \n",
      "11        1      2                   0.9  224.473595           49.78   \n",
      "12        1      3                   0.9  224.473595           49.78   \n",
      "13        2      2                   0.9  216.993310           50.34   \n",
      "14        2      3                   0.9  216.993310           50.34   \n",
      "15        3      2                   0.9  279.888354           41.39   \n",
      "16        3      3                   0.9  290.892989           40.41   \n",
      "17        4      2                   0.9   75.234129           75.97   \n",
      "18        4      3                   0.9   75.234129           75.97   \n",
      "19        5      2                   0.9  267.986331           44.46   \n",
      "20        5      3                   0.9  267.986331           44.46   \n",
      "\n",
      "    Test % Same Treatment  Train Error  Train % Optimal  \\\n",
      "0                   49.33     1.833834             83.0   \n",
      "1                   49.34     2.356756             85.2   \n",
      "2                   49.34     2.356756             85.2   \n",
      "3                   50.46     1.220292             87.8   \n",
      "4                   50.46     1.220292             87.8   \n",
      "5                   49.19     5.115352             75.0   \n",
      "6                   49.48     2.759458             81.4   \n",
      "7                   50.07     2.819187             83.8   \n",
      "8                   50.66     0.674055             91.8   \n",
      "9                   49.63     8.600535             64.8   \n",
      "10                  48.97     0.969443             87.0   \n",
      "11                  50.18     5.508442             73.6   \n",
      "12                  50.18     5.508442             73.6   \n",
      "13                  50.72    15.210286             48.6   \n",
      "14                  50.72    15.210286             48.6   \n",
      "15                  50.68    31.611031             25.0   \n",
      "16                  49.90    31.992727             24.2   \n",
      "17                  49.97    32.501338             16.6   \n",
      "18                  49.97    32.501338             16.6   \n",
      "19                  50.66    21.252970             35.4   \n",
      "20                  50.66    21.252970             35.4   \n",
      "\n",
      "    Train % Same Treatment                                               Tree  \n",
      "0                     51.4      branching = {1: 2}, treatments = {2: 1, 3: 0}  \n",
      "1                     51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "2                     51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "3                     49.6      branching = {1: 3}, treatments = {2: 1, 3: 0}  \n",
      "4                     49.6  branching = {1: 3, 2: 13, 3: 15}, treatments =...  \n",
      "5                     48.6     branching = {1: 12}, treatments = {2: 0, 3: 0}  \n",
      "6                     46.6  branching = {1: 5, 2: 14, 3: 12}, treatments =...  \n",
      "7                     52.6     branching = {1: 13}, treatments = {2: 0, 3: 0}  \n",
      "8                     48.0  branching = {1: 7, 2: 10, 3: 13}, treatments =...  \n",
      "9                     51.0     branching = {1: 15}, treatments = {2: 0, 3: 0}  \n",
      "10                    49.2  branching = {1: 15, 2: 7, 3: 5}, treatments = ...  \n",
      "11                    48.4     branching = {1: 15}, treatments = {2: 1, 3: 1}  \n",
      "12                    48.4  branching = {1: 10, 2: 15, 3: 0}, treatments =...  \n",
      "13                    51.2     branching = {1: 14}, treatments = {2: 1, 3: 1}  \n",
      "14                    51.2  branching = {1: 16, 2: 0, 3: 11}, treatments =...  \n",
      "15                    49.4     branching = {1: 15}, treatments = {2: 1, 3: 1}  \n",
      "16                    48.6  branching = {1: 10, 2: 16, 3: 8}, treatments =...  \n",
      "17                    50.0     branching = {1: 14}, treatments = {2: 1, 3: 1}  \n",
      "18                    50.0  branching = {1: 16, 2: 0, 3: 14}, treatments =...  \n",
      "19                    50.0     branching = {1: 16}, treatments = {2: 1, 3: 1}  \n",
      "20                    50.0  branching = {1: 10, 2: 16, 3: 0}, treatments =...  \n"
     ]
    }
   ],
   "source": [
    "print(bertsimas)\n",
    "bertsimas.to_csv('bertsimas_athey_500.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Performance for Athey's Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY: KALLUS on Athey\n",
    "summary = {'Method': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5', 'Dataset 1', \n",
    "                      'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5'],\n",
    "           'Depth': [2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3],\n",
    "           'P(Correct Treatment)': ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.9', '0.9',\n",
    "                                   '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9'],\n",
    "          'Error': [74.67, 74.67, 46.40, 79.86, 145, 109.21, 18.15, 18.15, 152.55, 90.47, 199.70, 238.67, 219.02, \n",
    "                    239.10, 201.21, 201.21, 99.23, 88.12, 196.07, 156.84],\n",
    "          '% Classified': [71.97, 71.97, 78.49, 71.11, 61.22, 68.03, 88.33, 88.33, 60.41, 70.03, 53.35,\n",
    "                          47.49, 49.91, 47.49, 53.42, 53.42, 71.19, 74.11, 54.12, 58.02]}\n",
    "summary = pd.DataFrame(summary)\n",
    "summary.to_csv('kallus_tree_athey.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY: Bertsimas on Athey\n",
    "summary = {'Method': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5', 'Dataset 1', \n",
    "                      'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5'],\n",
    "           'Depth': [2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3],\n",
    "           'P(Correct Treatment)': ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.9', '0.9',\n",
    "                                   '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9'],\n",
    "          'Error': [74.67, 74.67, 46.40, 55.17, 145, 109.21, 18.15, 18.15, 152.55, 90.47, 199.70, 154.07, 219.02, \n",
    "                    180.83, 201.21, 116.75, 99.23, 88.12, 196.07, 156.84],\n",
    "          '% Classified': [71.97, 71.97, 78.49, 76.49, 61.22, 68.03, 88.33, 88.33, 60.41, 70.03, 53.35,\n",
    "                          62.17, 49.91, 53.91, 53.42, 71.59, 71.19, 74.11, 54.12, 58.02]}\n",
    "summary = pd.DataFrame(summary)\n",
    "summary.to_csv('bertsimas_tree_athey.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoint_tree_avg(node, i):\n",
    "    if node in L: #if datapoint has reached leaf node, calculate error\n",
    "        return node\n",
    "    if train_X.iloc[i, branching[node]] <= 0: # go left (node 2)\n",
    "        return datapoint_tree_avg(tree.get_left_children(node), i)\n",
    "    else:\n",
    "        return datapoint_tree_avg(tree.get_right_children(node), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = {20: 0, 21: 0, 30: 0, 31: 0}\n",
    "count = {20: 0, 21: 0, 30: 0, 31: 0}\n",
    "\n",
    "for i in range(n):\n",
    "    leaf_node = datapoint_tree_avg(1, i)\n",
    "    index = str(leaf_node) + str(train_t[i])\n",
    "    summation[int(index)] += train_y[i]\n",
    "    count[int(index)] += 1\n",
    "    \n",
    "avg = {}\n",
    "for i in summation:\n",
    "    avg[i] = float(summation[i]) / count[i]\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.39851651102745433, 3: 0.34277517675515534}\n"
     ]
    }
   ],
   "source": [
    "summation = {2: 0, 3: 0}\n",
    "count = {2: 0, 3: 0}\n",
    "\n",
    "for i in range(n):\n",
    "    leaf_node = datapoint_tree_avg(1, i)\n",
    "    if train_t[i] == treatments[leaf_node]:\n",
    "        summation[leaf_node] += train_y[i]\n",
    "        count[leaf_node] += 1\n",
    "    \n",
    "avg = {}\n",
    "for i in summation:\n",
    "    avg[i] = float(summation[i]) / count[i]\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "N = L.union(L_c)\n",
    "print(N)\n",
    "\n",
    "model = gp.Model(\"Nathan\")\n",
    "\n",
    "# -- VARIABLE DECLARATION --\n",
    "\n",
    "# -- Variables to determine: gamma and lambda --\n",
    "# 1. gamma_p = choice of cut at node p ([0, 1]^C_p) (only applies to non-leaf node)\n",
    "#       - represent with a matrix gamma (|L_c| x |C_p|)\n",
    "\n",
    "gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "# This assumes gamma is binary\n",
    "#gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "\n",
    "# 2. lambda_pt = choice of treatment t at node p (only applies to leaf nodes L)\n",
    "#       - represent with a matrix lamb (|L| x m)\n",
    "lamb = model.addVars(L, m, vtype=GRB.BINARY, name='lamb')\n",
    "\n",
    "\n",
    "# -- Other Variables in Formulation --\n",
    "# 1. w_ip = membership of datapoint i in node p (only applies to leaf nodes L)\n",
    "#       - represent with a matrix w (n x |L|)\n",
    "\n",
    "c = model.addVars(n, N, vtype=GRB.BINARY, name='c')\n",
    "# This assumes w is binary, when in reality it is continuous from 0-1\n",
    "#w = model.addVars(n, L, vtype=GRB.BINARY, name='w') # Original paper has this be a continuous variable\n",
    "\n",
    "# 2. mu_p = mean outcome of prescribed treatment in node p\n",
    "#       - represent with a matrix mu (|L|)\n",
    "v = model.addVars(n, L_c, vtype=GRB.BINARY, name='v') # define in constraint\n",
    "\n",
    "# 3. nu_ip = \"effect\" of treatment in node p by multiplying mu and w\n",
    "#       - represent with a matrix nu (n x |L|)\n",
    "w = model.addVars(n, vtype=GRB.BINARY, name='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"if different_Cp:\n",
    "# ---- K and Z if we followed the definition of C_p from the paper -----\n",
    "    for p in L_c:\n",
    "        k[p] = math.ceil(math.log2(len(C[p])))\n",
    "\n",
    "    z = {}\n",
    "    for p in L_c:\n",
    "        matrix = np.zeros((k[p], len(C[p])))\n",
    "        print(matrix.shape)\n",
    "        for i in range(1, k[p]+1):\n",
    "            for j in range(1, len(C[p])+1):\n",
    "                if math.floor(j/(2**i)) % 2 == 1: # odd number\n",
    "                    z[i-1, j-1] = 1\n",
    "                else:\n",
    "                    z[i-1, j-1] = 0\n",
    "        z[p] = matrix\n",
    "\n",
    "else:\n",
    "    # ---- K and Z if we had constant C for all nodes ----\n",
    "    k = math.ceil(math.log2(len(C)))\n",
    "    z = np.zeros((k, len(C)))\n",
    "    for i in range(1, k+1):\n",
    "        for j in range(1, len(C)+1):\n",
    "            if math.floor(j/(2**i)) % 2 == 1: # odd number\n",
    "                z[i-1, j-1] = 1\n",
    "            else:\n",
    "                z[i-1, j-1] = 0\n",
    "print(z)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
