{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILP Formulation from Nathan Kallus' Paper (Problem 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specifications\n",
    "#### Since we chose to modify the formulation to a certain extent, these variables simply allow us to revert back to the original model\n",
    "- delta_include: If true, then constraint 4c from original formulation holds. If false, only the added constraint that gamma[p] need to add to 1 holds\n",
    "- different_Cp = If true, then we have different sets of branching choices for every non-leaf node (like original formulation). If false, then we have a static set C for all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- This class is an alternative to solving the right/left ancestor problem --\n",
    "\"\"\"\n",
    "INPUT: d = depth of tree (which includes root node), so d = 2 would make a tree with {1, 2, 3}\n",
    "RELEVANT FUNCTIONS:\n",
    "- get_right_left: For all leaf nodes, returns its right and left ancestors in a dictionary \n",
    "                  of {(p, q): 1 or -1 if q is right or left ancestor respectively}\n",
    "\"\"\"\n",
    "class Tree:\n",
    "    def __init__(self, d):\n",
    "        self.depth = d\n",
    "        self.nodes = list(range(1, 2**(d-1)))\n",
    "        self.leaves = list(range(2**(d-1), 2**d))\n",
    "        self.ancestor_rl = {}\n",
    "    \n",
    "    def get_left_children(self, n):\n",
    "        if n in self.nodes:\n",
    "            return int(2*n)\n",
    "        else:\n",
    "            raise Exception ('Invalid node n')\n",
    "    \n",
    "    def get_right_children(self, n):\n",
    "        if n in self.nodes:\n",
    "            return int(2*n+1)\n",
    "        else:\n",
    "            raise Exception ('Invalid node n')\n",
    "    \n",
    "    def get_parent(self, n):\n",
    "        if (n in self.nodes) | (n in self.leaves):\n",
    "            return int(math.floor(n/2))\n",
    "        else:\n",
    "            raise Exception ('Invalide node n')\n",
    "    \n",
    "    def get_ancestors(self, direction, n):\n",
    "        current = n\n",
    "        ancestors = []\n",
    "        while current != 1:\n",
    "            current_buffer = self.get_parent(current)\n",
    "            if direction == 'r':\n",
    "                if self.get_right_children(current_buffer) == current:\n",
    "                    ancestors.append(current_buffer)\n",
    "            else:\n",
    "                if self.get_left_children(current_buffer) == current:\n",
    "                    ancestors.append(current_buffer)\n",
    "            current = current_buffer\n",
    "        return ancestors\n",
    "    \n",
    "    def get_right_left(self):\n",
    "        for i in self.leaves:\n",
    "            right = self.get_ancestors('r', i)\n",
    "            for j in right:\n",
    "                self.ancestor_rl[(i, j)] = 1\n",
    "            left = self.get_ancestors('l', i)\n",
    "            for j in left:\n",
    "                self.ancestor_rl[(i, j)] = -1\n",
    "        return self.ancestor_rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    #train_X = df.iloc[:, :25]\n",
    "    train_X = df[['AGE2', 'AGE3', 'RVISINF', 'RSBP2', 'RSBP3', 'RSBP4', 'RDEF3', 'RDEF4', 'RDEF5', 'RCONSC1', 'RCONSC2']]\n",
    "    real = df[['y0', 'y1', 'y2', 'y3', 'y4', 'y5']]\n",
    "    train_t = df['t']\n",
    "    train_y = df['y']\n",
    "    return train_X, train_t, train_y, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_v2(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    train_X = df.iloc[:, :3]\n",
    "    real = df.iloc[:, 3:5]\n",
    "    train_t = df.iloc[:, 5]\n",
    "    train_y = df.iloc[:, 7]\n",
    "    return train_X, train_t, train_y, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoint_tree(node, i, test_X, test_real, test_t):\n",
    "    if node in L: #if datapoint has reached leaf node, calculate error\n",
    "        index = treatments[node]\n",
    "        ideal_outcome = max(test_real.iloc[i, :])\n",
    "        difference = ideal_outcome - test_real.iloc[i, index]\n",
    "        if difference == 0:\n",
    "            count_optimal = 1\n",
    "        else:\n",
    "            count_optimal = 0\n",
    "        \n",
    "        if index == test_t[i]:\n",
    "            same_treatment = 1\n",
    "        else:\n",
    "            same_treatment = 0\n",
    "        return difference, count_optimal, same_treatment\n",
    "    if test_X.iloc[i, branching[node]] <= 0: # go left (node 2)\n",
    "        return datapoint_tree(tree.get_left_children(node), i, test_X, test_real, test_t)\n",
    "    else:\n",
    "        return datapoint_tree(tree.get_right_children(node), i, test_X, test_real, test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_X, test_real, test_t):\n",
    "    difference = 0\n",
    "    count_optimal = 0\n",
    "    count_same = 0\n",
    "    for i in range(len(test_X)):\n",
    "        diff, optimal, treat = datapoint_tree(1, i, test_X, test_real, test_t)\n",
    "        difference += diff\n",
    "        count_optimal += optimal\n",
    "        count_same += treat\n",
    "    return difference, float(count_optimal)/len(test_X), float(count_same)/len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring variables determined a-priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Specfiying Input to Model\n",
    "- m treatments indexed by t {1,..., m}\n",
    "- n datapoints indexed by i {(X1, T1, Y1), ..., (Xn, Tn, Yn)} \n",
    "- d: depth of decision tree\n",
    "- n_min: minimum number of datapoints of each treatment in node p\n",
    "- num_features\n",
    "- num_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tree(depth, bert):\n",
    "    delta_include = False\n",
    "    different_Cp = False\n",
    "    bertsimas = bert\n",
    "\n",
    "    m = {0, 1, 2, 3, 4, 5}\n",
    "    n = len(train_X)\n",
    "    d = int(depth)\n",
    "    n_min = 0\n",
    "    num_features = 2\n",
    "    num_cuts = 2\n",
    "\n",
    "    \"\"\"# ---- CONSTRUCTING COMPLETE BINARY TREE ----\n",
    "    # - P = number of nodes in the tree\n",
    "    # - L_c = set of non-leaf nodes\n",
    "    # - L = set of leaf ndoes\"\"\"\n",
    "\n",
    "    P = 2**d\n",
    "    L_c = set(range(1, 2**(d-1)))\n",
    "    L = set(range(2**(d-1), P))\n",
    "\n",
    "    # - ancestors: dictionary {leaf nodes: {set of ancestors}}\n",
    "    ancestors = {}\n",
    "    for p in L:\n",
    "        ancestors[p] = [math.floor(p/(2**j)) for j in range(1, d)]\n",
    "\n",
    "        # Alternative way of retrieving right/left ancestors\n",
    "    tree = Tree(d)\n",
    "    right_left = tree.get_right_left()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    - C[p]: finite set of cuts on node p--determined apriori {(l, theta)}\n",
    "        Representation: dictionary {non-leaf node: list of (l, theta)}\n",
    "        Require a list instead of set so it's ordered (indexed easily)\n",
    "\n",
    "\n",
    "    From Kallus' paper, he wants us to:\n",
    "    1. For each l in [d], sort data along x_l\n",
    "    2a. For each non-leaf node, pick #features from [d] randomly\n",
    "    2b. Set J = {1, (n-1/#cuts), ..., n-1} in decreasing order of cuts\n",
    "    2c. Set Cp = {(l, midpoint between the two buckets in J) for all dimensions chosen and for all j in J}\n",
    "\n",
    "    Make version of ALG3 to take all features\"\"\"\n",
    "\n",
    "\n",
    "    if different_Cp:\n",
    "        pass\n",
    "    else:\n",
    "        # -- BINARY COVARIATES --> Create a finite set of cuts for C for all features --\n",
    "        C = []\n",
    "        for i in range(len(train_X.columns)):\n",
    "            C.append((i, 0))\n",
    "\n",
    "\n",
    "    \"\"\" --- OTHER DATA --- \n",
    "    BIG M Constraints:\n",
    "    - Ybar\n",
    "    - Ymax\n",
    "    - M\n",
    "\n",
    "    BINARY ENCODING FOR CUTS\n",
    "    - k_p: dictionary {non-leaf node p: k_p value}\n",
    "    - Z_p: dictionary {non-leaf node p: k_p x |C_p| 2d matrix}\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Big M Constraints ----\n",
    "    # Ybar is merged into data, but it could not be. ybar is a numpy array\n",
    "    minimum = min(train_y)\n",
    "\n",
    "    ybar = train_y - minimum\n",
    "    #data['ybar'] = ybar\n",
    "\n",
    "    # Ymax\n",
    "    ymax = max(ybar)\n",
    "\n",
    "    # M\n",
    "    # Find all sums for treatments 1, ..., m\n",
    "    #treatment_counts = treatment.value_counts().to_list()\n",
    "    unique, counts = np.unique(train_t, return_counts=True)\n",
    "    #frequencies = numpy.asarray((unique, counts)).T\n",
    "    M = np.array(counts)\n",
    "    M -= len(L) * n_min\n",
    "    M = max(M)\n",
    "    \n",
    "    model = gp.Model(\"Kallus\")\n",
    "    #model.params.TimeLimit = 3600\n",
    "\n",
    "    # -- VARIABLE DECLARATION --\n",
    "\n",
    "    # -- Variables to determine: gamma and lambda --\n",
    "    # 1. gamma_p = choice of cut at node p ([0, 1]^C_p) (only applies to non-leaf node)\n",
    "    #       - represent with a matrix gamma (|L_c| x |C_p|)\n",
    "\n",
    "    gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "    # This assumes gamma is binary\n",
    "    #gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "\n",
    "    # 2. lambda_pt = choice of treatment t at node p (only applies to leaf nodes L)\n",
    "    #       - represent with a matrix lamb (|L| x m)\n",
    "    lamb = model.addVars(L, m, vtype=GRB.BINARY, name='lamb')\n",
    "\n",
    "\n",
    "    # -- Other Variables in Formulation --\n",
    "    # 1. w_ip = membership of datapoint i in node p (only applies to leaf nodes L)\n",
    "    #       - represent with a matrix w (n x |L|)\n",
    "\n",
    "    w = model.addVars(n, L, lb=0, ub=1, name='w')\n",
    "    # This assumes w is binary, when in reality it is continuous from 0-1\n",
    "    #w = model.addVars(n, L, vtype=GRB.BINARY, name='w') # Original paper has this be a continuous variable\n",
    "\n",
    "    # 2. mu_p = mean outcome of prescribed treatment in node p\n",
    "    #       - represent with a matrix mu (|L|)\n",
    "    mu = model.addVars(L, lb=0, name='mu') # define in constraint\n",
    "\n",
    "    # 3. nu_ip = \"effect\" of treatment in node p by multiplying mu and w\n",
    "    #       - represent with a matrix nu (n x |L|)\n",
    "    nu = model.addVars(n, L, lb=0, name='nu')\n",
    "\n",
    "    # 4. delta_p = forces only 1 choice of cut at node p\n",
    "    #       - represent with a dictionary {non-leaf node p: 1d matrix of size k_p}\n",
    "    #delta = model.addVars(L, k, vtype=GRB.BINARY, name='delta')\n",
    "\n",
    "    # 5. Chi_i(gamma) = 1 if choice of cut induces datapoint i to go left on the cut gamma, 0 otherwise\n",
    "    chi = model.addVars(L_c, n, vtype=GRB.BINARY, name='chi')\n",
    "\n",
    "    if bertsimas:\n",
    "        # 6. f_i\n",
    "        f = model.addVars(n, lb=0, name='f')\n",
    "\n",
    "        # 7. Beta_lt\n",
    "        beta = model.addVars(L, m, lb=0, name='beta')\n",
    "\n",
    "    theta = 0.5\n",
    "    \n",
    "        # --- OBJECTIVE FUNCTION ---\n",
    "    if bertsimas:\n",
    "        model.setObjective(theta * gp.quicksum(nu[i, p] for i in range(n) for p in L) \n",
    "                       - (1-theta) * gp.quicksum((train_y[i] - f[i]) * (train_y[i] - f[i]) for i in range(n)), GRB.MAXIMIZE)\n",
    "    else:\n",
    "        model.setObjective(gp.quicksum(nu[i, p] for i in range(n) for p in L), GRB.MAXIMIZE)\n",
    "\n",
    "\n",
    "    # --- CONSTRAINTS ---\n",
    "    # Constraint 4c (4b is done by definition of variables)\n",
    "    if delta_include:\n",
    "        for p in L_c:\n",
    "            # need to do matrix multiplication somehow, but this might work?\n",
    "            for j in range(k):\n",
    "                model.addConstr(delta[p, j] == gp.quicksum(gamma[p, i] * z[j, i] for i in range(len(C))))\n",
    "\n",
    "    # Additional constraint that gamma[p] adds up to 1\n",
    "    # CHECKED\n",
    "    for p in L_c:\n",
    "        model.addConstr(gp.quicksum(gamma[p, i] for i in range(len(C))) == 1)\n",
    "\n",
    "    # Add constraint Chi\n",
    "    for i in range(n):\n",
    "        for p in L_c:\n",
    "            model.addConstr(chi[p, i] == gp.quicksum(gamma[p, j] for j in range(len(C)) if C[j][1] >= train_X.iloc[i, C[j][0]]))\n",
    "\n",
    "\n",
    "    # Constraint 4d&e (Membership restriction from its ancestors) CHECKED\n",
    "    for p in L:\n",
    "        A_p = ancestors[p] #index ancestors of p\n",
    "        for q in A_p:\n",
    "            R_pq = right_left[(p, q)]\n",
    "            for i in range(n):\n",
    "                model.addConstr(w[i, p] <= (1+R_pq)/2 - R_pq * chi[q, i])\n",
    "\n",
    "\n",
    "    #4e CHECKED\n",
    "    for p in L:\n",
    "        A_p = ancestors[p] #index ancestors of p\n",
    "        for i in range(n):\n",
    "            model.addConstr(w[i, p] >= 1 + gp.quicksum(-chi[q, i] for q in A_p if right_left[(p, q)] == 1)\n",
    "                        + gp.quicksum(-1+chi[q, i] for q in A_p if right_left[(p, q)] == -1))\n",
    "\n",
    "\n",
    "    # Constraint 4f\n",
    "    # CHECKED\n",
    "    for t in m:\n",
    "        for p in L:\n",
    "            model.addConstr(gp.quicksum(w[i, p] for i in range(n) if train_t[i] == t) >= n_min) #assuming the input comes in vector (Xi, Ti, Yi)\n",
    "            # only add the datapoints that have been given treatment t\n",
    "\n",
    "    # Constraints 4g&h (Linearization of nu)\n",
    "    # CHECKED\n",
    "    for p in L:\n",
    "        for i in range(n):\n",
    "            model.addConstr(nu[i, p] <= ymax * w[i, p])\n",
    "            model.addConstr(nu[i, p] <= mu[p])\n",
    "            model.addConstr(nu[i, p] >= mu[p] - ymax * (1-w[i, p]))\n",
    "\n",
    "    # Constraint 4i (Choice of treatment applied to p)\n",
    "    # CHECKED\n",
    "    for p in L:\n",
    "        model.addConstr(gp.quicksum(lamb[p, t] for t in m) == 1)\n",
    "\n",
    "    # Constraint 4j&k (Consistency between lambda and mu)\n",
    "    # CHECKED. There are some inconsistencies where some w don't appear, but this is because ybar is 0 (i.e. the minimum)\n",
    "    for p in L:\n",
    "        for t in m:\n",
    "            model.addConstr(gp.quicksum(nu[i, p] - w[i, p] * ybar[i] for i in range(n) if train_t[i] == t) <= M*(1-lamb[p, t]))\n",
    "            model.addConstr(gp.quicksum(nu[i, p] - w[i, p] * ybar[i] for i in range(n) if train_t[i] == t) >= M*(lamb[p, t]-1))\n",
    "    #model.addConstr(lamb[2, 0] == 1)\n",
    "    if bertsimas:\n",
    "        for i in range(n):\n",
    "            for p in L:\n",
    "                for t in m:\n",
    "                    if train_t[i] == t:\n",
    "                        model.addConstr(f[i] - beta[p, t] <= M * (1-w[i, p]))\n",
    "                        model.addConstr(f[i] - beta[p, t] >= M * (w[i, p]-1))\n",
    "    \n",
    "    #model.params.TimeLimit = 3600\n",
    "    timeLimit = 3600\n",
    "    oldSolutionLimit = model.Params.SolutionLimit\n",
    "    model.Params.SolutionLimit = 1\n",
    "    model.optimize()\n",
    "    model.Params.TimeLimit = timeLimit - model.getAttr(GRB.Attr.Runtime)\n",
    "    model.Params.SolutionLimit = oldSolutionLimit - model.Params.SolutionLimit\n",
    "    model.optimize()\n",
    "    \n",
    "    \n",
    "    #model.optimize()\n",
    "    g = model.getAttr(\"X\", gamma).items()\n",
    "    l = model.getAttr(\"X\", lamb).items()\n",
    "    \n",
    "    branching = {i[0][0]: i[0][1] for i in g if i[1] == 1.0}\n",
    "    treatments = {i[0][0]: i[0][1] for i in l if i[1] == 1.0}\n",
    "    \n",
    "    return branching, treatments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'bertsimas_athey_500.csv' does not exist: b'bertsimas_athey_500.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d2b3b115bc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbertsimas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bertsimas_athey_500.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'bertsimas_athey_500.csv' does not exist: b'bertsimas_athey_500.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"kallus = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                               'Train % Same Treatment', 'Tree'])\n",
    "bertsimas = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                                  'Train % Same Treatment', 'Tree'])\"\"\"\n",
    "\n",
    "\n",
    "#bertsimas = pd.read_csv('bertsimas_athey_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /Users/nathanjo/gurobi.lic\n",
      "Academic license - for non-commercial use only - expires 2021-02-17\n",
      "Changed value of parameter SolutionLimit to 1\n",
      "   Prev: 2000000000  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 8019 rows, 4007 columns and 24402 nonzeros\n",
      "Model fingerprint: 0x3fba9f65\n",
      "Variable types: 4001 continuous, 6 integer (6 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+02]\n",
      "Presolve removed 8019 rows and 4007 columns\n",
      "Presolve time: 0.05s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.07 seconds\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 1307.02 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.307017543860e+03, best bound 1.307017543860e+03, gap 0.0000%\n",
      "Changed value of parameter TimeLimit to 3599.9264299869537\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter SolutionLimit to 1999999999\n",
      "   Prev: 1  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 8019 rows, 4007 columns and 24402 nonzeros\n",
      "Model fingerprint: 0x3fba9f65\n",
      "Variable types: 4001 continuous, 6 integer (6 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+02]\n",
      "\n",
      "Loaded MIP start from previous solve with objective -1e+100\n",
      "\n",
      "Presolve removed 8019 rows and 4007 columns\n",
      "Presolve time: 0.04s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.07 seconds\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 1307.02 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.307017543860e+03, best bound 1.307017543860e+03, gap 0.0000%\n",
      "[1, 1, 0.5, 5214, 69.9221228728007, 11.445053360253823, 617, 69.15, 11.4, 'branching = {}, treatments = {1: 4}']\n",
      "Changed value of parameter SolutionLimit to 1\n",
      "   Prev: 2000000000  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 22039 rows, 10025 columns and 73687 nonzeros\n",
      "Model fingerprint: 0x5128becc\n",
      "Variable types: 8002 continuous, 2023 integer (2023 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+02]\n",
      "Presolve removed 8009 rows and 3999 columns\n",
      "Presolve time: 0.24s\n",
      "Presolved: 14030 rows, 6026 columns, 50138 nonzeros\n",
      "Variable types: 4002 continuous, 2024 integer (2018 binary)\n",
      "\n",
      "Root relaxation: objective 2.000000e+03, 6810 iterations, 0.27 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2000.00000    0    5          - 2000.00000      -     -    0s\n",
      "H    0     0                    1168.3501684 2000.00000  71.2%     -    0s\n",
      "\n",
      "Explored 1 nodes (232 simplex iterations) in 0.94 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 1168.35 \n",
      "\n",
      "Solution limit reached\n",
      "Best objective 1.168350168350e+03, best bound 2.000000000000e+03, gap 71.1816%\n",
      "Changed value of parameter TimeLimit to 3599.0496668815613\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter SolutionLimit to 1999999999\n",
      "   Prev: 1  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 22039 rows, 10025 columns and 73687 nonzeros\n",
      "Model fingerprint: 0x5128becc\n",
      "Variable types: 8002 continuous, 2023 integer (2023 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+02]\n",
      "Presolved: 14030 rows, 6026 columns, 50138 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      "     2     4 2000.00000    1 1829 1168.35017 2000.00000  71.2%   5.5    8s\n",
      "H    4     8                    1307.0175439 2000.00000  53.0%   146   14s\n",
      "    16    20 1729.91314    5    3 1307.01754 2000.00000  53.0%   401   15s\n",
      "*   62    37              13    1308.6538953 2000.00000  52.8%   571   17s\n",
      "H   64    37                    1312.7660352 2000.00000  52.4%   553   17s\n",
      "H  101    30                    1342.4915254 2000.00000  49.0%   602   18s\n",
      "   128    48 1755.16108   12 1759 1342.49153 2000.00000  49.0%   589   20s\n",
      "   242    54     cutoff   14      1342.49153 1980.15508  47.5%   578   25s\n",
      "*  349    57              12    1368.3373397 1951.82053  42.6%   596   28s\n",
      "   401    52     cutoff   11      1368.33734 1941.56665  41.9%   596   30s\n",
      "   536    29     cutoff   14      1368.33734 1823.00000  33.2%   617   35s\n",
      "\n",
      "Explored 611 nodes (378503 simplex iterations) in 35.80 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 6: 1368.34 1342.49 1312.77 ... 1168.35\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.368337339744e+03, best bound 1.368337339744e+03, gap 0.0000%\n",
      "[1, 2, 0.5, 5374, 68.99913469858667, 11.439284684164983, 635, 68.25, 12.25, 'branching = {1: 7}, treatments = {2: 0, 3: 4}']\n",
      "Changed value of parameter SolutionLimit to 1\n",
      "   Prev: 2000000000  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 54079 rows, 22061 columns and 184257 nonzeros\n",
      "Model fingerprint: 0x7f9dfd53\n",
      "Variable types: 16004 continuous, 6057 integer (6057 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+02]\n",
      "Presolve removed 33 rows and 15 columns\n",
      "Presolve time: 0.49s\n",
      "Presolved: 54046 rows, 22046 columns, 176233 nonzeros\n",
      "Variable types: 16004 continuous, 6042 integer (6042 binary)\n",
      "Found heuristic solution: objective 1265.4867257\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.78 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 1265.49 \n",
      "\n",
      "Solution limit reached\n",
      "Best objective 1.265486725664e+03, best bound 8.000000000000e+03, gap 532.1678%\n",
      "Changed value of parameter TimeLimit to 3599.218857049942\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter SolutionLimit to 1999999999\n",
      "   Prev: 1  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 54079 rows, 22061 columns and 184257 nonzeros\n",
      "Model fingerprint: 0x7f9dfd53\n",
      "Variable types: 16004 continuous, 6057 integer (6057 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+02]\n",
      "Presolved: 54046 rows, 22046 columns, 176233 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      "\n",
      "Root relaxation: objective 3.978000e+03, 29333 iterations, 1.95 seconds\n"
     ]
    }
   ],
   "source": [
    "kallus = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                               'Train % Same Treatment', 'Tree'])\n",
    "\n",
    "\n",
    "prob = 0.5\n",
    "bert = False\n",
    "\n",
    "depths = [1, 2, 3]\n",
    "datasets = [1, 2, 3, 4, 5]\n",
    "#probs = [0.1, 0.5, 0.9]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for d in depths:\n",
    "        train_filepath = 'data/IST_2000_binary/data_train_enc_' + str(dataset) + '.csv'\n",
    "        test_filepath = 'data/IST_2000_binary/data_test_enc_' + str(dataset) + '.csv'\n",
    "        train_X, train_t, train_y, train_real = open_file(train_filepath)\n",
    "        branching, treatments = run_tree(d, bert)\n",
    "\n",
    "        tree = Tree(d)\n",
    "        L = set(range(2**(d-1), 2**d))\n",
    "        test_X, test_t, test_y, test_real = open_file(test_filepath)\n",
    "        error, pct, acc = get_metrics(test_X, test_real, test_t)\n",
    "        error1, pct1, acc1 = get_metrics(train_X, train_real, train_t)\n",
    "\n",
    "        tree_stats = 'branching = ' + str(branching) + ', treatments = ' + str(treatments)\n",
    "        row = [dataset, d, prob, error, pct*100, acc*100, error1, pct1*100, acc1*100, tree_stats]\n",
    "        print(row)\n",
    "        if bert:\n",
    "            bertsimas.loc[len(bertsimas)] = row\n",
    "        else:\n",
    "            kallus.loc[len(kallus)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kallus.to_csv('Results_IST_binary/kallus_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed value of parameter TimeLimit to 3600.0\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 22039 rows, 10039 columns and 99696 nonzeros\n",
      "Model fingerprint: 0xb0b31bf7\n",
      "Variable types: 8002 continuous, 2037 integer (2037 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-02, 6e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [9e-01, 6e+02]\n",
      "Presolve removed 8034 rows and 4022 columns\n",
      "Presolve time: 0.58s\n",
      "Presolved: 14005 rows, 6017 columns, 79167 nonzeros\n",
      "Variable types: 4002 continuous, 2015 integer (2015 binary)\n",
      "\n",
      "Root relaxation: objective 1.897781e+03, 7002 iterations, 0.98 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1897.78083    0  568          - 1897.78083      -     -    2s\n",
      "H    0     0                     914.8065581 1897.78083   107%     -    2s\n",
      "H    0     0                     954.4295127 1897.78083  98.8%     -    3s\n",
      "     0     0 1897.78083    0 1681  954.42951 1897.78083  98.8%     -    8s\n",
      "H    0     0                     967.9462660 1897.78083  96.1%     -    8s\n",
      "     0     0 1897.78083    0 1473  967.94627 1897.78083  96.1%     -    8s\n",
      "     0     0 1897.78083    0 1529  967.94627 1897.78083  96.1%     -   11s\n",
      "     0     0 1897.78083    0 1529  967.94627 1897.78083  96.1%     -   11s\n",
      "     0     0 1897.78083    0  798  967.94627 1897.78083  96.1%     -   12s\n",
      "     0     0 1897.78083    0  796  967.94627 1897.78083  96.1%     -   12s\n",
      "H    0     0                    1020.6339109 1897.78083  85.9%     -   12s\n",
      "     0     0 1897.78083    0 1200 1020.63391 1897.78083  85.9%     -   13s\n",
      "     0     0 1897.78083    0 1200 1020.63391 1897.78083  85.9%     -   13s\n",
      "     0     0 1897.78083    0 1489 1020.63391 1897.78083  85.9%     -   14s\n",
      "     0     0 1897.78083    0 1489 1020.63391 1897.78083  85.9%     -   14s\n",
      "     0     2 1897.78083    0 1489 1020.63391 1897.78083  85.9%     -   15s\n",
      "    58    45     cutoff   12      1020.63391 1897.78083  85.9%   457   20s\n",
      "*   83    55              16    1027.4409749 1897.78083  84.7%   396   22s\n",
      "   137    67 1367.36946    9    2 1027.44097 1897.78083  84.7%   503   25s\n",
      "   219    91 1354.92210   12    2 1027.44097 1897.78083  84.7%   500   30s\n",
      "   279   115 1280.23208   11  692 1027.44097 1897.78083  84.7%   497   35s\n",
      "   372   139 1385.56397   22    2 1027.44097 1887.30698  83.7%   476   40s\n",
      "   488   137     cutoff   15      1027.44097 1837.14963  78.8%   512   45s\n",
      "   559   137 1653.62072   16    4 1027.44097 1808.69517  76.0%   524   50s\n",
      "   713   140 1318.62699    5    2 1027.44097 1759.19970  71.2%   540   55s\n",
      "   938   118     cutoff   13      1027.44097 1528.12742  48.7%   517   61s\n",
      "  1215    60     cutoff   20      1027.44097 1248.92886  21.6%   496   65s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 16\n",
      "  Flow cover: 3\n",
      "  RLT: 11\n",
      "\n",
      "Explored 1390 nodes (695145 simplex iterations) in 67.25 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 5: 1027.44 1020.63 967.946 ... 914.807\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.027440974920e+03, best bound 1.027440974920e+03, gap 0.0000%\n",
      "[4, 2, 1997.4432696442377, 24.39164701144797, 11.338664212161307, 231.808278142224, 23.75, 11.600000000000001, 'branching = {1: 23}, treatments = {2: 4, 3: 1}']\n"
     ]
    }
   ],
   "source": [
    "dataset = 4\n",
    "d = 2\n",
    "bert = False\n",
    "train_filepath = 'data/IST_2000/data_train_enc_' + str(dataset) + '.csv'\n",
    "test_filepath = 'data/IST_2000/data_test_enc_' + str(dataset) + '.csv'\n",
    "train_X, train_t, train_y, train_real = open_file(train_filepath)\n",
    "branching, treatments = run_tree(d, bert)\n",
    "\n",
    "tree = Tree(d)\n",
    "L = set(range(2**(d-1), 2**d))\n",
    "test_X, test_t, test_y, test_real = open_file(test_filepath)\n",
    "error, pct, acc = get_metrics(test_X, test_real, test_t)\n",
    "error1, pct1, acc1 = get_metrics(train_X, train_real, train_t)\n",
    "\n",
    "tree_stats = 'branching = ' + str(branching) + ', treatments = ' + str(treatments)\n",
    "row = [dataset, d, error, pct*100, acc*100, error1, pct1*100, acc1*100, tree_stats]\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267.9863312540136 0.4446 0.5066\n",
      "21.252969854711775 0.354 0.5\n"
     ]
    }
   ],
   "source": [
    "tree = Tree(d)\n",
    "L = set(range(2**(d-1), 2**d))\n",
    "test_X, test_t, test_y, test_real = open_file(test_filepath)\n",
    "error, pct, acc = get_metrics(test_X, test_real, test_t)\n",
    "error1, pct1, acc1 = get_metrics(train_X, train_real, train_t)\n",
    "print(error, pct, acc)\n",
    "print(error1, pct1, acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 0.9, 267.9863312540136, 44.46, 50.660000000000004, 21.252969854711775, 35.4, 50.0, 'branching = {1: 10, 2: 16, 3: 0}, treatments = {4: 1, 5: 1, 6: 1, 7: 1}']\n"
     ]
    }
   ],
   "source": [
    "tree_stats = 'branching = ' + str(branching) + ', treatments = ' + str(treatments)\n",
    "row = [dataset, d, prob, error, pct*100, acc*100, error1, pct1*100, acc1*100, tree_stats]\n",
    "if bert:\n",
    "    bertsimas.loc[len(bertsimas)] = row\n",
    "else:\n",
    "    kallus.loc[len(kallus)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset  Depth  P(Correct Treatment)  Test Error  Test % Optimal  \\\n",
      "0         1      2                   0.5   53.227602           76.83   \n",
      "1         1      3                   0.5  123.833930           66.00   \n",
      "2         1      3                   0.5  123.833930           66.00   \n",
      "3         2      2                   0.5   24.915258           84.31   \n",
      "4         2      3                   0.5   24.915258           84.31   \n",
      "5         3      2                   0.5  166.280038           58.61   \n",
      "6         3      3                   0.5   57.544135           77.50   \n",
      "7         4      2                   0.5  432.810829           24.05   \n",
      "8         4      3                   0.5  231.607156           44.69   \n",
      "9         5      2                   0.5  189.645268           55.55   \n",
      "10        5      3                   0.5   36.072978           82.59   \n",
      "11        1      2                   0.9  224.473595           49.78   \n",
      "12        1      3                   0.9  224.473595           49.78   \n",
      "13        2      2                   0.9  216.993310           50.34   \n",
      "14        2      3                   0.9  216.993310           50.34   \n",
      "15        3      2                   0.9  279.888354           41.39   \n",
      "16        3      3                   0.9  290.892989           40.41   \n",
      "17        4      2                   0.9   75.234129           75.97   \n",
      "18        4      3                   0.9   75.234129           75.97   \n",
      "19        5      2                   0.9  267.986331           44.46   \n",
      "20        5      3                   0.9  267.986331           44.46   \n",
      "\n",
      "    Test % Same Treatment  Train Error  Train % Optimal  \\\n",
      "0                   49.33     1.833834             83.0   \n",
      "1                   49.34     2.356756             85.2   \n",
      "2                   49.34     2.356756             85.2   \n",
      "3                   50.46     1.220292             87.8   \n",
      "4                   50.46     1.220292             87.8   \n",
      "5                   49.19     5.115352             75.0   \n",
      "6                   49.48     2.759458             81.4   \n",
      "7                   50.07     2.819187             83.8   \n",
      "8                   50.66     0.674055             91.8   \n",
      "9                   49.63     8.600535             64.8   \n",
      "10                  48.97     0.969443             87.0   \n",
      "11                  50.18     5.508442             73.6   \n",
      "12                  50.18     5.508442             73.6   \n",
      "13                  50.72    15.210286             48.6   \n",
      "14                  50.72    15.210286             48.6   \n",
      "15                  50.68    31.611031             25.0   \n",
      "16                  49.90    31.992727             24.2   \n",
      "17                  49.97    32.501338             16.6   \n",
      "18                  49.97    32.501338             16.6   \n",
      "19                  50.66    21.252970             35.4   \n",
      "20                  50.66    21.252970             35.4   \n",
      "\n",
      "    Train % Same Treatment                                               Tree  \n",
      "0                     51.4      branching = {1: 2}, treatments = {2: 1, 3: 0}  \n",
      "1                     51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "2                     51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "3                     49.6      branching = {1: 3}, treatments = {2: 1, 3: 0}  \n",
      "4                     49.6  branching = {1: 3, 2: 13, 3: 15}, treatments =...  \n",
      "5                     48.6     branching = {1: 12}, treatments = {2: 0, 3: 0}  \n",
      "6                     46.6  branching = {1: 5, 2: 14, 3: 12}, treatments =...  \n",
      "7                     52.6     branching = {1: 13}, treatments = {2: 0, 3: 0}  \n",
      "8                     48.0  branching = {1: 7, 2: 10, 3: 13}, treatments =...  \n",
      "9                     51.0     branching = {1: 15}, treatments = {2: 0, 3: 0}  \n",
      "10                    49.2  branching = {1: 15, 2: 7, 3: 5}, treatments = ...  \n",
      "11                    48.4     branching = {1: 15}, treatments = {2: 1, 3: 1}  \n",
      "12                    48.4  branching = {1: 10, 2: 15, 3: 0}, treatments =...  \n",
      "13                    51.2     branching = {1: 14}, treatments = {2: 1, 3: 1}  \n",
      "14                    51.2  branching = {1: 16, 2: 0, 3: 11}, treatments =...  \n",
      "15                    49.4     branching = {1: 15}, treatments = {2: 1, 3: 1}  \n",
      "16                    48.6  branching = {1: 10, 2: 16, 3: 8}, treatments =...  \n",
      "17                    50.0     branching = {1: 14}, treatments = {2: 1, 3: 1}  \n",
      "18                    50.0  branching = {1: 16, 2: 0, 3: 14}, treatments =...  \n",
      "19                    50.0     branching = {1: 16}, treatments = {2: 1, 3: 1}  \n",
      "20                    50.0  branching = {1: 10, 2: 16, 3: 0}, treatments =...  \n"
     ]
    }
   ],
   "source": [
    "print(bertsimas)\n",
    "bertsimas.to_csv('bertsimas_athey_500.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Performance for Athey's Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY: KALLUS on Athey\n",
    "summary = {'Method': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5', 'Dataset 1', \n",
    "                      'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5'],\n",
    "           'Depth': [2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3],\n",
    "           'P(Correct Treatment)': ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.9', '0.9',\n",
    "                                   '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9'],\n",
    "          'Error': [74.67, 74.67, 46.40, 79.86, 145, 109.21, 18.15, 18.15, 152.55, 90.47, 199.70, 238.67, 219.02, \n",
    "                    239.10, 201.21, 201.21, 99.23, 88.12, 196.07, 156.84],\n",
    "          '% Classified': [71.97, 71.97, 78.49, 71.11, 61.22, 68.03, 88.33, 88.33, 60.41, 70.03, 53.35,\n",
    "                          47.49, 49.91, 47.49, 53.42, 53.42, 71.19, 74.11, 54.12, 58.02]}\n",
    "summary = pd.DataFrame(summary)\n",
    "summary.to_csv('kallus_tree_athey.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY: Bertsimas on Athey\n",
    "summary = {'Method': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5', 'Dataset 1', \n",
    "                      'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5'],\n",
    "           'Depth': [2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3],\n",
    "           'P(Correct Treatment)': ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.9', '0.9',\n",
    "                                   '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9'],\n",
    "          'Error': [74.67, 74.67, 46.40, 55.17, 145, 109.21, 18.15, 18.15, 152.55, 90.47, 199.70, 154.07, 219.02, \n",
    "                    180.83, 201.21, 116.75, 99.23, 88.12, 196.07, 156.84],\n",
    "          '% Classified': [71.97, 71.97, 78.49, 76.49, 61.22, 68.03, 88.33, 88.33, 60.41, 70.03, 53.35,\n",
    "                          62.17, 49.91, 53.91, 53.42, 71.59, 71.19, 74.11, 54.12, 58.02]}\n",
    "summary = pd.DataFrame(summary)\n",
    "summary.to_csv('bertsimas_tree_athey.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoint_tree_avg(node, i):\n",
    "    if node in L: #if datapoint has reached leaf node, calculate error\n",
    "        return node\n",
    "    if train_X.iloc[i, branching[node]] <= 0: # go left (node 2)\n",
    "        return datapoint_tree_avg(tree.get_left_children(node), i)\n",
    "    else:\n",
    "        return datapoint_tree_avg(tree.get_right_children(node), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = {20: 0, 21: 0, 30: 0, 31: 0}\n",
    "count = {20: 0, 21: 0, 30: 0, 31: 0}\n",
    "\n",
    "for i in range(n):\n",
    "    leaf_node = datapoint_tree_avg(1, i)\n",
    "    index = str(leaf_node) + str(train_t[i])\n",
    "    summation[int(index)] += train_y[i]\n",
    "    count[int(index)] += 1\n",
    "    \n",
    "avg = {}\n",
    "for i in summation:\n",
    "    avg[i] = float(summation[i]) / count[i]\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.39851651102745433, 3: 0.34277517675515534}\n"
     ]
    }
   ],
   "source": [
    "summation = {2: 0, 3: 0}\n",
    "count = {2: 0, 3: 0}\n",
    "\n",
    "for i in range(n):\n",
    "    leaf_node = datapoint_tree_avg(1, i)\n",
    "    if train_t[i] == treatments[leaf_node]:\n",
    "        summation[leaf_node] += train_y[i]\n",
    "        count[leaf_node] += 1\n",
    "    \n",
    "avg = {}\n",
    "for i in summation:\n",
    "    avg[i] = float(summation[i]) / count[i]\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "N = L.union(L_c)\n",
    "print(N)\n",
    "\n",
    "model = gp.Model(\"Nathan\")\n",
    "\n",
    "# -- VARIABLE DECLARATION --\n",
    "\n",
    "# -- Variables to determine: gamma and lambda --\n",
    "# 1. gamma_p = choice of cut at node p ([0, 1]^C_p) (only applies to non-leaf node)\n",
    "#       - represent with a matrix gamma (|L_c| x |C_p|)\n",
    "\n",
    "gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "# This assumes gamma is binary\n",
    "#gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "\n",
    "# 2. lambda_pt = choice of treatment t at node p (only applies to leaf nodes L)\n",
    "#       - represent with a matrix lamb (|L| x m)\n",
    "lamb = model.addVars(L, m, vtype=GRB.BINARY, name='lamb')\n",
    "\n",
    "\n",
    "# -- Other Variables in Formulation --\n",
    "# 1. w_ip = membership of datapoint i in node p (only applies to leaf nodes L)\n",
    "#       - represent with a matrix w (n x |L|)\n",
    "\n",
    "c = model.addVars(n, N, vtype=GRB.BINARY, name='c')\n",
    "# This assumes w is binary, when in reality it is continuous from 0-1\n",
    "#w = model.addVars(n, L, vtype=GRB.BINARY, name='w') # Original paper has this be a continuous variable\n",
    "\n",
    "# 2. mu_p = mean outcome of prescribed treatment in node p\n",
    "#       - represent with a matrix mu (|L|)\n",
    "v = model.addVars(n, L_c, vtype=GRB.BINARY, name='v') # define in constraint\n",
    "\n",
    "# 3. nu_ip = \"effect\" of treatment in node p by multiplying mu and w\n",
    "#       - represent with a matrix nu (n x |L|)\n",
    "w = model.addVars(n, vtype=GRB.BINARY, name='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"if different_Cp:\n",
    "# ---- K and Z if we followed the definition of C_p from the paper -----\n",
    "    for p in L_c:\n",
    "        k[p] = math.ceil(math.log2(len(C[p])))\n",
    "\n",
    "    z = {}\n",
    "    for p in L_c:\n",
    "        matrix = np.zeros((k[p], len(C[p])))\n",
    "        print(matrix.shape)\n",
    "        for i in range(1, k[p]+1):\n",
    "            for j in range(1, len(C[p])+1):\n",
    "                if math.floor(j/(2**i)) % 2 == 1: # odd number\n",
    "                    z[i-1, j-1] = 1\n",
    "                else:\n",
    "                    z[i-1, j-1] = 0\n",
    "        z[p] = matrix\n",
    "\n",
    "else:\n",
    "    # ---- K and Z if we had constant C for all nodes ----\n",
    "    k = math.ceil(math.log2(len(C)))\n",
    "    z = np.zeros((k, len(C)))\n",
    "    for i in range(1, k+1):\n",
    "        for j in range(1, len(C)+1):\n",
    "            if math.floor(j/(2**i)) % 2 == 1: # odd number\n",
    "                z[i-1, j-1] = 1\n",
    "            else:\n",
    "                z[i-1, j-1] = 0\n",
    "print(z)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
