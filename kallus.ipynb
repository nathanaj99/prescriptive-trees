{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILP Formulation from Nathan Kallus' Paper (Problem 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specifications\n",
    "#### Since we chose to modify the formulation to a certain extent, these variables simply allow us to revert back to the original model\n",
    "- delta_include: If true, then constraint 4c from original formulation holds. If false, only the added constraint that gamma[p] need to add to 1 holds\n",
    "- different_Cp = If true, then we have different sets of branching choices for every non-leaf node (like original formulation). If false, then we have a static set C for all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- This class is an alternative to solving the right/left ancestor problem --\n",
    "\"\"\"\n",
    "INPUT: d = depth of tree (which includes root node), so d = 2 would make a tree with {1, 2, 3}\n",
    "RELEVANT FUNCTIONS:\n",
    "- get_right_left: For all leaf nodes, returns its right and left ancestors in a dictionary \n",
    "                  of {(p, q): 1 or -1 if q is right or left ancestor respectively}\n",
    "\"\"\"\n",
    "class Tree:\n",
    "    def __init__(self, d):\n",
    "        self.depth = d\n",
    "        self.nodes = list(range(1, 2**(d-1)))\n",
    "        self.leaves = list(range(2**(d-1), 2**d))\n",
    "        self.ancestor_rl = {}\n",
    "    \n",
    "    def get_left_children(self, n):\n",
    "        if n in self.nodes:\n",
    "            return int(2*n)\n",
    "        else:\n",
    "            raise Exception ('Invalid node n')\n",
    "    \n",
    "    def get_right_children(self, n):\n",
    "        if n in self.nodes:\n",
    "            return int(2*n+1)\n",
    "        else:\n",
    "            raise Exception ('Invalid node n')\n",
    "    \n",
    "    def get_parent(self, n):\n",
    "        if (n in self.nodes) | (n in self.leaves):\n",
    "            return int(math.floor(n/2))\n",
    "        else:\n",
    "            raise Exception ('Invalide node n')\n",
    "    \n",
    "    def get_ancestors(self, direction, n):\n",
    "        current = n\n",
    "        ancestors = []\n",
    "        while current != 1:\n",
    "            current_buffer = self.get_parent(current)\n",
    "            if direction == 'r':\n",
    "                if self.get_right_children(current_buffer) == current:\n",
    "                    ancestors.append(current_buffer)\n",
    "            else:\n",
    "                if self.get_left_children(current_buffer) == current:\n",
    "                    ancestors.append(current_buffer)\n",
    "            current = current_buffer\n",
    "        return ancestors\n",
    "    \n",
    "    def get_right_left(self):\n",
    "        for i in self.leaves:\n",
    "            right = self.get_ancestors('r', i)\n",
    "            for j in right:\n",
    "                self.ancestor_rl[(i, j)] = 1\n",
    "            left = self.get_ancestors('l', i)\n",
    "            for j in left:\n",
    "                self.ancestor_rl[(i, j)] = -1\n",
    "        return self.ancestor_rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    #train_X = df.iloc[:, :25]\n",
    "    train_X = df[['Age1.2', 'Age3.4', 'Age5.6', 'Age7', 'Age8.9', 'Height1', 'Height2', 'Height3', 'Height4', 'Height5',\n",
    "                'Weight1', 'Weight2', 'Weight3', 'Weight4', 'Weight5', 'Asian', 'Black.or.African.American', 'Unknown.Race',\n",
    "                'X.1..1', 'X.1..3', 'X.2..2', 'X.2..3', 'X.3..3', 'Unknown.Cyp2C9', 'VKORC1.A.G', 'VKORC1.A.A', 'VKORC1.Missing']]\n",
    "    real = df[['y0', 'y1', 'y2']]\n",
    "    train_t = df['t']\n",
    "    train_y = df['y']\n",
    "    return train_X, train_t, train_y, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_v2(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    train_X = df.iloc[:, :3]\n",
    "    real = df.iloc[:, 3:5]\n",
    "    train_t = df.iloc[:, 5]\n",
    "    train_y = df.iloc[:, 7]\n",
    "    return train_X, train_t, train_y, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoint_tree(node, i, test_X, test_real, test_t):\n",
    "    if node in L: #if datapoint has reached leaf node, calculate error\n",
    "        index = treatments[node]\n",
    "        ideal_outcome = max(test_real.iloc[i, :])\n",
    "        difference = ideal_outcome - test_real.iloc[i, int(index)]\n",
    "        #print(test_real.iloc[i, index])\n",
    "        if difference == 0:\n",
    "            count_optimal = 1\n",
    "        else:\n",
    "            count_optimal = 0\n",
    "        \n",
    "        if index == test_t[i]:\n",
    "            same_treatment = 1\n",
    "        else:\n",
    "            same_treatment = 0\n",
    "        return difference, count_optimal, same_treatment\n",
    "    if test_X.iloc[i, branching[node]] <= 0: # go left (node 2)\n",
    "        return datapoint_tree(tree.get_left_children(node), i, test_X, test_real, test_t)\n",
    "    else:\n",
    "        return datapoint_tree(tree.get_right_children(node), i, test_X, test_real, test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_X, test_real, test_t):\n",
    "    difference = 0\n",
    "    count_optimal = 0\n",
    "    count_same = 0\n",
    "    for i in range(len(test_X)):\n",
    "        diff, optimal, treat = datapoint_tree(1, i, test_X, test_real, test_t)\n",
    "        difference += diff\n",
    "        count_optimal += optimal\n",
    "        count_same += treat\n",
    "    return difference, float(count_optimal)/len(test_X), float(count_same)/len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring variables determined a-priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Specfiying Input to Model\n",
    "- m treatments indexed by t {1,..., m}\n",
    "- n datapoints indexed by i {(X1, T1, Y1), ..., (Xn, Tn, Yn)} \n",
    "- d: depth of decision tree\n",
    "- n_min: minimum number of datapoints of each treatment in node p\n",
    "- num_features\n",
    "- num_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tree(depth, bert):\n",
    "    delta_include = False\n",
    "    different_Cp = False\n",
    "    bertsimas = bert\n",
    "\n",
    "    m = {0, 1, 2}\n",
    "    n = len(train_X)\n",
    "    d = int(depth)\n",
    "    n_min = 0\n",
    "    num_features = 2\n",
    "    num_cuts = 2\n",
    "\n",
    "    \"\"\"# ---- CONSTRUCTING COMPLETE BINARY TREE ----\n",
    "    # - P = number of nodes in the tree\n",
    "    # - L_c = set of non-leaf nodes\n",
    "    # - L = set of leaf ndoes\"\"\"\n",
    "\n",
    "    P = 2**d\n",
    "    L_c = set(range(1, 2**(d-1)))\n",
    "    L = set(range(2**(d-1), P))\n",
    "\n",
    "    # - ancestors: dictionary {leaf nodes: {set of ancestors}}\n",
    "    ancestors = {}\n",
    "    for p in L:\n",
    "        ancestors[p] = [math.floor(p/(2**j)) for j in range(1, d)]\n",
    "\n",
    "        # Alternative way of retrieving right/left ancestors\n",
    "    tree = Tree(d)\n",
    "    right_left = tree.get_right_left()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    - C[p]: finite set of cuts on node p--determined apriori {(l, theta)}\n",
    "        Representation: dictionary {non-leaf node: list of (l, theta)}\n",
    "        Require a list instead of set so it's ordered (indexed easily)\n",
    "\n",
    "\n",
    "    From Kallus' paper, he wants us to:\n",
    "    1. For each l in [d], sort data along x_l\n",
    "    2a. For each non-leaf node, pick #features from [d] randomly\n",
    "    2b. Set J = {1, (n-1/#cuts), ..., n-1} in decreasing order of cuts\n",
    "    2c. Set Cp = {(l, midpoint between the two buckets in J) for all dimensions chosen and for all j in J}\n",
    "\n",
    "    Make version of ALG3 to take all features\"\"\"\n",
    "\n",
    "\n",
    "    if different_Cp:\n",
    "        pass\n",
    "    else:\n",
    "        # -- BINARY COVARIATES --> Create a finite set of cuts for C for all features --\n",
    "        C = []\n",
    "        for i in range(len(train_X.columns)):\n",
    "            C.append((i, 0))\n",
    "\n",
    "\n",
    "    \"\"\" --- OTHER DATA --- \n",
    "    BIG M Constraints:\n",
    "    - Ybar\n",
    "    - Ymax\n",
    "    - M\n",
    "\n",
    "    BINARY ENCODING FOR CUTS\n",
    "    - k_p: dictionary {non-leaf node p: k_p value}\n",
    "    - Z_p: dictionary {non-leaf node p: k_p x |C_p| 2d matrix}\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Big M Constraints ----\n",
    "    # Ybar is merged into data, but it could not be. ybar is a numpy array\n",
    "    minimum = min(train_y)\n",
    "\n",
    "    ybar = train_y - minimum\n",
    "    #data['ybar'] = ybar\n",
    "\n",
    "    # Ymax\n",
    "    ymax = max(ybar)\n",
    "\n",
    "    # M\n",
    "    # Find all sums for treatments 1, ..., m\n",
    "    #treatment_counts = treatment.value_counts().to_list()\n",
    "    unique, counts = np.unique(train_t, return_counts=True)\n",
    "    #frequencies = numpy.asarray((unique, counts)).T\n",
    "    M = np.array(counts)\n",
    "    M -= len(L) * n_min\n",
    "    M = max(M)\n",
    "    \n",
    "    model = gp.Model(\"Kallus\")\n",
    "    #model.params.TimeLimit = 3600\n",
    "\n",
    "    # -- VARIABLE DECLARATION --\n",
    "\n",
    "    # -- Variables to determine: gamma and lambda --\n",
    "    # 1. gamma_p = choice of cut at node p ([0, 1]^C_p) (only applies to non-leaf node)\n",
    "    #       - represent with a matrix gamma (|L_c| x |C_p|)\n",
    "\n",
    "    gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "    # This assumes gamma is binary\n",
    "    #gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "\n",
    "    # 2. lambda_pt = choice of treatment t at node p (only applies to leaf nodes L)\n",
    "    #       - represent with a matrix lamb (|L| x m)\n",
    "    lamb = model.addVars(L, m, vtype=GRB.BINARY, name='lamb')\n",
    "\n",
    "\n",
    "    # -- Other Variables in Formulation --\n",
    "    # 1. w_ip = membership of datapoint i in node p (only applies to leaf nodes L)\n",
    "    #       - represent with a matrix w (n x |L|)\n",
    "\n",
    "    w = model.addVars(n, L, lb=0, ub=1, name='w')\n",
    "    # This assumes w is binary, when in reality it is continuous from 0-1\n",
    "    #w = model.addVars(n, L, vtype=GRB.BINARY, name='w') # Original paper has this be a continuous variable\n",
    "\n",
    "    # 2. mu_p = mean outcome of prescribed treatment in node p\n",
    "    #       - represent with a matrix mu (|L|)\n",
    "    mu = model.addVars(L, lb=0, name='mu') # define in constraint\n",
    "\n",
    "    # 3. nu_ip = \"effect\" of treatment in node p by multiplying mu and w\n",
    "    #       - represent with a matrix nu (n x |L|)\n",
    "    nu = model.addVars(n, L, lb=0, name='nu')\n",
    "\n",
    "    # 4. delta_p = forces only 1 choice of cut at node p\n",
    "    #       - represent with a dictionary {non-leaf node p: 1d matrix of size k_p}\n",
    "    #delta = model.addVars(L, k, vtype=GRB.BINARY, name='delta')\n",
    "\n",
    "    # 5. Chi_i(gamma) = 1 if choice of cut induces datapoint i to go left on the cut gamma, 0 otherwise\n",
    "    chi = model.addVars(L_c, n, vtype=GRB.BINARY, name='chi')\n",
    "\n",
    "    if bertsimas:\n",
    "        # 6. f_i\n",
    "        f = model.addVars(n, lb=0, name='f')\n",
    "\n",
    "        # 7. Beta_lt\n",
    "        beta = model.addVars(L, m, lb=0, name='beta')\n",
    "\n",
    "    theta = 0.5\n",
    "    \n",
    "        # --- OBJECTIVE FUNCTION ---\n",
    "    if bertsimas:\n",
    "        model.setObjective(theta * gp.quicksum(nu[i, p] for i in range(n) for p in L) \n",
    "                       - (1-theta) * gp.quicksum((train_y[i] - f[i]) * (train_y[i] - f[i]) for i in range(n)), GRB.MAXIMIZE)\n",
    "    else:\n",
    "        model.setObjective(gp.quicksum(nu[i, p] for i in range(n) for p in L), GRB.MAXIMIZE)\n",
    "\n",
    "\n",
    "    # --- CONSTRAINTS ---\n",
    "    # Constraint 4c (4b is done by definition of variables)\n",
    "    if delta_include:\n",
    "        for p in L_c:\n",
    "            # need to do matrix multiplication somehow, but this might work?\n",
    "            for j in range(k):\n",
    "                model.addConstr(delta[p, j] == gp.quicksum(gamma[p, i] * z[j, i] for i in range(len(C))))\n",
    "\n",
    "    # Additional constraint that gamma[p] adds up to 1\n",
    "    # CHECKED\n",
    "    for p in L_c:\n",
    "        model.addConstr(gp.quicksum(gamma[p, i] for i in range(len(C))) == 1)\n",
    "\n",
    "    # Add constraint Chi\n",
    "    for i in range(n):\n",
    "        for p in L_c:\n",
    "            model.addConstr(chi[p, i] == gp.quicksum(gamma[p, j] for j in range(len(C)) if C[j][1] >= train_X.iloc[i, C[j][0]]))\n",
    "\n",
    "\n",
    "    # Constraint 4d&e (Membership restriction from its ancestors) CHECKED\n",
    "    for p in L:\n",
    "        A_p = ancestors[p] #index ancestors of p\n",
    "        for q in A_p:\n",
    "            R_pq = right_left[(p, q)]\n",
    "            for i in range(n):\n",
    "                model.addConstr(w[i, p] <= (1+R_pq)/2 - R_pq * chi[q, i])\n",
    "\n",
    "\n",
    "    #4e CHECKED\n",
    "    for p in L:\n",
    "        A_p = ancestors[p] #index ancestors of p\n",
    "        for i in range(n):\n",
    "            model.addConstr(w[i, p] >= 1 + gp.quicksum(-chi[q, i] for q in A_p if right_left[(p, q)] == 1)\n",
    "                        + gp.quicksum(-1+chi[q, i] for q in A_p if right_left[(p, q)] == -1))\n",
    "\n",
    "\n",
    "    # Constraint 4f\n",
    "    # CHECKED\n",
    "    for t in m:\n",
    "        for p in L:\n",
    "            model.addConstr(gp.quicksum(w[i, p] for i in range(n) if train_t[i] == t) >= n_min) #assuming the input comes in vector (Xi, Ti, Yi)\n",
    "            # only add the datapoints that have been given treatment t\n",
    "\n",
    "    # Constraints 4g&h (Linearization of nu)\n",
    "    # CHECKED\n",
    "    for p in L:\n",
    "        for i in range(n):\n",
    "            model.addConstr(nu[i, p] <= ymax * w[i, p])\n",
    "            model.addConstr(nu[i, p] <= mu[p])\n",
    "            model.addConstr(nu[i, p] >= mu[p] - ymax * (1-w[i, p]))\n",
    "\n",
    "    # Constraint 4i (Choice of treatment applied to p)\n",
    "    # CHECKED\n",
    "    for p in L:\n",
    "        model.addConstr(gp.quicksum(lamb[p, t] for t in m) == 1)\n",
    "\n",
    "    # Constraint 4j&k (Consistency between lambda and mu)\n",
    "    # CHECKED. There are some inconsistencies where some w don't appear, but this is because ybar is 0 (i.e. the minimum)\n",
    "    for p in L:\n",
    "        for t in m:\n",
    "            model.addConstr(gp.quicksum(nu[i, p] - w[i, p] * ybar[i] for i in range(n) if train_t[i] == t) <= M*(1-lamb[p, t]))\n",
    "            model.addConstr(gp.quicksum(nu[i, p] - w[i, p] * ybar[i] for i in range(n) if train_t[i] == t) >= M*(lamb[p, t]-1))\n",
    "    #model.addConstr(lamb[2, 0] == 1)\n",
    "    if bertsimas:\n",
    "        for i in range(n):\n",
    "            for p in L:\n",
    "                for t in m:\n",
    "                    if train_t[i] == t:\n",
    "                        model.addConstr(f[i] - beta[p, t] <= M * (1-w[i, p]))\n",
    "                        model.addConstr(f[i] - beta[p, t] >= M * (w[i, p]-1))\n",
    "    \n",
    "    #model.params.TimeLimit = 3600\n",
    "    timeLimit = 3600\n",
    "    oldSolutionLimit = model.Params.SolutionLimit\n",
    "    model.Params.SolutionLimit = 1\n",
    "    model.optimize()\n",
    "    model.Params.TimeLimit = timeLimit - model.getAttr(GRB.Attr.Runtime)\n",
    "    model.Params.SolutionLimit = oldSolutionLimit - model.Params.SolutionLimit\n",
    "    model.optimize()\n",
    "    \n",
    "    \n",
    "    #model.optimize()\n",
    "    g = model.getAttr(\"X\", gamma).items()\n",
    "    l = model.getAttr(\"X\", lamb).items()\n",
    "    \n",
    "    branching = {i[0][0]: i[0][1] for i in g if i[1] == 1.0}\n",
    "    treatments = {i[0][0]: i[0][1] for i in l if i[1] == 1.0}\n",
    "    \n",
    "    return branching, treatments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'bertsimas_athey_500.csv' does not exist: b'bertsimas_athey_500.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d2b3b115bc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbertsimas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bertsimas_athey_500.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'bertsimas_athey_500.csv' does not exist: b'bertsimas_athey_500.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"kallus = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                               'Train % Same Treatment', 'Tree'])\n",
    "bertsimas = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                                  'Train % Same Treatment', 'Tree'])\"\"\"\n",
    "\n",
    "\n",
    "#bertsimas = pd.read_csv('bertsimas_athey_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed value of parameter SolutionLimit to 1\n",
      "   Prev: 2000000000  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 54043 rows, 22097 columns and 249634 nonzeros\n",
      "Model fingerprint: 0x7dc4d0bd\n",
      "Variable types: 16004 continuous, 6093 integer (6093 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 9e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 9e+02]\n",
      "Presolve removed 7026 rows and 3263 columns\n",
      "Presolve time: 1.98s\n",
      "Presolved: 47017 rows, 18834 columns, 194314 nonzeros\n",
      "Variable types: 14124 continuous, 4710 integer (4710 binary)\n",
      "Found heuristic solution: objective 611.5384615\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 2.33 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 611.538 \n",
      "\n",
      "Solution limit reached\n",
      "Best objective 6.115384615384e+02, best bound 8.000000000000e+03, gap 1208.1761%\n",
      "Changed value of parameter TimeLimit to 3597.6593520641327\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter SolutionLimit to 1999999999\n",
      "   Prev: 1  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 54043 rows, 22097 columns and 249634 nonzeros\n",
      "Model fingerprint: 0x7dc4d0bd\n",
      "Variable types: 16004 continuous, 6093 integer (6093 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 9e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 9e+02]\n",
      "Presolved: 47017 rows, 18834 columns, 194314 nonzeros\n",
      "\n",
      "Continuing optimization...\n",
      "\n",
      "\n",
      "Root relaxation: objective 3.996000e+03, 24271 iterations, 1.50 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "H    0     2                    1189.1063830 8000.00000   573%     -  815s\n",
      "     0     2 3996.00000    0 4626 1189.10638 3996.00000   236%     -  815s\n",
      "     1     4 3611.00000    1 3570 1189.10638 3834.50000   222% 33097  841s\n",
      "H    3     8                    1620.5904353 3611.00000   123% 14161  858s\n",
      "     7    12 3456.00000    3 3225 1620.59044 3587.50000   121%  7959  862s\n",
      "    11    16 3300.00000    4 2787 1620.59044 3587.50000   121%  5365  869s\n",
      "    15    20 2880.00000    5 2316 1620.59044 3587.50000   121%  4153  878s\n",
      "    19    24 2804.00000    6 2157 1620.59044 3587.50000   121%  3366  882s\n",
      "    23    31 2661.00000    7 1815 1620.59044 3587.50000   121%  2881  885s\n",
      "H   30    33                    1628.4372294 3587.50000   120%  2309  889s\n",
      "    36    38 2000.00000    8    8 1628.43723 3587.50000   120%  2064  891s\n",
      "    55    53 1980.78824   11 1038 1628.43723 3587.50000   120%  1548  895s\n",
      "    71    60     cutoff   13      1628.43723 3587.50000   120%  1401  901s\n",
      "    86    63 1724.67961   15    4 1628.43723 3455.00000   112%  1254  909s\n",
      "   100    71 2584.90569    4 2401 1628.43723 3455.00000   112%  1208  914s\n",
      "H  108    71                    1662.2439571 3455.00000   108%  1157  914s\n",
      "   110    77 2416.79206    5 1931 1662.24396 3455.00000   108%  1169  917s\n",
      "   116    88 2000.00000    6 1526 1662.24396 3455.00000   108%  1167  920s\n",
      "H  141   107                    1663.4263379 3455.00000   108%  1103  927s\n",
      "   174   118     cutoff   20      1663.42634 3455.00000   108%   986  940s\n",
      "   214   139     cutoff   20      1663.42634 3455.00000   108%   873  948s\n",
      "H  239   139                    1664.2403926 3455.00000   108%   816  955s\n",
      "   256   143 1702.16511   20    2 1664.24039 3455.00000   108%   792  960s\n",
      "   290   146     cutoff   21      1664.24039 3455.00000   108%   747  971s\n",
      "H  299   146                    1664.3404762 3455.00000   108%   728  971s\n",
      "   309   158     cutoff   23      1664.34048 3455.00000   108%   731  980s\n",
      "   348   162     cutoff   24      1664.34048 3455.00000   108%   702  990s\n",
      "   364   170     cutoff   24      1664.34048 2527.00000  51.8%   688  999s\n",
      "   400   195 2000.00000    5 1031 1664.34048 2527.00000  51.8%   677 1005s\n",
      "   450   201     cutoff   17      1664.34048 2527.00000  51.8%   646 1010s\n",
      "   479   203     cutoff   17      1664.34048 2361.00000  41.9%   642 1026s\n",
      "H  482   203                    1665.6869048 2361.00000  41.7%   645 1026s\n",
      "   485   214 2000.00000   10    6 1665.68690 2361.00000  41.7%   642 1031s\n",
      "H  527   221                    1673.9011905 2361.00000  41.0%   630 1039s\n",
      "   550   227 1889.90767   13 1541 1673.90119 2361.00000  41.0%   639 1046s\n",
      "   584   226 1829.00000   13 1546 1673.90119 2361.00000  41.0%   625 1052s\n",
      "   601   246 1870.21951   14 1256 1673.90119 2361.00000  41.0%   621 1084s\n",
      "   650   240 1707.82230   25 1607 1673.90119 2361.00000  41.0%   597 1093s\n",
      "   702   252 1693.32914   26 1547 1673.90119 2361.00000  41.0%   582 1117s\n",
      "H  704   252                    1675.2711779 2361.00000  40.9%   581 1117s\n",
      "   722   263     cutoff   26      1675.27118 2361.00000  40.9%   583 1126s\n",
      "   767   262 1691.65334   27 1372 1675.27118 2361.00000  40.9%   581 1145s\n",
      "   777   273     cutoff   27      1675.27118 2328.53426  39.0%   582 1155s\n",
      "   838   285 2059.36914    7 1572 1675.27118 2304.38415  37.6%   576 1235s\n",
      "H  852   285                    1677.9148673 2304.38415  37.3%   574 1235s\n",
      "   858   299 1955.10521    8 2808 1677.91487 2304.38415  37.3%   579 1244s\n",
      "   936   317     cutoff    9      1677.91487 2304.38415  37.3%   557 1257s\n",
      "   962   320 1682.85908   11  902 1677.91487 2259.11885  34.6%   561 1271s\n",
      "  1028   329 2061.09489    9 2787 1677.91487 2258.86845  34.6%   552 1280s\n",
      "  1079   351 1962.45927   12 2877 1677.91487 2145.92201  27.9%   549 1293s\n",
      "  1161   359 2000.00000    9  775 1677.91487 2060.89502  22.8%   543 1303s\n",
      "  1200   369 1891.78744   10 1329 1677.91487 2060.89502  22.8%   544 1315s\n",
      "  1241   370     cutoff   14      1677.91487 2060.89502  22.8%   536 1327s\n",
      "  1310   383 1839.08598   11 2178 1677.91487 2000.00000  19.2%   538 1340s\n",
      "  1396   426 1760.12566   11  318 1677.91487 2000.00000  19.2%   532 1364s\n",
      "  1570   466 1973.41232   12 1547 1677.91487 2000.00000  19.2%   527 1390s\n",
      "  1752   512 1879.47620   10 1107 1677.91487 2000.00000  19.2%   515 1413s\n",
      "  1878   530     cutoff   15      1677.91487 2000.00000  19.2%   522 1434s\n",
      "  2038   554 1731.83698   17 1418 1677.91487 2000.00000  19.2%   517 1455s\n",
      "  2166   572 1800.29631   14 1262 1677.91487 2000.00000  19.2%   515 1481s\n",
      "  2336   589     cutoff   19      1677.91487 2000.00000  19.2%   515 1497s\n",
      "  2512   619     cutoff   13      1677.91487 2000.00000  19.2%   510 1514s\n",
      "  2668   638 1926.35710   11  904 1677.91487 2000.00000  19.2%   508 1529s\n",
      "  2815   649 1808.95652   13  458 1677.91487 2000.00000  19.2%   506 1546s\n",
      "H 2910   623                    1695.0867965 2000.00000  18.0%   505 1546s\n",
      "  2945   650 1847.34199   12  904 1695.08680 2000.00000  18.0%   505 1562s\n",
      "  3069   655 1867.19306   14  791 1695.08680 2000.00000  18.0%   505 1589s\n",
      "  3185   665 1729.06851   18 1114 1695.08680 2000.00000  18.0%   505 1619s\n",
      "  3229   714     cutoff   19      1695.08680 1980.69056  16.8%   505 1641s\n",
      "  3393   742     cutoff   18      1695.08680 1977.33466  16.7%   502 1658s\n",
      "  3508   767 1761.46872   18 1631 1695.08680 1971.54631  16.3%   501 1679s\n",
      "  3665   766 1759.65924   19 1329 1695.08680 1969.30732  16.2%   498 1701s\n",
      "  3802   778     cutoff   11      1695.08680 1958.32576  15.5%   499 1720s\n",
      "  3931   802 1745.54950   17 2032 1695.08680 1953.20331  15.2%   501 1740s\n",
      "  4073   814     cutoff   21      1695.08680 1949.72632  15.0%   500 1767s\n",
      "  4252   815 1944.12516   10 1280 1695.08680 1946.34644  14.8%   497 1782s\n",
      "  4254   816 1917.32685   12 2475 1695.08680 1946.34644  14.8%   496 1789s\n",
      "  4256   818 1922.86885   13 2475 1695.08680 1946.34644  14.8%   496 1800s\n",
      "  4257   821 1946.34644   16 2042 1695.08680 1946.34644  14.8%   500 1820s\n",
      "  4263   827 1946.34644   18 1979 1695.08680 1946.34644  14.8%   501 1827s\n",
      "  4267   830 1946.34644   18 1614 1695.08680 1946.34644  14.8%   501 1830s\n",
      "  4279   838 1946.34644   20 1469 1695.08680 1946.34644  14.8%   502 1836s\n",
      "  4283   841 1946.34644   20 1697 1695.08680 1946.34644  14.8%   502 1841s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4287   844 1946.34644   21 1490 1695.08680 1946.34644  14.8%   503 1845s\n",
      "  4296   849 1946.34644   22  969 1695.08680 1946.34644  14.8%   504 1852s\n",
      "  4300   852 1946.34644   22 1293 1695.08680 1946.34644  14.8%   505 1855s\n",
      "  4304   859 1946.34644   23  969 1695.08680 1946.34644  14.8%   505 1861s\n",
      "  4317   870 1946.34644   24  782 1695.08680 1946.34644  14.8%   507 1870s\n",
      "  4341   883 1946.34644   28    9 1695.08680 1946.34644  14.8%   508 1876s\n",
      "  4363   892 1811.66463   32    4 1695.08680 1946.34644  14.8%   509 1883s\n",
      "  4378   885     cutoff   33      1695.08680 1946.34644  14.8%   508 1889s\n",
      "  4388   888 1946.34644   20 1191 1695.08680 1946.34644  14.8%   509 1896s\n",
      "  4405   905 1946.34644   21    8 1695.08680 1946.34644  14.8%   510 1903s\n",
      "  4423   906 1889.93831   24    4 1695.08680 1946.34644  14.8%   511 1914s\n",
      "  4442   907 1733.14402   28  830 1695.08680 1946.34644  14.8%   512 1926s\n",
      "  4459   908     cutoff   30      1695.08680 1946.34644  14.8%   513 1932s\n",
      "  4476   911 1946.34644   20 1742 1695.08680 1946.34644  14.8%   514 1948s\n",
      "  4487   911 1946.34644   21 1756 1695.08680 1946.34644  14.8%   514 1952s\n",
      "  4514   904 1946.34644   22 1701 1695.08680 1946.34644  14.8%   513 1958s\n",
      "  4526   904 1946.34644   23 1977 1695.08680 1946.34644  14.8%   512 1963s\n",
      "  4552   901 1946.34644   24 1339 1695.08680 1946.34644  14.8%   512 1968s\n",
      "  4575   913 1946.34644   26  962 1695.08680 1946.34644  14.8%   511 1977s\n",
      "  4616   908 1717.90783   29 1001 1695.08680 1946.34644  14.8%   509 1987s\n",
      "  4628   914     cutoff   30      1695.08680 1946.34644  14.8%   510 1992s\n",
      "  4660   909     cutoff   32      1695.08680 1946.34644  14.8%   510 2005s\n",
      "  4668   922     cutoff   33      1695.08680 1946.34644  14.8%   510 2018s\n",
      "  4711   919 1946.34644   22 2213 1695.08680 1946.34644  14.8%   510 2025s\n",
      "  4755   914 1946.34644   23 1573 1695.08680 1946.34644  14.8%   509 2032s\n",
      "  4775   916 1941.90547   25  303 1695.08680 1946.34644  14.8%   509 2042s\n",
      "  4818   918 1946.34644   22    7 1695.08680 1946.34644  14.8%   510 2053s\n",
      "  4869   923 1946.34644   22 1426 1695.08680 1946.34644  14.8%   508 2069s\n",
      "  4912   917 1946.34644   25  153 1695.08680 1946.34644  14.8%   509 2077s\n",
      "  4942   923 1709.84383   30    4 1695.08680 1946.34644  14.8%   509 2087s\n",
      "  4988   912 1946.34644   25  942 1695.08680 1946.34644  14.8%   509 2110s\n",
      "  5011   919 1946.34644   23 1835 1695.08680 1946.34644  14.8%   509 2124s\n",
      "  5047   923 1946.34644   25 1304 1695.08680 1946.34644  14.8%   508 2135s\n",
      "  5075   930 1946.34644   21  717 1695.08680 1946.34644  14.8%   510 2150s\n",
      "  5138   923 1946.34644   22    8 1695.08680 1946.34644  14.8%   508 2160s\n",
      "  5200   918 1946.34644   22    8 1695.08680 1946.34644  14.8%   507 2175s\n",
      "  5266   918     cutoff   31      1695.08680 1946.34644  14.8%   506 2185s\n",
      "  5315   916 1946.34644   22  809 1695.08680 1946.34644  14.8%   505 2196s\n",
      "  5362   911     cutoff   26      1695.08680 1946.34644  14.8%   507 2214s\n",
      "  5456   884 1771.20000   26    4 1695.08680 1946.34644  14.8%   505 2225s\n",
      "  5516   873 1776.63530   27  142 1695.08680 1946.34644  14.8%   506 2235s\n",
      "  5583   867 1903.20000   26  976 1695.08680 1946.34644  14.8%   506 2247s\n",
      "  5637   872 1946.34644   24 1961 1695.08680 1946.34644  14.8%   506 2257s\n",
      "  5701   877 1938.30362   26 1769 1695.08680 1946.34644  14.8%   506 2273s\n",
      "  5789   847     cutoff   28      1695.08680 1946.34644  14.8%   506 2288s\n",
      "  5890   831 1946.34644   26  816 1695.08680 1946.34644  14.8%   504 2309s\n",
      "  5945   851 1946.34644   28    6 1695.08680 1946.34644  14.8%   504 2322s\n",
      "  6040   839 1718.68363   31  819 1695.08680 1946.34644  14.8%   503 2335s\n",
      "  6143   823 1946.34644   28  390 1695.08680 1946.34644  14.8%   503 2348s\n",
      "  6238   809     cutoff   26      1695.08680 1946.34644  14.8%   503 2361s\n",
      "  6302   808 1735.84848   29  245 1695.08680 1946.34644  14.8%   502 2378s\n",
      "  6449   776     cutoff   27      1695.08680 1946.34644  14.8%   500 2391s\n",
      "  6577   778     cutoff   27      1695.08680 1946.34644  14.8%   499 2407s\n",
      "  6723   773 1946.34644   25    6 1695.08680 1946.34644  14.8%   499 2422s\n",
      "  6870   807 1723.86255   28  248 1695.08680 1946.34644  14.8%   499 2437s\n",
      "  7006   833     cutoff   35      1695.08680 1946.34644  14.8%   498 2461s\n",
      "  7163   859 1946.34644   29    7 1695.08680 1946.34644  14.8%   496 2486s\n",
      "  7309   870 1946.34644   25 1011 1695.08680 1946.34644  14.8%   496 2519s\n",
      "  7357   915 1946.34644   28  763 1695.08680 1946.34644  14.8%   496 2545s\n",
      "  7572   994 1796.29654   31  794 1695.08680 1946.34644  14.8%   493 2576s\n",
      "  7795  1051 1733.91706   31  880 1695.08680 1946.34644  14.8%   491 2605s\n",
      "  8047  1099     cutoff   28      1695.08680 1946.34644  14.8%   488 2634s\n",
      "  8287  1146 1946.34644   29  458 1695.08680 1946.34644  14.8%   486 2664s\n",
      "  8502  1178 1816.59186   29  822 1695.08680 1946.34644  14.8%   484 2699s\n",
      "  8720  1208 1946.34644   32  299 1695.08680 1946.34644  14.8%   482 2740s\n",
      "  8944  1271 1868.41379   26  411 1695.08680 1946.34644  14.8%   480 2772s\n",
      "  9184  1329 1703.27725   37 1003 1695.08680 1946.34644  14.8%   477 2808s\n",
      "  9466  1377 1946.34644   28  978 1695.08680 1946.34644  14.8%   476 2847s\n",
      "  9792  1446 1733.86421   36  175 1695.08680 1946.34644  14.8%   472 2884s\n",
      " 10105  1495 1946.34644   23  791 1695.08680 1946.34644  14.8%   468 2925s\n",
      " 10376  1561 1912.28190   31  494 1695.08680 1946.34644  14.8%   468 2979s\n",
      " 10754  1577 1946.34644   27 1057 1695.08680 1946.34644  14.8%   466 3004s\n",
      " 10949  1621     cutoff   34      1695.08680 1946.34644  14.8%   466 3025s\n",
      " 11114  1665     cutoff   35      1695.08680 1946.34644  14.8%   467 3045s\n",
      " 11536  1699     cutoff   29      1695.08680 1946.34644  14.8%   464 3063s\n",
      " 11802  1746 1946.34644   33  430 1695.08680 1946.34644  14.8%   462 3083s\n",
      " 12130  1780 1852.37805   32  306 1695.08680 1946.34644  14.8%   461 3105s\n",
      " 12434  1827     cutoff   27      1695.08680 1946.34644  14.8%   461 3126s\n",
      " 12830  1833     cutoff   31      1695.08680 1946.34644  14.8%   457 3169s\n",
      " 13185  1881 1719.72449   35  183 1695.08680 1946.34644  14.8%   456 3192s\n",
      " 13568  1890 1705.82857   28  164 1695.08680 1946.34644  14.8%   456 3218s\n",
      " 13975  1870     cutoff   37      1695.08680 1946.34644  14.8%   455 3246s\n",
      " 14400  1881 1736.55507   32  493 1695.08680 1946.34644  14.8%   455 3274s\n",
      " 14875  1892 1728.73497   33  179 1695.08680 1946.34644  14.8%   454 3314s\n",
      " 15586  1949 1801.00000   32  877 1695.08680 1946.34644  14.8%   454 3348s\n",
      " 16277  1958 1728.73497   31  179 1695.08680 1946.34644  14.8%   451 3381s\n",
      " 16352  2044 1788.88153   31  177 1695.08680 1946.34644  14.8%   451 3413s\n",
      " 17000  2109 1797.50202   33  772 1695.08680 1946.34644  14.8%   449 3444s\n",
      " 17530  2190     cutoff   29      1695.08680 1946.34644  14.8%   448 3470s\n",
      " 18113  2264 1742.65690   29  186 1695.08680 1946.34644  14.8%   446 3494s\n",
      " 18541  2264 1804.17951   33    4 1695.08680 1946.34644  14.8%   445 3495s\n",
      " 18671  2273 1946.34644   28  425 1695.08680 1946.34644  14.8%   445 3520s\n",
      " 19177  2316 1744.43820   34  539 1695.08680 1946.34644  14.8%   444 3546s\n",
      " 19656  2322 1699.75857   34  529 1695.08680 1946.34644  14.8%   443 3571s\n",
      " 20052  2313 1936.82964   28  450 1695.08680 1946.34644  14.8%   443 3592s\n",
      " 20513  2317 1800.19319   33  858 1695.08680 1946.34644  14.8%   441 3600s\n",
      "\n",
      "Explored 20686 nodes (9124250 simplex iterations) in 3597.72 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 1695.09 1677.91 1675.27 ... 1628.44\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.695086796537e+03, best bound 1.946346439223e+03, gap 14.8228%\n",
      "[3, 3, 0.6, 872, 63.45347862531433, 44.80301760268232, 714, 64.3, 45.5, 'branching = {1: 25, 2: 23, 3: 1}, treatments = {4: 1, 5: 0, 6: 0, 7: 1}']\n"
     ]
    }
   ],
   "source": [
    "kallus = pd.DataFrame(columns=['Dataset','Depth','P(Correct Treatment)','Test Error','Test % Optimal',\n",
    "                               'Test % Same Treatment', 'Train Error', 'Train % Optimal', \n",
    "                               'Train % Same Treatment', 'Tree'])\n",
    "\n",
    "\n",
    "prob = 0.6\n",
    "bert = False\n",
    "\n",
    "depths = [3]\n",
    "datasets = [3]\n",
    "#probs = [0.1, 0.5, 0.9]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for d in depths:\n",
    "        train_filepath = 'data/Warfarin/Warfarin_0.6_2000/data_train_enc_' + str(dataset) + '.csv'\n",
    "        test_filepath = 'data/Warfarin/Warfarin_0.6_2000/data_test_enc_' + str(dataset) + '.csv'\n",
    "        train_X, train_t, train_y, train_real = open_file(train_filepath)\n",
    "        branching, treatments = run_tree(d, bert)\n",
    "\n",
    "        tree = Tree(d)\n",
    "        L = set(range(2**(d-1), 2**d))\n",
    "        test_X, test_t, test_y, test_real = open_file(test_filepath)\n",
    "        error, pct, acc = get_metrics(test_X, test_real, test_t)\n",
    "        error1, pct1, acc1 = get_metrics(train_X, train_real, train_t)\n",
    "\n",
    "        tree_stats = 'branching = ' + str(branching) + ', treatments = ' + str(treatments)\n",
    "        row = [dataset, d, prob, error, pct*100, acc*100, error1, pct1*100, acc1*100, tree_stats]\n",
    "        print(row)\n",
    "        if bert:\n",
    "            bertsimas.loc[len(bertsimas)] = row\n",
    "        else:\n",
    "            kallus.loc[len(kallus)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kallus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kallus.to_csv('Results_Warfarin/kallus_0.85.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed value of parameter SolutionLimit to 1\n",
      "   Prev: 2000000000  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 8010 rows, 4004 columns and 22397 nonzeros\n",
      "Model fingerprint: 0x5dd805c3\n",
      "Variable types: 4001 continuous, 3 integer (3 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 8e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 8e+02]\n",
      "Presolve removed 8010 rows and 4004 columns\n",
      "Presolve time: 0.05s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.06 seconds\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 456.48 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.564796905222e+02, best bound 4.564796905222e+02, gap 0.0000%\n",
      "Changed value of parameter TimeLimit to 3599.934494972229\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter SolutionLimit to 1999999999\n",
      "   Prev: 1  Min: 1  Max: 2000000000  Default: 2000000000\n",
      "Gurobi Optimizer version 9.1.0 build v9.1.0rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 8010 rows, 4004 columns and 22397 nonzeros\n",
      "Model fingerprint: 0x5dd805c3\n",
      "Variable types: 4001 continuous, 3 integer (3 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 8e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 8e+02]\n",
      "\n",
      "Loaded MIP start from previous solve with objective -1e+100\n",
      "\n",
      "Presolve removed 8010 rows and 4004 columns\n",
      "Presolve time: 0.06s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.10 seconds\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 456.48 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.564796905222e+02, best bound 4.564796905222e+02, gap 0.0000%\n",
      "[1, 1, 1105, 53.68818105616094, 26.73931265716681, 897, 55.15, 25.85, 'branching = {}, treatments = {1: 1}']\n"
     ]
    }
   ],
   "source": [
    "dataset = 1\n",
    "d = 1\n",
    "bert = False\n",
    "train_filepath = 'data/Warfarin/Warfarin_0.1_2000/data_train_enc_' + str(dataset) + '.csv'\n",
    "test_filepath = 'data/Warfarin/Warfarin_0.1_2000/data_test_enc_' + str(dataset) + '.csv'\n",
    "train_X, train_t, train_y, train_real = open_file(train_filepath)\n",
    "branching, treatments = run_tree(d, bert)\n",
    "\n",
    "tree = Tree(d)\n",
    "L = set(range(2**(d-1), 2**d))\n",
    "test_X, test_t, test_y, test_real = open_file(test_filepath)\n",
    "error, pct, acc = get_metrics(test_X, test_real, test_t)\n",
    "error1, pct1, acc1 = get_metrics(train_X, train_real, train_t)\n",
    "\n",
    "tree_stats = 'branching = ' + str(branching) + ', treatments = ' + str(treatments)\n",
    "row = [dataset, d, error, pct*100, acc*100, error1, pct1*100, acc1*100, tree_stats]\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267.9863312540136 0.4446 0.5066\n",
      "21.252969854711775 0.354 0.5\n"
     ]
    }
   ],
   "source": [
    "tree = Tree(d)\n",
    "L = set(range(2**(d-1), 2**d))\n",
    "test_X, test_t, test_y, test_real = open_file(test_filepath)\n",
    "error, pct, acc = get_metrics(test_X, test_real, test_t)\n",
    "error1, pct1, acc1 = get_metrics(train_X, train_real, train_t)\n",
    "print(error, pct, acc)\n",
    "print(error1, pct1, acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 0.9, 267.9863312540136, 44.46, 50.660000000000004, 21.252969854711775, 35.4, 50.0, 'branching = {1: 10, 2: 16, 3: 0}, treatments = {4: 1, 5: 1, 6: 1, 7: 1}']\n"
     ]
    }
   ],
   "source": [
    "tree_stats = 'branching = ' + str(branching) + ', treatments = ' + str(treatments)\n",
    "row = [dataset, d, prob, error, pct*100, acc*100, error1, pct1*100, acc1*100, tree_stats]\n",
    "if bert:\n",
    "    bertsimas.loc[len(bertsimas)] = row\n",
    "else:\n",
    "    kallus.loc[len(kallus)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset  Depth  P(Correct Treatment)  Test Error  Test % Optimal  \\\n",
      "0         1      2                   0.5   53.227602           76.83   \n",
      "1         1      3                   0.5  123.833930           66.00   \n",
      "2         1      3                   0.5  123.833930           66.00   \n",
      "3         2      2                   0.5   24.915258           84.31   \n",
      "4         2      3                   0.5   24.915258           84.31   \n",
      "5         3      2                   0.5  166.280038           58.61   \n",
      "6         3      3                   0.5   57.544135           77.50   \n",
      "7         4      2                   0.5  432.810829           24.05   \n",
      "8         4      3                   0.5  231.607156           44.69   \n",
      "9         5      2                   0.5  189.645268           55.55   \n",
      "10        5      3                   0.5   36.072978           82.59   \n",
      "11        1      2                   0.9  224.473595           49.78   \n",
      "12        1      3                   0.9  224.473595           49.78   \n",
      "13        2      2                   0.9  216.993310           50.34   \n",
      "14        2      3                   0.9  216.993310           50.34   \n",
      "15        3      2                   0.9  279.888354           41.39   \n",
      "16        3      3                   0.9  290.892989           40.41   \n",
      "17        4      2                   0.9   75.234129           75.97   \n",
      "18        4      3                   0.9   75.234129           75.97   \n",
      "19        5      2                   0.9  267.986331           44.46   \n",
      "20        5      3                   0.9  267.986331           44.46   \n",
      "\n",
      "    Test % Same Treatment  Train Error  Train % Optimal  \\\n",
      "0                   49.33     1.833834             83.0   \n",
      "1                   49.34     2.356756             85.2   \n",
      "2                   49.34     2.356756             85.2   \n",
      "3                   50.46     1.220292             87.8   \n",
      "4                   50.46     1.220292             87.8   \n",
      "5                   49.19     5.115352             75.0   \n",
      "6                   49.48     2.759458             81.4   \n",
      "7                   50.07     2.819187             83.8   \n",
      "8                   50.66     0.674055             91.8   \n",
      "9                   49.63     8.600535             64.8   \n",
      "10                  48.97     0.969443             87.0   \n",
      "11                  50.18     5.508442             73.6   \n",
      "12                  50.18     5.508442             73.6   \n",
      "13                  50.72    15.210286             48.6   \n",
      "14                  50.72    15.210286             48.6   \n",
      "15                  50.68    31.611031             25.0   \n",
      "16                  49.90    31.992727             24.2   \n",
      "17                  49.97    32.501338             16.6   \n",
      "18                  49.97    32.501338             16.6   \n",
      "19                  50.66    21.252970             35.4   \n",
      "20                  50.66    21.252970             35.4   \n",
      "\n",
      "    Train % Same Treatment                                               Tree  \n",
      "0                     51.4      branching = {1: 2}, treatments = {2: 1, 3: 0}  \n",
      "1                     51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "2                     51.4  branching = {1: 16, 2: 5, 3: 12}, treatments =...  \n",
      "3                     49.6      branching = {1: 3}, treatments = {2: 1, 3: 0}  \n",
      "4                     49.6  branching = {1: 3, 2: 13, 3: 15}, treatments =...  \n",
      "5                     48.6     branching = {1: 12}, treatments = {2: 0, 3: 0}  \n",
      "6                     46.6  branching = {1: 5, 2: 14, 3: 12}, treatments =...  \n",
      "7                     52.6     branching = {1: 13}, treatments = {2: 0, 3: 0}  \n",
      "8                     48.0  branching = {1: 7, 2: 10, 3: 13}, treatments =...  \n",
      "9                     51.0     branching = {1: 15}, treatments = {2: 0, 3: 0}  \n",
      "10                    49.2  branching = {1: 15, 2: 7, 3: 5}, treatments = ...  \n",
      "11                    48.4     branching = {1: 15}, treatments = {2: 1, 3: 1}  \n",
      "12                    48.4  branching = {1: 10, 2: 15, 3: 0}, treatments =...  \n",
      "13                    51.2     branching = {1: 14}, treatments = {2: 1, 3: 1}  \n",
      "14                    51.2  branching = {1: 16, 2: 0, 3: 11}, treatments =...  \n",
      "15                    49.4     branching = {1: 15}, treatments = {2: 1, 3: 1}  \n",
      "16                    48.6  branching = {1: 10, 2: 16, 3: 8}, treatments =...  \n",
      "17                    50.0     branching = {1: 14}, treatments = {2: 1, 3: 1}  \n",
      "18                    50.0  branching = {1: 16, 2: 0, 3: 14}, treatments =...  \n",
      "19                    50.0     branching = {1: 16}, treatments = {2: 1, 3: 1}  \n",
      "20                    50.0  branching = {1: 10, 2: 16, 3: 0}, treatments =...  \n"
     ]
    }
   ],
   "source": [
    "print(bertsimas)\n",
    "bertsimas.to_csv('bertsimas_athey_500.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Performance for Athey's Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY: KALLUS on Athey\n",
    "summary = {'Method': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5', 'Dataset 1', \n",
    "                      'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5'],\n",
    "           'Depth': [2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3],\n",
    "           'P(Correct Treatment)': ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.9', '0.9',\n",
    "                                   '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9'],\n",
    "          'Error': [74.67, 74.67, 46.40, 79.86, 145, 109.21, 18.15, 18.15, 152.55, 90.47, 199.70, 238.67, 219.02, \n",
    "                    239.10, 201.21, 201.21, 99.23, 88.12, 196.07, 156.84],\n",
    "          '% Classified': [71.97, 71.97, 78.49, 71.11, 61.22, 68.03, 88.33, 88.33, 60.41, 70.03, 53.35,\n",
    "                          47.49, 49.91, 47.49, 53.42, 53.42, 71.19, 74.11, 54.12, 58.02]}\n",
    "summary = pd.DataFrame(summary)\n",
    "summary.to_csv('kallus_tree_athey.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY: Bertsimas on Athey\n",
    "summary = {'Method': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5', 'Dataset 1', \n",
    "                      'Dataset 1', 'Dataset 2', 'Dataset 2', 'Dataset 3',\n",
    "                     'Dataset 3', 'Dataset 4', 'Dataset 4', 'Dataset 5', 'Dataset 5'],\n",
    "           'Depth': [2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3],\n",
    "           'P(Correct Treatment)': ['0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.5', '0.9', '0.9',\n",
    "                                   '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9', '0.9'],\n",
    "          'Error': [74.67, 74.67, 46.40, 55.17, 145, 109.21, 18.15, 18.15, 152.55, 90.47, 199.70, 154.07, 219.02, \n",
    "                    180.83, 201.21, 116.75, 99.23, 88.12, 196.07, 156.84],\n",
    "          '% Classified': [71.97, 71.97, 78.49, 76.49, 61.22, 68.03, 88.33, 88.33, 60.41, 70.03, 53.35,\n",
    "                          62.17, 49.91, 53.91, 53.42, 71.59, 71.19, 74.11, 54.12, 58.02]}\n",
    "summary = pd.DataFrame(summary)\n",
    "summary.to_csv('bertsimas_tree_athey.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapoint_tree_avg(node, i):\n",
    "    if node in L: #if datapoint has reached leaf node, calculate error\n",
    "        return node\n",
    "    if train_X.iloc[i, branching[node]] <= 0: # go left (node 2)\n",
    "        return datapoint_tree_avg(tree.get_left_children(node), i)\n",
    "    else:\n",
    "        return datapoint_tree_avg(tree.get_right_children(node), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation = {20: 0, 21: 0, 30: 0, 31: 0}\n",
    "count = {20: 0, 21: 0, 30: 0, 31: 0}\n",
    "\n",
    "for i in range(n):\n",
    "    leaf_node = datapoint_tree_avg(1, i)\n",
    "    index = str(leaf_node) + str(train_t[i])\n",
    "    summation[int(index)] += train_y[i]\n",
    "    count[int(index)] += 1\n",
    "    \n",
    "avg = {}\n",
    "for i in summation:\n",
    "    avg[i] = float(summation[i]) / count[i]\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 0.39851651102745433, 3: 0.34277517675515534}\n"
     ]
    }
   ],
   "source": [
    "summation = {2: 0, 3: 0}\n",
    "count = {2: 0, 3: 0}\n",
    "\n",
    "for i in range(n):\n",
    "    leaf_node = datapoint_tree_avg(1, i)\n",
    "    if train_t[i] == treatments[leaf_node]:\n",
    "        summation[leaf_node] += train_y[i]\n",
    "        count[leaf_node] += 1\n",
    "    \n",
    "avg = {}\n",
    "for i in summation:\n",
    "    avg[i] = float(summation[i]) / count[i]\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "N = L.union(L_c)\n",
    "print(N)\n",
    "\n",
    "model = gp.Model(\"Nathan\")\n",
    "\n",
    "# -- VARIABLE DECLARATION --\n",
    "\n",
    "# -- Variables to determine: gamma and lambda --\n",
    "# 1. gamma_p = choice of cut at node p ([0, 1]^C_p) (only applies to non-leaf node)\n",
    "#       - represent with a matrix gamma (|L_c| x |C_p|)\n",
    "\n",
    "gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "# This assumes gamma is binary\n",
    "#gamma = model.addVars(L_c, len(C), vtype=GRB.BINARY, name='gamma') \n",
    "\n",
    "# 2. lambda_pt = choice of treatment t at node p (only applies to leaf nodes L)\n",
    "#       - represent with a matrix lamb (|L| x m)\n",
    "lamb = model.addVars(L, m, vtype=GRB.BINARY, name='lamb')\n",
    "\n",
    "\n",
    "# -- Other Variables in Formulation --\n",
    "# 1. w_ip = membership of datapoint i in node p (only applies to leaf nodes L)\n",
    "#       - represent with a matrix w (n x |L|)\n",
    "\n",
    "c = model.addVars(n, N, vtype=GRB.BINARY, name='c')\n",
    "# This assumes w is binary, when in reality it is continuous from 0-1\n",
    "#w = model.addVars(n, L, vtype=GRB.BINARY, name='w') # Original paper has this be a continuous variable\n",
    "\n",
    "# 2. mu_p = mean outcome of prescribed treatment in node p\n",
    "#       - represent with a matrix mu (|L|)\n",
    "v = model.addVars(n, L_c, vtype=GRB.BINARY, name='v') # define in constraint\n",
    "\n",
    "# 3. nu_ip = \"effect\" of treatment in node p by multiplying mu and w\n",
    "#       - represent with a matrix nu (n x |L|)\n",
    "w = model.addVars(n, vtype=GRB.BINARY, name='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"if different_Cp:\n",
    "# ---- K and Z if we followed the definition of C_p from the paper -----\n",
    "    for p in L_c:\n",
    "        k[p] = math.ceil(math.log2(len(C[p])))\n",
    "\n",
    "    z = {}\n",
    "    for p in L_c:\n",
    "        matrix = np.zeros((k[p], len(C[p])))\n",
    "        print(matrix.shape)\n",
    "        for i in range(1, k[p]+1):\n",
    "            for j in range(1, len(C[p])+1):\n",
    "                if math.floor(j/(2**i)) % 2 == 1: # odd number\n",
    "                    z[i-1, j-1] = 1\n",
    "                else:\n",
    "                    z[i-1, j-1] = 0\n",
    "        z[p] = matrix\n",
    "\n",
    "else:\n",
    "    # ---- K and Z if we had constant C for all nodes ----\n",
    "    k = math.ceil(math.log2(len(C)))\n",
    "    z = np.zeros((k, len(C)))\n",
    "    for i in range(1, k+1):\n",
    "        for j in range(1, len(C)+1):\n",
    "            if math.floor(j/(2**i)) % 2 == 1: # odd number\n",
    "                z[i-1, j-1] = 1\n",
    "            else:\n",
    "                z[i-1, j-1] = 0\n",
    "print(z)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
