bound_df$PI_upper[bound_df$race == "Black-vs-Rest"] = mu_U_Black - mu_L_other
bound_df$CI_lower[bound_df$race == "Black-vs-Rest"] =
mu_L_Black - mu_U_other - qnorm(1 - 0.025) * sqrt(var_L)/sqrt(nrow(proxy_income))
bound_df$CI_upper[bound_df$race == "Black-vs-Rest"] =
mu_U_Black - mu_L_other + qnorm(1 - 0.025) * sqrt(var_U)/sqrt(nrow(proxy_income))
# API versus the rest
mu_L_API = compute_mu_L(proxy_income$API, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["API"])
mu_U_other = compute_mu_U(1 - proxy_income$API, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["API"])
mu_U_API = compute_mu_U(proxy_income$API, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["API"])
mu_L_other = compute_mu_L(1 - proxy_income$API, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["API"])
var_L = compute_var_L(raw_race_prob["API"], 1 - raw_race_prob["API"],
proxy_income$yhat1, proxy_income$API,  1 - proxy_income$API,
proxy_income$outcome, mu_L_API - mu_U_other)
var_U = compute_var_U(raw_race_prob["API"], 1 - raw_race_prob["API"],
proxy_income$yhat1, proxy_income$API,  1 - proxy_income$API,
proxy_income$outcome, mu_U_API - mu_L_other)
bound_df$PI_lower[bound_df$race == "API-vs-Rest"] = mu_L_API - mu_U_other
bound_df$PI_upper[bound_df$race == "API-vs-Rest"] = mu_U_API - mu_L_other
bound_df$CI_lower[bound_df$race == "API-vs-Rest"] =
mu_L_API - mu_U_other - qnorm(1 - 0.025) * sqrt(var_L)/sqrt(nrow(proxy_income))
bound_df$CI_upper[bound_df$race == "API-vs-Rest"] =
mu_U_API - mu_L_other + qnorm(1 - 0.025) * sqrt(var_U)/sqrt(nrow(proxy_income))
bound_df[bound_df$race == "White-vs-Rest", "truth"] =
compute_true_dd(proxy_income, "White")
bound_df[bound_df$race == "Black-vs-Rest", "truth"] =
compute_true_dd(proxy_income, "Black")
bound_df[bound_df$race == "API-vs-Rest", "truth"] =
compute_true_dd(proxy_income, "API")
View(bound_df)
View(proxy_income)
View(bound_df)
# Black vs rest
mu_L_Black = compute_mu_L(proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["Black"])
mu_U_other = compute_mu_U(1 - proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["Black"])
mu_U_Black = compute_mu_U(proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["Black"])
mu_L_other = compute_mu_L(1 - proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["Black"])
var_L = compute_var_L(raw_race_prob["Black"], 1 - raw_race_prob["Black"],
proxy_income$yhat1, proxy_income$Black,  1 - proxy_income$Black,
proxy_income$outcome, mu_L_Black - mu_U_other)
var_U = compute_var_U(raw_race_prob["Black"], 1 - raw_race_prob["Black"],
proxy_income$yhat1, proxy_income$Black,  1 - proxy_income$Black,
proxy_income$outcome, mu_U_Black - mu_L_other)
bound_df$PI_lower[bound_df$race == "Black-vs-Rest"] = mu_L_Black - mu_U_other
bound_df$PI_upper[bound_df$race == "Black-vs-Rest"] = mu_U_Black - mu_L_other
bound_df$CI_lower[bound_df$race == "Black-vs-Rest"] =
mu_L_Black - mu_U_other - qnorm(1 - 0.025) * sqrt(var_L)/sqrt(nrow(proxy_income))
####################
#  Income as proxy
####################
proxy_income = read_csv("small_proxy_income.csv")
raw_race_prob = table(proxy_income$race)/nrow(proxy_income)
bound_df = data.frame(PI_lower = rep(0, 3), PI_upper = rep(0, 3),
CI_lower = rep(0, 3), CI_upper = rep(0, 3),
truth = rep(0, 3),
race = (c("White-vs-Rest", "Black-vs-Rest", "API-vs-Rest")))
# white vs other
mu_L_white = compute_mu_L(proxy_income$White, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["White"])
mu_U_other = compute_mu_U(1 - proxy_income$White, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["White"])
mu_U_white = compute_mu_U(proxy_income$White, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["White"])
mu_L_other = compute_mu_L(1 - proxy_income$White, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["White"])
var_L = compute_var_L(raw_race_prob["White"], 1 - raw_race_prob["White"],
proxy_income$yhat1, proxy_income$White,  1 - proxy_income$White,
proxy_income$outcome, mu_L_white - mu_U_other)
var_U = compute_var_U(raw_race_prob["White"], 1 - raw_race_prob["White"],
proxy_income$yhat1, proxy_income$White,  1 - proxy_income$White,
proxy_income$outcome, mu_U_white - mu_L_other)
bound_df$PI_lower[bound_df$race == "White-vs-Rest"] = mu_L_white - mu_U_other
bound_df$PI_upper[bound_df$race == "White-vs-Rest"] = mu_U_white - mu_L_other
bound_df$CI_lower[bound_df$race == "White-vs-Rest"] =
mu_L_white - mu_U_other - qnorm(1 - 0.025) * sqrt(var_L)/sqrt(nrow(proxy_income))
bound_df$CI_upper[bound_df$race == "White-vs-Rest"] =
mu_U_white - mu_L_other + qnorm(1 - 0.025) * sqrt(var_U)/sqrt(nrow(proxy_income))
# Black vs rest
mu_L_Black = compute_mu_L(proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["Black"])
mu_U_other = compute_mu_U(1 - proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["Black"])
mu_U_Black = compute_mu_U(proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  raw_race_prob["Black"])
mu_L_other = compute_mu_L(1 - proxy_income$Black, proxy_income$yhat1, proxy_income$outcome,  1 - raw_race_prob["Black"])
#####################
#  Both Income and Geolocation as proxy:
#####################
proxy_county_income = read_csv("small_proxy_county_income.csv")
View(proxy_county_income)
library(tidyverse)
source("warfarin_helper.R")
ls
setwd('/Users/nathanjo/Documents/Github/FairnessWithUnobservedProtectedClass/Warfrin')
source("warfarin_helper.R")
#########################
# Only Medicine as proxy
#########################
proxy_medicine = read_csv("medicine_as_proxy.csv")
n = nrow(proxy_medicine)
r = 1/2 # sample size ratio of each dataset over the total sample size
primary_index = sample(1:n, n/2, replace = FALSE)
# the first n/2 obs correspond to D_{pri} in paper
# the last n/2 obs correspond to D_{aux} in paper
bound_df_medicine = data.frame(PI_lower = rep(0, 3), PI_upper = rep(0, 3),
CI_lower = rep(0, 3), CI_upper = rep(0, 3),
truth = rep(0, 3),
race = (c("White-vs-Rest", "Black-vs-Rest", "Asian-vs-Rest")))
proxy_medicine = read_csv("medicine_as_proxy.csv")
proxy_medicine = proxy_medicine %>%
mutate(
White_prob = white_prob,
Black_prob = black_prob,
Asian_prob = asian_prob
)
###  White vs rest
# estimate the quantities for alpha = white in equation (35)
Wbar_L_11_White = compute_Wbar_L_hyy(primary_index,
proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat1"],
ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 1) & (proxy_medicine$Y == 1), 1, 0))
Wbar_L_01_White = compute_Wbar_L_hyy(primary_index,
proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat0"],
ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 0) & (proxy_medicine$Y == 1), 1, 0))
Wbar_U_11_White = compute_Wbar_U_hyy(primary_index,
proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat1"],
ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 1) & (proxy_medicine$Y == 1), 1, 0))
Wbar_U_01_White = compute_Wbar_U_hyy(primary_index,
proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat0"],
ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 0) & (proxy_medicine$Y == 1), 1, 0))
# estimate the quantity \hat mu'_{\hat y, y}(alpha; \tilde w^L, \tilde w^U) on page 39 for alpha = white in
mu_White_WL_WU_11 = (truncate(Wbar_L_11_White)/(truncate(Wbar_L_11_White) + truncate(Wbar_U_01_White)))
mu_White_WU_WL_11 = (truncate(Wbar_U_11_White)/(truncate(Wbar_U_11_White) + truncate(Wbar_L_01_White)))
mu_White_WL_WU_01 = truncate(Wbar_L_01_White)/(truncate(Wbar_L_01_White) + truncate(Wbar_U_11_White))
mu_White_WU_WL_01 = truncate(Wbar_U_01_White)/(truncate(Wbar_U_01_White) + truncate(Wbar_L_11_White))
# do the same for alpha = non_white
Wbar_L_11_Other = compute_Wbar_L_hyy(primary_index,
1 - proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat1"],
1 - ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 1) & (proxy_medicine$Y == 1), 1, 0))
Wbar_L_01_Other = compute_Wbar_L_hyy(primary_index,
1 - proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat0"],
1- ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 0) & (proxy_medicine$Y == 1), 1, 0))
Wbar_U_11_Other = compute_Wbar_U_hyy(primary_index,
1 - proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat1"],
1 - ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 1) & (proxy_medicine$Y == 1), 1, 0))
Wbar_U_01_Other = compute_Wbar_U_hyy(primary_index,
1 - proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat0"],
1 - ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 0) & (proxy_medicine$Y == 1), 1, 0))
mu_Other_WL_WU_11 = (truncate(Wbar_L_11_Other)/(truncate(Wbar_L_11_Other) + truncate(Wbar_U_01_Other)))
mu_Other_WU_WL_11 = (truncate(Wbar_U_11_Other)/(truncate(Wbar_U_11_Other) + truncate(Wbar_L_01_Other)))
mu_Other_WL_WU_01 = truncate(Wbar_L_01_Other)/(truncate(Wbar_L_01_Other) + truncate(Wbar_U_11_Other))
mu_Other_WU_WL_01 = truncate(Wbar_U_01_Other)/(truncate(Wbar_U_01_Other) + truncate(Wbar_L_11_Other))
# compute the estimated partial identification bounds
bound_df_medicine$PI_lower[bound_df_medicine$race == "White-vs-Rest"] = mu_White_WL_WU_11 - mu_Other_WU_WL_11
bound_df_medicine$PI_upper[bound_df_medicine$race == "White-vs-Rest"] = mu_White_WU_WL_11 - mu_Other_WL_WU_11
# compute the estimated variance \hat V_L of the upper bound estimator, namely equation (39)
consta_UL = mu_White_WU_WL_01/(Wbar_L_11_White + Wbar_U_01_White)
consta_LU = mu_White_WL_WU_11/(Wbar_L_11_White + Wbar_U_01_White)
constb_UL = mu_Other_WU_WL_11/(Wbar_U_11_Other + Wbar_L_01_Other)
constb_LU = mu_Other_WL_WU_01/(Wbar_U_11_Other + Wbar_L_01_Other)
compute_Wbar_L_hyy <- function(primary_index,
race_prob, outcome_prob,
race, outcome){
# estimate the equation (35)
ind = ifelse(outcome_prob + race_prob - 1 >= 0, 1, 0)
lambda = c(ind * (outcome_prob + race_prob - 1))[[1]]
print(lambda)
xi = c(ind * (race - race_prob))[[1]]
gamma = c(ind * (outcome - outcome_prob))[[1]]
mean(lambda)+ mean(xi[-primary_index]) + mean(gamma[primary_index])
}
Wbar_L_11_White = compute_Wbar_L_hyy(primary_index,
proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat1"],
ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 1) & (proxy_medicine$Y == 1), 1, 0))
compute_Wbar_L_hyy <- function(primary_index,
race_prob, outcome_prob,
race, outcome){
# estimate the equation (35)
ind = ifelse(outcome_prob + race_prob - 1 >= 0, 1, 0)
lambda = c(ind * (outcome_prob + race_prob - 1))[[1]]
print(c(ind * (outcome_prob + race_prob - 1)))
print(lambda)
xi = c(ind * (race - race_prob))[[1]]
gamma = c(ind * (outcome - outcome_prob))[[1]]
mean(lambda)+ mean(xi[-primary_index]) + mean(gamma[primary_index])
}
Wbar_L_11_White = compute_Wbar_L_hyy(primary_index,
proxy_medicine[, "White_prob"], proxy_medicine[, "py1yhat1"],
ifelse(proxy_medicine$race == "White.", 1, 0),
ifelse((proxy_medicine$Yhat == 1) & (proxy_medicine$Y == 1), 1, 0))
View(proxy_income)
View(proxy_medicine)
library(policytree)
library(grf)
library(tictoc)
library(glue)
library(ggplot2)
library(dplyr)
setwd('/Users/nathanjo/Documents/Github/prescriptive-trees/data/Warfarin_v2/rf_balance_proba')
run = function(df_train, df_test, depth) {
get_scores = function(df_train) {
df_train = df_train %>% mutate(y_pred = ifelse(t == 0, ml0,
ifelse(t==1, ml1, ifelse(t==2, ml2, 'NA')))) %>%
transform(y_pred = as.numeric(y_pred))
bias <- (df_train$y - df_train$y_pred)/df_train$prob_t_pred_tree
scores <- df_train[, c('ml0', 'ml1', 'ml2')]
scores <- scores %>% rename('0'='ml0',
'1'="ml1",
'2'="ml2")
for(i in 1:ncol(scores)) {
scores[, i] <- scores[, i] + bias
}
return(scores)
}
scores <- get_scores(df_train)
X_train <- data.matrix(df_train[ , !(names(df_train) %in% c('y', 't', 'y0',
'y1', 'y2', 'prob_t_pred_tree',
'ml0', 'ml1', 'ml2', 'y_pred'))])
y_train <- data.matrix(df_train[c('y')])
t_train <- factor(df_train[, 't'], labels=c(0, 1, 2))
X_test <- data.matrix(df_test[ , !(names(df_test) %in% c('y', 't', 'y0',
'y1', 'y2', 'prob_t_pred_tree',
'ml0', 'ml1', 'ml2', 'y_pred'))])
y_test <- data.matrix(df_test[c('y')])
t_test <- factor(df_test[, 't'], labels=c(0, 1, 2))
tic('policytree')
tree <- policy_tree(X_train, scores, depth)
# policy_tree(X_train, scores, 2)
toc()
node.id <- predict(tree, X_test, type='action.id')
node.id <- node.id-1
df_test = df_test %>% mutate(t_opt = ifelse(y0 == 1, 0,
ifelse(y1 == 1, 1, ifelse(y2 == 1, 2, 'NA'))))
eval_policy <- node.id == df_test$t_opt
return(sum(eval_policy)/length(eval_policy))
}
seeds <- c('1', '2', '3', '4', '5')
splits <- c('1', '2', '3', '4', '5')
dataset_type <- 'r0.06'
oosp_random <- c()
oosp_r0.06 <- c()
oosp_r0.11 <- c()
dataset_type <- '0.33'
for (seed in seeds) {
for (split in splits) {
df_train <- read.csv(glue('seed{seed}/data_train_enc_{dataset_type}_{split}.csv'))
df_test <- read.csv(glue('seed{seed}/data_test_enc_{dataset_type}_{split}.csv'))
oosp_random <- append(oosp_random, run(df_train, df_test, 2))
}
}
dataset_type <- 'r0.06'
for (seed in seeds) {
for (split in splits) {
df_train <- read.csv(glue('seed{seed}/data_train_enc_{dataset_type}_{split}.csv'))
df_test <- read.csv(glue('seed{seed}/data_test_enc_{dataset_type}_{split}.csv'))
oosp_r0.06 <- append(oosp_r0.06, run(df_train, df_test, 2))
}
}
dataset_type <- 'r0.11'
for (seed in seeds) {
for (split in splits) {
df_train <- read.csv(glue('seed{seed}/data_train_enc_{dataset_type}_{split}.csv'))
df_test <- read.csv(glue('seed{seed}/data_test_enc_{dataset_type}_{split}.csv'))
oosp_r0.11 <- append(oosp_r0.11, run(df_train, df_test, 2))
}
}
results = data.frame(random=oosp_random, r0.06=oosp_r0.06, r0.11=oosp_r0.11)
colMeans(results)
transformed_results = data.frame()
for(i in 1:ncol(results)) {
print(names(results)[i])
buffer = data.frame(exp_design=rep(names(results)[i], 25), oosp=results[, i])
transformed_results <- rbind(transformed_results, buffer)
}
ggplot(transformed_results, aes(x=exp_design, y=oosp)) +
geom_boxplot()
setwd('/Users/nathanjo/Documents/Github/prescriptive-trees/other_methods/results/policytree/warfarin')
write.csv(results, glue('raw_proba_enc.csv'), row.names = FALSE)
ggsave(glue("oosp_boxplot_proba_enc.pdf"))
View(df_train)
rm(list=ls())
graphics.off()
##########################################################################################################
# Parameters
##########################################################################################################
# Choose the seeds
seeds = c(123,156,67,1,43)
for(data_seed in c(1,2,3,4,5)){
for(r in c(1,2,3)){
##########################################################################################################
# read data
##########################################################################################################
data_list = c("warfarin_0.33.csv","warfarin_r0.06.csv","warfarin_r0.11.csv")
data_enc_list = c("warfarin_enc_0.33.csv","warfarin_enc_r0.06.csv","warfarin_enc_r0.11.csv")
threshold_list = c("0.33","r0.06","r0.11")
path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/data/Warfarin_v2/add_gender/seed",toString(data_seed),"/",sep = "")
data_path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/Direct_Approach/test/seed",toString(data_seed),"/",data_list[r],sep = "")
data_enc_path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/Direct_Approach/test/seed",toString(data_seed),"/",data_enc_list[r],sep = "")
setwd(path)
data <- read.csv(data_path, header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data_enc <- read.csv(data_enc_path, header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data$t <- as.factor(data$t)
data_enc$t <- as.factor(data_enc$t)
threshold = threshold_list[r]
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
smp_size = 3000
if((data_seed==1 | data_seed == 3) & r==3){
rare_index <- (data$t == 2 & data$y ==0)
prob = rep(1/nrow(data), nrow(data))
prob[rare_index]=1
train_ind <- sample(seq_len(nrow(data)), size = smp_size, prob = prob)
}else{
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
}
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
data_train_enc <- data_enc[train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
##########################################################################################################
# Learning propensity score P(t|x) for each entry using decision tree
##########################################################################################################
t_train_data = data_train[,!(names(data_train) %in% c("y","y0","y1","y2"))]
t_test_data = data_test[,!(names(data_test) %in% c("y","y0","y1","y2"))]
train_control<- trainControl(method="repeatedcv", number=10, repeats = 3)
model.cv <- train(t ~ .,
data = t_train_data,
method = "rpart",
trControl = train_control)
model <- model.cv$finalModel
data_train_enc$prob_t_pred_tree <- NA
data_test_enc$prob_t_pred_tree <- NA
for(t in levels(data$t)){
index <- data_train$t == t
data_train_enc$prob_t_pred_tree[index]  <- predict(model, t_train_data, type = "prob")[index,t]
data_train$prob_t_pred_tree[index]  <- predict(model, t_train_data, type = "prob")[index,t]
index <- data_test$t == t
data_test_enc$prob_t_pred_tree[index]  <- predict(model, t_test_data, type = "prob")[index,t]
data_test$prob_t_pred_tree[index]  <- predict(model, t_test_data, type = "prob")[index,t]
}
rm(t_train_data,t_test_data)
# par(xpd = TRUE)
# plot(model, compress = TRUE)
# text(model, use.n = TRUE)
rm(model,model.cv,train_control)
##########################################################################################################
# Save the files
##########################################################################################################
# Save files
write.csv(data_train_enc,paste("data_train_enc_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("data_test_enc_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("data_train_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("data_test_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
}
}
}
library(caret)
##########################################################################################################
# Parameters
##########################################################################################################
# Choose the seeds
seeds = c(123,156,67,1,43)
for(data_seed in c(1,2,3,4,5)){
for(r in c(1,2,3)){
##########################################################################################################
# read data
##########################################################################################################
data_list = c("warfarin_0.33.csv","warfarin_r0.06.csv","warfarin_r0.11.csv")
data_enc_list = c("warfarin_enc_0.33.csv","warfarin_enc_r0.06.csv","warfarin_enc_r0.11.csv")
threshold_list = c("0.33","r0.06","r0.11")
path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/data/Warfarin_v2/add_gender/seed",toString(data_seed),"/",sep = "")
data_path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/Direct_Approach/test/seed",toString(data_seed),"/",data_list[r],sep = "")
data_enc_path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/Direct_Approach/test/seed",toString(data_seed),"/",data_enc_list[r],sep = "")
setwd(path)
data <- read.csv(data_path, header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data_enc <- read.csv(data_enc_path, header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data$t <- as.factor(data$t)
data_enc$t <- as.factor(data_enc$t)
threshold = threshold_list[r]
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
smp_size = 3000
if((data_seed==1 | data_seed == 3) & r==3){
rare_index <- (data$t == 2 & data$y ==0)
prob = rep(1/nrow(data), nrow(data))
prob[rare_index]=1
train_ind <- sample(seq_len(nrow(data)), size = smp_size, prob = prob)
}else{
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
}
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
data_train_enc <- data_enc[train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
##########################################################################################################
# Learning propensity score P(t|x) for each entry using decision tree
##########################################################################################################
t_train_data = data_train[,!(names(data_train) %in% c("y","y0","y1","y2"))]
t_test_data = data_test[,!(names(data_test) %in% c("y","y0","y1","y2"))]
train_control<- trainControl(method="repeatedcv", number=10, repeats = 3)
model.cv <- train(t ~ .,
data = t_train_data,
method = "rpart",
trControl = train_control)
model <- model.cv$finalModel
data_train_enc$prob_t_pred_tree <- NA
data_test_enc$prob_t_pred_tree <- NA
for(t in levels(data$t)){
index <- data_train$t == t
data_train_enc$prob_t_pred_tree[index]  <- predict(model, t_train_data, type = "prob")[index,t]
data_train$prob_t_pred_tree[index]  <- predict(model, t_train_data, type = "prob")[index,t]
index <- data_test$t == t
data_test_enc$prob_t_pred_tree[index]  <- predict(model, t_test_data, type = "prob")[index,t]
data_test$prob_t_pred_tree[index]  <- predict(model, t_test_data, type = "prob")[index,t]
}
rm(t_train_data,t_test_data)
# par(xpd = TRUE)
# plot(model, compress = TRUE)
# text(model, use.n = TRUE)
rm(model,model.cv,train_control)
##########################################################################################################
# Save the files
##########################################################################################################
# Save files
write.csv(data_train_enc,paste("data_train_enc_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("data_test_enc_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("data_train_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("data_test_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
}
}
}
for(data_seed in c(1,2,3,4,5)){
for(r in c(1,2,3)){
##########################################################################################################
# read data
##########################################################################################################
data_list = c("warfarin_0.33.csv","warfarin_r0.06.csv","warfarin_r0.11.csv")
data_enc_list = c("warfarin_enc_0.33.csv","warfarin_enc_r0.06.csv","warfarin_enc_r0.11.csv")
threshold_list = c("0.33","r0.06","r0.11")
path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/data/Warfarin_v2/add_gender/seed",toString(data_seed),"/",sep = "")
data_path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/Direct_Approach/test/seed",toString(data_seed),"/",data_list[r],sep = "")
data_enc_path = paste("/Users/nathanjo/Documents/GitHub/prescriptive-trees/Direct_Approach/test/seed",toString(data_seed),"/",data_enc_list[r],sep = "")
setwd(path)
data <- read.csv(data_path, header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data_enc <- read.csv(data_enc_path, header = TRUE, sep = ",",na.strings = "",stringsAsFactors = TRUE)
data$t <- as.factor(data$t)
data_enc$t <- as.factor(data_enc$t)
threshold = threshold_list[r]
for(Run in c(1,2,3,4,5)){
## set the seed to make your partition reproducible
set.seed(seeds[Run])
##########################################################################################################
# Splitting data into training and test
##########################################################################################################
smp_size = 3000
if((data_seed==1 | data_seed == 3) & r==3){
rare_index <- (data$t == 2 & data$y ==0)
prob = rep(1/nrow(data), nrow(data))
prob[rare_index]=1
train_ind <- sample(seq_len(nrow(data)), size = smp_size, prob = prob)
}else{
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
}
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
data_train_enc <- data_enc[train_ind, ]
data_test_enc <- data_enc[-train_ind, ]
##########################################################################################################
# Learning propensity score P(t|x) for each entry using decision tree
##########################################################################################################
t_train_data = data_train[,!(names(data_train) %in% c("y","y0","y1","y2", "id", "Gender"))]
t_test_data = data_test[,!(names(data_test) %in% c("y","y0","y1","y2", "id", "Gender"))]
train_control<- trainControl(method="repeatedcv", number=10, repeats = 3)
model.cv <- train(t ~ .,
data = t_train_data,
method = "rpart",
trControl = train_control)
model <- model.cv$finalModel
data_train_enc$prob_t_pred_tree <- NA
data_test_enc$prob_t_pred_tree <- NA
for(t in levels(data$t)){
index <- data_train$t == t
data_train_enc$prob_t_pred_tree[index]  <- predict(model, t_train_data, type = "prob")[index,t]
data_train$prob_t_pred_tree[index]  <- predict(model, t_train_data, type = "prob")[index,t]
index <- data_test$t == t
data_test_enc$prob_t_pred_tree[index]  <- predict(model, t_test_data, type = "prob")[index,t]
data_test$prob_t_pred_tree[index]  <- predict(model, t_test_data, type = "prob")[index,t]
}
rm(t_train_data,t_test_data)
# par(xpd = TRUE)
# plot(model, compress = TRUE)
# text(model, use.n = TRUE)
rm(model,model.cv,train_control)
##########################################################################################################
# Save the files
##########################################################################################################
# Save files
write.csv(data_train_enc,paste("data_train_enc_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test_enc,paste("data_test_enc_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_train,paste("data_train_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
write.csv(data_test,paste("data_test_",toString(threshold),"_",toString(Run),".csv",sep=''),row.names = FALSE)
}
}
}
